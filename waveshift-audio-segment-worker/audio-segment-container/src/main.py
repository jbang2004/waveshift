#!/usr/bin/env python3
"""
éŸ³é¢‘åˆ‡åˆ†å®¹å™¨æœåŠ¡
åŸºäºè½¬å½•æ•°æ®å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œæ™ºèƒ½éŸ³é¢‘ç‰‡æ®µæå–
"""
import os
import re
import asyncio
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timezone

import boto3
from fastapi import FastAPI
from pydantic import BaseModel

# é…ç½®æ—¥å¿— - å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(title="Audio Segment Container")

# æ•°æ®æ¨¡å‹
class TranscriptItem(BaseModel):
    sequence: int
    startMs: int  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    endMs: int    # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    speaker: str
    original: str
    translation: Optional[str] = None
    content_type: str = 'speech'

class R2Config(BaseModel):
    accountId: str
    accessKeyId: str
    secretAccessKey: str
    bucketName: str
    publicDomain: str

class SegmentRequest(BaseModel):
    audioKey: str
    transcripts: List[TranscriptItem]
    outputPrefix: str
    r2Config: R2Config

class AudioSegment(BaseModel):
    segmentId: str
    audioKey: str
    speaker: str
    startMs: int
    endMs: int
    durationMs: int
    sentences: List[Dict]

class SegmentResponse(BaseModel):
    success: bool
    segments: Optional[List[AudioSegment]] = None
    sentenceToSegmentMap: Optional[Dict[int, str]] = None
    error: Optional[str] = None


from enum import Enum
from typing import Optional, NamedTuple

class AccumulatorState(Enum):
    ACCUMULATING = "accumulating"      # æ­£åœ¨ç´¯ç§¯sentences
    READY_FOR_REUSE = "ready_for_reuse"  # å·²ä¸Šä¼ ï¼Œå¯å¤ç”¨audio_url

class BreakDecision(NamedTuple):
    should_break: bool
    reason: str

class StreamingAccumulator:
    """æµå¼ç´¯ç§¯å™¨ï¼šç»´æŠ¤å½“å‰éŸ³é¢‘ç‰‡æ®µçš„å¤„ç†çŠ¶æ€"""
    def __init__(self, first_sentence: Dict):
        self.speaker = first_sentence['speaker']
        self.time_ranges = [[first_sentence['startMs'], first_sentence['endMs']]]
        self.pending_sentences = [first_sentence]
        self.sequence_start = first_sentence['sequence']
        self.state = AccumulatorState.ACCUMULATING
        self._audio_url: Optional[str] = None
        self._segment_id: Optional[str] = None
        
    @property
    def audio_url(self) -> Optional[str]:
        return self._audio_url
        
    @property
    def segment_id(self) -> Optional[str]:
        return self._segment_id
        
    def mark_as_uploaded(self, audio_url: str, segment_id: str):
        """æ ‡è®°ä¸ºå·²ä¸Šä¼ ï¼Œè¿›å…¥å¤ç”¨çŠ¶æ€"""
        self._audio_url = audio_url
        self._segment_id = segment_id
        self.state = AccumulatorState.READY_FOR_REUSE
        self.pending_sentences = []  # æ¸…ç©ºå¾…å¤„ç†å¥å­
        self.time_ranges = []
        
    def can_reuse_audio(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å·²ä¸Šä¼ çš„éŸ³é¢‘"""
        return (self.state == AccumulatorState.READY_FOR_REUSE and 
                self._audio_url is not None and 
                self._segment_id is not None)
        
    def get_total_duration(self, gap_duration_ms: int) -> int:
        """è®¡ç®—ç´¯ç§¯å™¨çš„æ€»æ—¶é•¿ï¼ˆåŒ…å«gapsï¼‰"""
        if self.state == AccumulatorState.READY_FOR_REUSE:
            return 0  # å·²ä¸Šä¼ çŠ¶æ€ä¸è®¡ç®—æ—¶é•¿
            
        audio_duration = sum(end - start for start, end in self.time_ranges)
        gap_count = max(0, len(self.time_ranges) - 1)
        return audio_duration + (gap_count * gap_duration_ms)
        
    def add_sentence(self, sentence: Dict, gap_threshold_ms: int):
        """æ·»åŠ å¥å­åˆ°ç´¯ç§¯å™¨ï¼Œæ™ºèƒ½å¤„ç†æ—¶é—´èŒƒå›´"""
        if self.state != AccumulatorState.ACCUMULATING:
            raise ValueError("Cannot add sentence to non-accumulating accumulator")
            
        # æ£€æŸ¥é—´éš”å¹¶å†³å®šå¦‚ä½•åˆå¹¶æ—¶é—´èŒƒå›´
        last_end = self.time_ranges[-1][1]
        gap = sentence['startMs'] - last_end
        
        if gap <= gap_threshold_ms:
            # å°é—´éš”ï¼šæ‰©å±•æœ€åä¸€ä¸ªæ—¶é—´èŒƒå›´
            self.time_ranges[-1][1] = sentence['endMs']
        else:
            # å¤§é—´éš”ï¼šæ·»åŠ æ–°æ—¶é—´èŒƒå›´
            self.time_ranges.append([sentence['startMs'], sentence['endMs']])
            
        self.pending_sentences.append(sentence)


class SegmentationDecision:
    """éŸ³é¢‘åˆ‡åˆ†å†³ç­–é€»è¾‘"""
    
    @staticmethod
    def should_break_accumulation(accumulator: StreamingAccumulator, sentence: Dict, 
                                 gap_threshold_ms: int) -> BreakDecision:
        """ç»Ÿä¸€çš„ç´¯ç§¯ä¸­æ–­å†³ç­–"""
        if not accumulator:
            return BreakDecision(False, "no_accumulator")
            
        # è¯´è¯äººå˜åŒ–
        if sentence['speaker'] != accumulator.speaker:
            return BreakDecision(True, "speaker_change")
            
        # é—´éš”è¿‡å¤§
        if accumulator.time_ranges:
            last_end = accumulator.time_ranges[-1][1]
            gap = sentence['startMs'] - last_end
            if gap > gap_threshold_ms:
                return BreakDecision(True, f"gap_too_large_{gap}ms")
                
        return BreakDecision(False, "continue_accumulation")


class AudioSegmenter:
    """éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - æµå¼å¤„ç†çš„æ™ºèƒ½éŸ³é¢‘åˆ‡ç‰‡"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å‚æ•°
        self.gap_duration_ms = int(os.getenv('GAP_DURATION_MS', '500'))
        self.max_duration_ms = int(os.getenv('MAX_DURATION_MS', '12000'))  
        self.min_duration_ms = int(os.getenv('MIN_DURATION_MS', '3000'))
        self.gap_threshold_multiplier = int(os.getenv('GAP_THRESHOLD_MULTIPLIER', '3'))
        self.gap_threshold_ms = self.gap_duration_ms * self.gap_threshold_multiplier
        
        self.logger = logger
        self.logger.info(f"ğŸµ AudioSegmenteråˆå§‹åŒ– - Gap:{self.gap_duration_ms}ms, "
                        f"Max:{self.max_duration_ms}ms, Min:{self.min_duration_ms}ms, "
                        f"GapThreshold:{self.gap_threshold_ms}ms")
        
    async def process_sentences_streaming(self, transcripts: List[TranscriptItem], 
                                        audio_path: str, output_prefix: str, 
                                        s3_client, bucket_name: str) -> Tuple[List[AudioSegment], Dict[int, str]]:
        """æµå¼å¤„ç†ï¼šä¸€æ¬¡éå†ï¼Œå®æ—¶å†³ç­–ï¼Œç«‹å³ä¸Šä¼ """
        segments = []
        sentence_to_segment_map = {}
        accumulator = None
        
        # æå–æœ‰æ•ˆè¯­éŸ³å¥å­ï¼ˆç›´æ¥ä½¿ç”¨TranscriptItemï¼Œé¿å…ä¸å¿…è¦è½¬æ¢ï¼‰
        valid_sentences = [item for item in transcripts 
                          if item.content_type == 'speech' and item.startMs < item.endMs]
        
        self.logger.info(f"ğŸ¬ å¼€å§‹æµå¼å¤„ç† {len(valid_sentences)} ä¸ªè¯­éŸ³å¥å­")
        
        for sentence in valid_sentences:
            # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å·²ä¸Šä¼ çš„éŸ³é¢‘
            if accumulator and accumulator.can_reuse_audio() and sentence.speaker == accumulator.speaker:
                sentence_to_segment_map[sentence.sequence] = accumulator.segment_id
                self.logger.debug(f"å¥å­{sentence.sequence}å¤ç”¨éŸ³é¢‘ç‰‡æ®µ: {accumulator.segment_id}")
                continue
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘å°„å½“å‰ç´¯ç§¯å™¨
            decision = SegmentationDecision.should_break_accumulation(
                accumulator, self._sentence_to_dict(sentence), self.gap_threshold_ms
            )
            
            if decision.should_break:
                # å¦‚æœæ˜¯READY_FOR_REUSEçŠ¶æ€ï¼Œå¼ºåˆ¶æ¸…ç†é¿å…åç»­é”™è¯¯å¤ç”¨
                if accumulator and accumulator.state == AccumulatorState.READY_FOR_REUSE:
                    self.logger.info(f"ğŸ§¹ æ¸…ç†è·¨è¯´è¯äººçš„å¤ç”¨çŠ¶æ€: {accumulator.speaker} -> {sentence.speaker}")
                    accumulator = None
                else:
                    segment = await self._finalize_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
                    if segment:
                        segments.append(segment)
                        self._update_sentence_mapping(accumulator, segment.segmentId, sentence_to_segment_map)
                    accumulator = None
            
            # æ·»åŠ å½“å‰å¥å­åˆ°ç´¯ç§¯å™¨
            if not accumulator:
                accumulator = StreamingAccumulator(self._sentence_to_dict(sentence))
            else:
                accumulator.add_sentence(self._sentence_to_dict(sentence), self.gap_threshold_ms)
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è½½
            if self._is_accumulator_full(accumulator):
                segment = await self._finalize_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
                if segment:
                    segments.append(segment)
                    self._update_sentence_mapping(accumulator, segment.segmentId, sentence_to_segment_map)
                    accumulator.mark_as_uploaded(segment.audioKey, segment.segmentId)
        
        # å¤„ç†æœ€åçš„ç´¯ç§¯å™¨
        if accumulator and accumulator.pending_sentences:
            segment = await self._finalize_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
            if segment:
                segments.append(segment)
                self._update_sentence_mapping(accumulator, segment.segmentId, sentence_to_segment_map)
        
        self.logger.info(f"âœ… æµå¼å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
        return segments, sentence_to_segment_map
    
    def _sentence_to_dict(self, item: TranscriptItem) -> Dict:
        """è½¬æ¢TranscriptItemä¸ºå­—å…¸ï¼ˆä»…åœ¨éœ€è¦æ—¶è½¬æ¢ï¼‰"""
        return {
            'sequence': item.sequence,
            'speaker': item.speaker,
            'original': item.original,
            'translation': item.translation,
            'startMs': item.startMs,
            'endMs': item.endMs,
            'duration': item.endMs - item.startMs
        }
    
    
    def _update_sentence_mapping(self, accumulator: StreamingAccumulator, segment_id: str, 
                                sentence_map: Dict[int, str]):
        """ç»Ÿä¸€çš„å¥å­æ˜ å°„æ›´æ–°é€»è¾‘"""
        for sentence in accumulator.pending_sentences:
            sentence_map[sentence['sequence']] = segment_id
    
    def _is_accumulator_full(self, accumulator: StreamingAccumulator) -> bool:
        """æ£€æŸ¥ç´¯ç§¯å™¨æ˜¯å¦æ»¡è½½"""
        if not accumulator or accumulator.state != AccumulatorState.ACCUMULATING:
            return False
        return accumulator.get_total_duration(self.gap_duration_ms) >= self.max_duration_ms
    
    async def _finalize_accumulator(self, accumulator: StreamingAccumulator, 
                                   audio_path: str, output_prefix: str, 
                                   s3_client, bucket_name: str) -> Optional[AudioSegment]:
        """å®Œæˆç´¯ç§¯å™¨ï¼šç”ŸæˆéŸ³é¢‘å¹¶ä¸Šä¼ """
        if not accumulator or not accumulator.pending_sentences:
            return None
        
        # æ£€æŸ¥æœ€å°æ—¶é•¿
        total_duration = accumulator.get_total_duration(self.gap_duration_ms)
        if len(accumulator.pending_sentences) == 1 and total_duration < self.min_duration_ms:
            sentence_details = [(s['sequence'], s['startMs'], s['endMs'], s['endMs']-s['startMs']) 
                               for s in accumulator.pending_sentences]
            self.logger.warning(f"ğŸ—‘ï¸ ä¸¢å¼ƒè¿‡çŸ­å•å¥ç‰‡æ®µ: speaker={accumulator.speaker}, "
                              f"è®¡ç®—æ—¶é•¿={total_duration}ms < æœ€å°æ—¶é•¿={self.min_duration_ms}ms, "
                              f"å¥å­è¯¦æƒ…(sequence,start,end,å®é™…æ—¶é•¿)={sentence_details}")
            return None
        
        # ç”Ÿæˆclipä¿¡æ¯
        clip_id = f"sequence_{accumulator.sequence_start:04d}"
        audio_key = f"{output_prefix}/{clip_id}_{accumulator.speaker}.wav"
        
        self.logger.info(f"ğŸµ å®ŒæˆéŸ³é¢‘ç‰‡æ®µ {clip_id}: speaker={accumulator.speaker}, "
                        f"ranges={len(accumulator.time_ranges)}, sentences={len(accumulator.pending_sentences)}, "
                        f"duration={total_duration}ms")
        
        # ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘
        success = await self._process_audio_with_ffmpeg(
            audio_path, accumulator.time_ranges, audio_key, s3_client, bucket_name
        )
        
        if not success:
            return None
        
        # åˆ›å»ºsegmentå¯¹è±¡
        return AudioSegment(
            segmentId=clip_id,
            audioKey=audio_key,
            speaker=accumulator.speaker,
            startMs=accumulator.time_ranges[0][0],
            endMs=accumulator.time_ranges[-1][1],
            durationMs=total_duration,
            sentences=[{
                'sequence': s['sequence'],
                'original': s['original'],
                'translation': s.get('translation')
            } for s in accumulator.pending_sentences]
        )
    
    async def _process_audio_with_ffmpeg(self, audio_path: str, time_ranges: List[List[int]], 
                                       audio_key: str, s3_client, bucket_name: str) -> bool:
        """ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘å¹¶ä¸Šä¼ åˆ°R2"""
        import subprocess
        import tempfile
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            output_path = tmp_file.name
        
        try:
            if len(time_ranges) == 1:
                # ğŸ¯ å•æ®µå¤„ç† - é«˜æ€§èƒ½æµå¤åˆ¶
                start_ms, end_ms = time_ranges[0]
                start_sec = start_ms / 1000.0
                duration_sec = (end_ms - start_ms) / 1000.0
                
                ffmpeg_cmd = [
                    'ffmpeg', '-y',
                    '-ss', f'{start_sec:.3f}',
                    '-i', audio_path,
                    '-t', f'{duration_sec:.3f}',
                    '-c:a', 'copy',
                    '-avoid_negative_ts', 'make_zero',
                    output_path
                ]
                
                self.logger.info(f"ğŸ“ å•æ®µFFmpeg: {' '.join(ffmpeg_cmd)}")
                
            else:
                # ğŸµ å¤šæ®µå¤„ç† - Gapé™éŸ³æ’å…¥
                input_specs = []
                
                # ä¸ºæ¯ä¸ªéŸ³é¢‘æ®µæ·»åŠ è¾“å…¥
                for i, (start_ms, end_ms) in enumerate(time_ranges):
                    start_sec = start_ms / 1000.0
                    duration_sec = (end_ms - start_ms) / 1000.0
                    
                    input_specs.extend(['-ss', f'{start_sec:.3f}', '-t', f'{duration_sec:.3f}', '-i', audio_path])
                    
                    self.logger.info(f"  æ®µ{i+1}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s ({duration_sec:.3f}s)")
                
                # æ„å»ºfilter_complex - Gapé™éŸ³æ’å…¥
                gap_sec = self.gap_duration_ms / 1000.0
                gap_filter = f'anullsrc=channel_layout=mono:sample_rate=44100:duration={gap_sec:.3f}'
                
                # æ„å»ºæ‹¼æ¥åºåˆ—ï¼šéŸ³é¢‘1 + gap + éŸ³é¢‘2 + gap + éŸ³é¢‘3...
                concat_parts = []
                for i in range(len(time_ranges)):
                    concat_parts.append(f'[{i}:a]')
                    if i < len(time_ranges) - 1:
                        concat_parts.append('[gap]')
                
                filter_complex = f'{gap_filter}[gap];{"".join(concat_parts)}concat=n={len(concat_parts)}:v=0:a=1[out]'
                
                ffmpeg_cmd = ['ffmpeg', '-y'] + input_specs + [
                    '-filter_complex', filter_complex,
                    '-map', '[out]',
                    output_path
                ]
                
                self.logger.info(f"ğŸµ å¤šæ®µå¤„ç†: {len(time_ranges)}æ®µ + {len(time_ranges)-1}ä¸ªGap({gap_sec:.3f}s)")
            
            # æ‰§è¡Œffmpegå‘½ä»¤
            await asyncio.to_thread(
                subprocess.run, ffmpeg_cmd,
                capture_output=True, text=True, check=True
            )
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
                self.logger.error(f"FFmpegæœªç”Ÿæˆæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
                return False
            
            # ä¸Šä¼ åˆ°R2
            with open(output_path, 'rb') as f:
                s3_client.put_object(
                    Bucket=bucket_name,
                    Body=f,
                    Key=audio_key,
                    ContentType='audio/wav'
                )
            
            self.logger.info(f"ğŸ“¤ å·²ä¸Šä¼ éŸ³é¢‘åˆ°R2: {audio_key}")
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"FFmpegå¤„ç†å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            self.logger.error(f"å¤„ç†éŸ³é¢‘å¼‚å¸¸: {e}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(output_path):
                os.unlink(output_path)
    
    # æ‰€æœ‰æ—§çš„å¤„ç†é€»è¾‘å·²ç§»é™¤ï¼Œä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
    # åŸæœ‰æ–¹æ³•ï¼š
    # - _calculate_total_duration_with_gaps
    # - _create_audio_clips
    # - _extract_speech_sentences
    # - _group_by_speaker
    # - _process_speaker_groups
    # - _split_long_group
    # - _should_keep_clip
    # - _generate_clip_info
    # å·²å…¨éƒ¨è¢«æµå¼å¤„ç†æ–¹æ³•å–ä»£


# åˆ›å»ºR2å®¢æˆ·ç«¯
def create_r2_client(config: R2Config):
    """åˆ›å»ºR2å®¢æˆ·ç«¯"""
    return boto3.client(
        's3',
        endpoint_url=f'https://{config.accountId}.r2.cloudflarestorage.com',
        aws_access_key_id=config.accessKeyId,
        aws_secret_access_key=config.secretAccessKey,
        region_name='auto'
    )


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "audio-segment-container",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@app.post("/segment", response_model=SegmentResponse)
async def segment_audio(request: SegmentRequest):
    """éŸ³é¢‘åˆ‡åˆ†æ¥å£"""
    logger.info(f"æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚: audioKey={request.audioKey}, transcripts={len(request.transcripts)}")
    
    # å·²ç§»é™¤æ€§èƒ½ä¼˜åŒ–å¼€å…³ - æ–°ç®—æ³•å·²å½»åº•ç§»é™¤fadeé€»è¾‘
    
    try:
        # åˆ›å»ºR2å®¢æˆ·ç«¯
        s3_client = create_r2_client(request.r2Config)
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•ååˆ›å»ºä¸´æ—¶æ–‡ä»¶
            original_ext = os.path.splitext(request.audioKey)[1] or '.aac'
            audio_path = Path(temp_dir) / f"input_audio{original_ext}"
            
            # ä»R2ä¸‹è½½éŸ³é¢‘
            try:
                logger.info(f"ä»R2ä¸‹è½½éŸ³é¢‘: {request.audioKey}")
                logger.info(f"ç›®æ ‡è·¯å¾„: {audio_path}")
                
                s3_client.download_file(
                    Bucket=request.r2Config.bucketName,
                    Key=request.audioKey,
                    Filename=str(audio_path)
                )
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                if not audio_path.exists():
                    raise FileNotFoundError(f"ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
                downloaded_size = audio_path.stat().st_size
                logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {downloaded_size} bytes")
                
                if downloaded_size == 0:
                    raise ValueError(f"ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {request.audioKey}")
                    
            except Exception as e:
                logger.error(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ {request.audioKey}: {e}")
            
            # ğŸµ åˆ›å»ºåˆ‡åˆ†å™¨ - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
            segmenter = AudioSegmenter()
            
            # ğŸš€ ä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
            s3_client_for_upload = boto3.client(
                's3',
                endpoint_url=f'https://{request.r2Config.accountId}.r2.cloudflarestorage.com',
                aws_access_key_id=request.r2Config.accessKeyId,
                aws_secret_access_key=request.r2Config.secretAccessKey,
                region_name='auto'
            )
            
            segments, sentence_to_segment_map = await segmenter.process_sentences_streaming(
                request.transcripts,
                str(audio_path),
                request.outputPrefix,
                s3_client_for_upload,
                request.r2Config.bucketName
            )
            
            if not segments:
                return SegmentResponse(
                    success=True,
                    segments=[],
                    sentenceToSegmentMap={}
                )
            
            logger.info(f"âœ… æµå¼å¤„ç†æˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
            
            return SegmentResponse(
                success=True,
                segments=segments,
                sentenceToSegmentMap=sentence_to_segment_map
            )
            
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: {e}", exc_info=True)
        # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_message = str(e)
        if hasattr(e, '__cause__') and e.__cause__:
            error_message += f" (åŸå› : {e.__cause__})"
        
        return SegmentResponse(
            success=False,
            error=f"{error_type}: {error_message}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)