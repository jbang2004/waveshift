#!/usr/bin/env python3
"""
éŸ³é¢‘åˆ‡åˆ†å®¹å™¨æœåŠ¡
åŸºäºè½¬å½•æ•°æ®å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œæ™ºèƒ½éŸ³é¢‘ç‰‡æ®µæå–
"""
import os
import re
import json
import asyncio
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timezone

import boto3
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# é…ç½®æ—¥å¿— - å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(title="Audio Segment Container")

# æ•°æ®æ¨¡å‹
class TranscriptItem(BaseModel):
    sequence: int
    startMs: int  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    endMs: int    # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    speaker: str
    original: str
    translation: Optional[str] = None
    content_type: str = 'speech'

class R2Config(BaseModel):
    accountId: str
    accessKeyId: str
    secretAccessKey: str
    bucketName: str
    publicDomain: str

class SegmentRequest(BaseModel):
    audioKey: str
    transcripts: List[TranscriptItem]
    outputPrefix: str
    r2Config: R2Config

class AudioSegment(BaseModel):
    segmentId: str
    audioKey: str
    speaker: str
    startMs: int
    endMs: int
    durationMs: int
    sentences: List[Dict]

class SegmentResponse(BaseModel):
    success: bool
    segments: Optional[List[AudioSegment]] = None
    sentenceToSegmentMap: Optional[Dict[int, str]] = None
    error: Optional[str] = None


class AudioSegmenter:
    """éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - åŸºäºç²¾ç¡®æ—¶é—´æˆ³å’ŒGapæœºåˆ¶çš„æ™ºèƒ½éŸ³é¢‘åˆ‡ç‰‡"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å‚æ•°
        self.gap_duration_ms = int(os.getenv('GAP_DURATION_MS', '500'))
        self.max_duration_ms = int(os.getenv('MAX_DURATION_MS', '12000'))  
        self.min_duration_ms = int(os.getenv('MIN_DURATION_MS', '1500'))  # æ”¹ä¸º1500ms
        
        self.logger = logger
        self.logger.info(f"ğŸµ AudioSegmenteråˆå§‹åŒ– - Gap:{self.gap_duration_ms}ms, "
                        f"Max:{self.max_duration_ms}ms, Min:{self.min_duration_ms}ms")
        
    # æ—¶é—´è½¬æ¢å‡½æ•°å·²ç§»é™¤ - ç›´æ¥ä½¿ç”¨æ¯«ç§’æ ¼å¼ï¼Œæ— éœ€è½¬æ¢
    
    def _calculate_total_duration_with_gaps(self, block: List[Dict]) -> int:
        """è®¡ç®—åŒ…å«gapçš„æ€»æ—¶é•¿"""
        if not block:
            return 0
        
        # éŸ³é¢‘æ€»æ—¶é•¿
        audio_duration = sum(s['duration'] for s in block)
        
        # Gapæ€»æ—¶é•¿ = (å¥å­æ•°é‡ - 1) * gap_duration_ms
        gap_duration = (len(block) - 1) * self.gap_duration_ms
        
        total = audio_duration + gap_duration
        self.logger.debug(f"æ—¶é•¿è®¡ç®—: éŸ³é¢‘{audio_duration}ms + Gap{gap_duration}ms = {total}ms")
        
        return total
    
    def _truncate_block_with_gaps(self, block: List[Dict]) -> List[Dict]:
        """è€ƒè™‘gapçš„æ™ºèƒ½æˆªæ–­"""
        if not block:
            return block
        
        accumulated_duration = 0
        sentences_to_include = []
        
        for i, sentence in enumerate(block):
            # å½“å‰å¥å­æ—¶é•¿
            sentence_duration = sentence['duration']
            
            # å¦‚æœä¸æ˜¯ç¬¬ä¸€ä¸ªå¥å­ï¼Œéœ€è¦åŠ ä¸Šgapæ—¶é•¿
            gap_duration = self.gap_duration_ms if i > 0 else 0
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ—¶é•¿
            if accumulated_duration + gap_duration + sentence_duration <= self.max_duration_ms:
                sentences_to_include.append(sentence)
                accumulated_duration += gap_duration + sentence_duration
                self.logger.debug(f"åŒ…å«å¥å­{sentence['sequence']}: ç´¯è®¡{accumulated_duration}ms")
            else:
                # è¶…è¿‡é™åˆ¶ï¼Œåœæ­¢æ·»åŠ 
                self.logger.debug(f"æˆªæ–­: å¥å­{sentence['sequence']}ä¼šå¯¼è‡´è¶…è¿‡{self.max_duration_ms}ms")
                break
        
        return sentences_to_include
    
    def _merge_adjacent_short_blocks(self, blocks: List[List[Dict]]) -> List[List[Dict]]:
        """æ™ºèƒ½åˆå¹¶ç›¸é‚»çš„åŒè¯´è¯äººçŸ­å—ï¼Œé¿å…è¯¯åˆ å¯åˆå¹¶çš„ç‰‡æ®µ"""
        if not blocks:
            return blocks
            
        merged_blocks = []
        i = 0
        
        while i < len(blocks):
            current_block = blocks[i]
            current_duration = self._calculate_total_duration_with_gaps(current_block)
            current_speaker = current_block[0]['speaker']
            
            # å¦‚æœå½“å‰å—å·²ç»è¶³å¤Ÿé•¿ï¼Œç›´æ¥ä¿ç•™
            if current_duration >= self.min_duration_ms:
                merged_blocks.append(current_block)
                i += 1
                continue
            
            # å½“å‰å—å¤ªçŸ­ï¼Œå°è¯•ä¸åç»­åŒè¯´è¯äººå—åˆå¹¶
            merged = current_block.copy()
            j = i + 1
            
            while j < len(blocks):
                next_block = blocks[j]
                next_speaker = next_block[0]['speaker']
                
                # åªåˆå¹¶åŒè¯´è¯äººçš„å—
                if next_speaker != current_speaker:
                    break
                    
                # å°è¯•åˆå¹¶
                potential_merged = merged + next_block
                potential_duration = self._calculate_total_duration_with_gaps(potential_merged)
                
                # å¦‚æœåˆå¹¶åè¶…è¿‡æœ€å¤§æ—¶é•¿ï¼Œåœæ­¢åˆå¹¶
                if potential_duration > self.max_duration_ms:
                    break
                    
                # æ‰§è¡Œåˆå¹¶
                merged = potential_merged
                self.logger.info(f"ğŸ”— åˆå¹¶ç›¸é‚»çŸ­å—: speaker={current_speaker}, "
                               f"blocks {i+1}-{j+1}, duration {current_duration}ms -> {potential_duration}ms")
                
                # å¦‚æœåˆå¹¶åè¾¾åˆ°æœ€å°æ—¶é•¿ï¼Œå¯ä»¥åœæ­¢ï¼ˆä½†ç»§ç»­æ£€æŸ¥æ˜¯å¦èƒ½åˆå¹¶æ›´å¤šï¼‰
                if potential_duration >= self.min_duration_ms:
                    # ç»§ç»­å°è¯•åˆå¹¶ï¼Œç›´åˆ°è¾¾åˆ°åˆç†é•¿åº¦æˆ–æœ€å¤§æ—¶é•¿
                    j += 1
                    if j < len(blocks) and blocks[j][0]['speaker'] == current_speaker:
                        continue
                    else:
                        break
                else:
                    j += 1
            
            # æ·»åŠ åˆå¹¶åçš„å—ï¼ˆå¯èƒ½ä»ç„¶å¾ˆçŸ­ï¼Œä½†å·²ç»æ˜¯æœ€å¥½çš„ç»“æœï¼‰
            merged_blocks.append(merged)
            i = j  # è·³è¿‡å·²åˆå¹¶çš„å—
            
        return merged_blocks
    
    def _process_speaker_block(self, block: List[Dict]) -> Tuple[List[Dict], bool]:
        """å¤„ç†å•ä¸ªè¯´è¯äººå—ï¼šåˆå¹¶ -> æˆªæ–­ -> éªŒè¯æ—¶é•¿
        
        Returns:
            (final_sentences, should_keep): å¤„ç†åçš„å¥å­åˆ—è¡¨å’Œæ˜¯å¦ä¿ç•™çš„æ ‡å¿—
        """
        if not block:
            return [], False
            
        # 1. è®¡ç®—åˆå¹¶åçš„æ€»æ—¶é•¿
        total_duration = self._calculate_total_duration_with_gaps(block)
        
        self.logger.debug(f"ğŸ“Š å¤„ç†è¯´è¯äººå—: speaker='{block[0]['speaker']}', "
                         f"sentences={len(block)}, total_duration={total_duration}ms")
        
        # 2. å¦‚æœè¶…è¿‡æœ€å¤§æ—¶é•¿ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­
        if total_duration > self.max_duration_ms:
            self.logger.info(f"ğŸ“ å—æ—¶é•¿{total_duration}msè¶…è¿‡æœ€å¤§å€¼{self.max_duration_ms}msï¼Œæ‰§è¡Œæˆªæ–­")
            final_sentences = self._truncate_block_with_gaps(block)
        else:
            # å—å¤§å°åˆé€‚ï¼Œç›´æ¥ä½¿ç”¨
            final_sentences = block
        
        # 3. è®¡ç®—æˆªæ–­åçš„æœ€ç»ˆæ—¶é•¿
        final_duration = self._calculate_total_duration_with_gaps(final_sentences)
        
        # 4. æ›´å®½æ¾çš„ä¿ç•™ç­–ç•¥ï¼šåªä¸¢å¼ƒæçŸ­çš„å­¤ç«‹ç‰‡æ®µ
        # å¦‚æœæ˜¯å¤šå¥å­å—ï¼Œå³ä½¿ç•¥çŸ­ä¹Ÿä¿ç•™ï¼ˆå› ä¸ºå·²ç»å°è¯•è¿‡åˆå¹¶ï¼‰
        if len(final_sentences) > 1:
            # å¤šå¥å­å—æ›´å®½æ¾ï¼Œåªè¦è¶…è¿‡1000mså°±ä¿ç•™
            if final_duration < 1000:
                self.logger.warning(f"ğŸ—‘ï¸ ä¸¢å¼ƒæçŸ­å¤šå¥å—: speaker='{block[0]['speaker']}', "
                               f"sentences={len(final_sentences)}, duration={final_duration}ms < 1000ms")
                return final_sentences, False
        else:
            # å•å¥å­å—ä½¿ç”¨æ ‡å‡†é˜ˆå€¼
            if final_duration < self.min_duration_ms:
                self.logger.info(f"ğŸ—‘ï¸ ä¸¢å¼ƒè¿‡çŸ­å•å¥: speaker='{block[0]['speaker']}', "
                               f"sequence={final_sentences[0]['sequence']}, duration={final_duration}ms < {self.min_duration_ms}ms")
                return final_sentences, False
        
        self.logger.info(f"âœ… ä¿ç•™æœ‰æ•ˆç‰‡æ®µ: speaker='{block[0]['speaker']}', "
                        f"sentences={len(final_sentences)}, final_duration={final_duration}ms")
        return final_sentences, True
    
    def _create_audio_clips(self, transcripts: List[TranscriptItem]) -> Tuple[Dict, Dict]:
        """æ ¹æ®è½¬å½•æ•°æ®åˆ›å»ºéŸ³é¢‘åˆ‡ç‰‡è®¡åˆ’"""
        self.logger.info(f"ğŸ¬ å¼€å§‹å¤„ç† {len(transcripts)} ä¸ªè½¬å½•é¡¹")
        
        # åˆ†ææ—¶é—´æˆ³èŒƒå›´
        speech_items = [t for t in transcripts if t.content_type == 'speech']
        if speech_items:
            min_time = min(t.startMs for t in speech_items)
            max_time = max(t.endMs for t in speech_items)
            self.logger.info(f"ğŸ“Š è½¬å½•æ—¶é—´æˆ³èŒƒå›´: {min_time}ms - {max_time}ms ({(max_time-min_time)/1000:.1f}ç§’)")
        
        # ğŸ¯ ç²¾ç¡®æ—¶é—´æˆ³é¢„å¤„ç†ï¼šç›´æ¥ä½¿ç”¨è½¬å½•æ—¶é—´æˆ³ï¼Œæ— padding
        sentences = []
        for i, item in enumerate(transcripts):
            self.logger.debug(f"è½¬å½•é¡¹ {i}: sequence={item.sequence}, type={item.content_type}, "
                            f"start={item.startMs}ms, end={item.endMs}ms, speaker='{item.speaker}', "
                            f"text='{item.original[:50]}...'")
            
            if item.content_type != 'speech':
                self.logger.debug(f"  è·³è¿‡éè¯­éŸ³å†…å®¹: {item.content_type}")
                continue
            
            start_ms = item.startMs
            end_ms = item.endMs
            
            if start_ms >= end_ms:
                self.logger.warning(f"  æ—¶é—´èŒƒå›´æ— æ•ˆ: start={start_ms}ms >= end={end_ms}msï¼Œè·³è¿‡")
                continue
            
            # ğŸ¯ ç²¾ç¡®æ—¶é•¿è®¡ç®—ï¼Œæ— padding
            duration = end_ms - start_ms
            
            self.logger.debug(f"  ç²¾ç¡®æ—¶é—´: [{start_ms}-{end_ms}]ms ({duration}ms)")
            
            sentence_data = {
                'sequence': item.sequence,
                'speaker': item.speaker,
                'original': item.original,
                'translation': item.translation,
                'time_segment': [start_ms, end_ms],  # ç²¾ç¡®æ—¶é—´è¾¹ç•Œ
                'duration': duration                # ç²¾ç¡®æ—¶é•¿
            }
            
            if sentence_data['duration'] > 0:
                sentences.append(sentence_data)
                self.logger.debug(f"  âœ… æ·»åŠ æœ‰æ•ˆå¥å­: {duration}ms")
            else:
                self.logger.warning(f"  âŒ å¥å­æ—¶é•¿æ— æ•ˆ: {duration}ms")

        self.logger.info(f"ğŸ“ é¢„å¤„ç†å®Œæˆï¼Œè·å¾— {len(sentences)} ä¸ªæœ‰æ•ˆè¯­éŸ³å¥å­")
        if not sentences:
            self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³å¥å­ï¼Œè¿”å›ç©ºç»“æœ")
            return {}, {}

        # ğŸ”§ æ”¹è¿›çš„åˆ†ç»„ç­–ç•¥ï¼šæ›´å®½æ¾çš„è¿ç»­æ€§åˆ¤æ–­
        large_blocks = []
        if sentences:
            current_block = [sentences[0]]
            for i in range(1, len(sentences)):
                current_sentence = sentences[i]
                last_sentence = current_block[-1]
                
                # æ£€æŸ¥è¯´è¯äººæ˜¯å¦ç›¸åŒï¼ˆç§»é™¤ä¸¥æ ¼çš„åºåˆ—è¿ç»­æ€§è¦æ±‚ï¼‰
                same_speaker = current_sentence['speaker'] == last_sentence['speaker']
                # å…è®¸åºåˆ—å·æœ‰å°è·³è·ƒï¼ˆä¾‹å¦‚ä¸­é—´æœ‰non-speechè¢«è¿‡æ»¤ï¼‰
                sequence_gap = current_sentence['sequence'] - last_sentence['sequence']
                reasonable_gap = sequence_gap <= 3  # å…è®¸æœ€å¤šè·³è¿‡2ä¸ªåºå·
                
                if same_speaker and reasonable_gap:
                    current_block.append(current_sentence)
                else:
                    large_blocks.append(current_block)
                    current_block = [current_sentence]
            large_blocks.append(current_block)

        # ğŸµ æ™ºèƒ½åˆå¹¶ç­–ç•¥ï¼šç›¸é‚»åŒè¯´è¯äººçŸ­å—å°è¯•åˆå¹¶
        self.logger.info(f"ğŸ“‹ åˆå§‹åˆ†ç»„å®Œæˆï¼Œå…± {len(large_blocks)} ä¸ªå—")
        
        # æ˜¾ç¤ºåˆå§‹åˆ†ç»„æƒ…å†µ
        for i, block in enumerate(large_blocks):
            duration = self._calculate_total_duration_with_gaps(block)
            sequences = [s['sequence'] for s in block]
            self.logger.debug(f"  å—{i+1}: speaker={block[0]['speaker']}, "
                            f"sentences={len(block)}, duration={duration}ms, sequences={sequences}")
        
        # ğŸ”§ äºŒæ¬¡å¤„ç†ï¼šåˆå¹¶ç›¸é‚»çš„åŒè¯´è¯äººçŸ­å—
        optimized_blocks = self._merge_adjacent_short_blocks(large_blocks)
        self.logger.info(f"ğŸ”„ æ™ºèƒ½åˆå¹¶åï¼Œä¼˜åŒ–ä¸º {len(optimized_blocks)} ä¸ªå—")
        
        clips_library = {}
        sentence_to_clip_id_map = {}
        processed_count = 0
        kept_count = 0

        for block in optimized_blocks:
            processed_count += 1
            
            # å¤„ç†å½“å‰è¯´è¯äººå—ï¼šåˆå¹¶ -> æˆªæ–­ -> éªŒè¯
            final_sentences, should_keep = self._process_speaker_block(block)
            
            if not should_keep:
                # æ·»åŠ è¯¦ç»†ä¿¡æ¯å¸®åŠ©è°ƒè¯•
                sequences = [s['sequence'] for s in block]
                self.logger.warning(f"âš ï¸ å³ä½¿åˆå¹¶åä»ç„¶è¿‡çŸ­ï¼Œä¸¢å¼ƒå—: speaker={block[0]['speaker']}, "
                                  f"sentences={len(block)}, sequences={sequences}")
                continue  # åªæœ‰åœ¨å°è¯•åˆå¹¶åä»ç„¶è¿‡çŸ­æ‰ä¸¢å¼ƒ
                
            kept_count += 1
            
            # ğŸ¯ ä½¿ç”¨ç¬¬ä¸€ä¸ªå¥å­çš„åºå·ä½œä¸ºæ ‡è¯†ï¼ˆæ›´ç›´è§‚ï¼‰
            first_sequence = final_sentences[0]['sequence']
            clip_id = f"sequence_{first_sequence:04d}"
            
            # ğŸµ ç”Ÿæˆç²¾ç¡®éŸ³é¢‘æ®µåˆ—è¡¨ï¼ˆç”¨äºFFmpegå¤„ç†ï¼‰
            audio_segments = [s['time_segment'] for s in final_sentences]
            
            clips_library[clip_id] = {
                "speaker": final_sentences[0]['speaker'],
                "first_sequence": first_sequence,  # ç”¨äºæ–‡ä»¶å‘½å
                "total_duration_ms": self._calculate_total_duration_with_gaps(final_sentences),
                "audio_segments": audio_segments,  # ç²¾ç¡®éŸ³é¢‘æ®µï¼Œç”¨äºFFmpeg
                "gap_duration_ms": self.gap_duration_ms,  # gapä¿¡æ¯
                "sentences": [{
                    "sequence": s['sequence'], 
                    "original": s['original'], 
                    "translation": s['translation']
                } for s in final_sentences]
            }
            
            # æ˜ å°„sentenceåˆ°clipï¼ˆåªæ˜ å°„æœ€ç»ˆåŒ…å«çš„å¥å­ï¼‰
            for sentence in final_sentences:
                sentence_to_clip_id_map[sentence['sequence']] = clip_id
            
            self.logger.info(f"âœ… ç”Ÿæˆåˆ‡ç‰‡ {clip_id}: åºå·{first_sequence}å¼€å§‹, {len(final_sentences)}ä¸ªå¥å­, "
                           f"æ€»æ—¶é•¿{clips_library[clip_id]['total_duration_ms']}ms")
        
        self.logger.info(f"ğŸ¯ å¤„ç†å®Œæˆ: å¤„ç†{processed_count}ä¸ªå—ï¼Œä¿ç•™{kept_count}ä¸ªæœ‰æ•ˆç‰‡æ®µ")

        return clips_library, sentence_to_clip_id_map
    
    # _merge_overlapping_segmentsæ–¹æ³•å·²ç§»é™¤ - æ–°ç®—æ³•ä½¿ç”¨ç²¾ç¡®æ—¶é—´æ®µå’Œgapæœºåˆ¶
    
    async def extract_and_save_clips(self, audio_path: str, clips_library: Dict, 
                                    output_prefix: str, s3_client, bucket_name: str) -> List[AudioSegment]:
        """ä½¿ç”¨ffmpegç›´æ¥åˆ‡åˆ†éŸ³é¢‘ - é«˜æ€§èƒ½AACåŸç”Ÿæ”¯æŒ"""
        import subprocess
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        self.logger.info(f"éªŒè¯éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        file_size = os.path.getsize(audio_path)
        self.logger.info(f"éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        if file_size == 0:
            raise ValueError(f"éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {audio_path}")
        
        # æ£€æŸ¥ffmpegå¯ç”¨æ€§å’ŒéŸ³é¢‘ä¿¡æ¯
        try:
            # è·å–éŸ³é¢‘æ—¶é•¿ä¿¡æ¯
            probe_cmd = [
                'ffprobe', '-v', 'quiet', '-print_format', 'json', 
                '-show_format', '-show_streams', audio_path
            ]
            probe_result = await asyncio.to_thread(
                subprocess.run, probe_cmd, 
                capture_output=True, text=True, check=True
            )
            
            import json
            audio_info = json.loads(probe_result.stdout)
            duration_str = audio_info['format']['duration']
            total_duration_ms = int(float(duration_str) * 1000)
            
            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥clips_libraryçš„å®é™…å†…å®¹
            self.logger.info(f"ğŸ” è°ƒè¯•clips_libraryç»“æ„:")
            for clip_id, clip_info in clips_library.items():
                self.logger.info(f"  clip_id: {clip_id}")
                self.logger.info(f"  clip_info keys: {list(clip_info.keys())}")
                break  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªç”¨äºè°ƒè¯•
            
            # è·å–è½¬å½•æ—¶é—´æˆ³èŒƒå›´ç”¨äºæ—¶é—´è½´éªŒè¯
            speech_transcripts = [t for t in clips_library.values() if t.get('sentences')]
            if speech_transcripts:
                all_segments = []
                for clip_info in speech_transcripts:
                    # ğŸ” æ·»åŠ å®‰å…¨è®¿é—®å’Œè°ƒè¯•ä¿¡æ¯
                    if 'audio_segments' in clip_info:
                        all_segments.extend(clip_info['audio_segments'])
                    elif 'segments_to_concatenate' in clip_info:
                        self.logger.warning(f"ğŸš¨ å‘ç°æ—§å­—æ®µåsegments_to_concatenateï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼")
                        all_segments.extend(clip_info['segments_to_concatenate'])
                    else:
                        self.logger.error(f"âŒ clip_infoç¼ºå°‘éŸ³é¢‘æ®µæ•°æ®ï¼Œavailable keys: {list(clip_info.keys())}")
                        continue
                
                if all_segments:
                    transcript_start = min(seg[0] for seg in all_segments)
                    transcript_end = max(seg[1] for seg in all_segments)
                    transcript_duration = transcript_end - transcript_start
                    
                    self.logger.info(f"ğŸµ éŸ³é¢‘æ–‡ä»¶æ—¶é•¿: {total_duration_ms/1000:.1f}ç§’ ({total_duration_ms}ms)")
                    self.logger.info(f"ğŸ“ è½¬å½•æ—¶é—´æˆ³èŒƒå›´: {transcript_start}ms - {transcript_end}ms ({transcript_duration/1000:.1f}ç§’)")
                    
                    # æ—¶é—´è½´åç§»æ£€æµ‹
                    duration_diff = abs(total_duration_ms - transcript_duration) 
                    if duration_diff > 5000:  # è¶…è¿‡5ç§’å·®å¼‚
                        self.logger.warning(f"âš ï¸ æ—¶é—´è½´å¯èƒ½ä¸åŒ¹é…: éŸ³é¢‘={total_duration_ms/1000:.1f}s vs è½¬å½•={transcript_duration/1000:.1f}s, å·®å¼‚={duration_diff/1000:.1f}s")
                    
                    # æ£€æŸ¥è½¬å½•æ—¶é—´æˆ³æ˜¯å¦è¶…å‡ºéŸ³é¢‘èŒƒå›´
                    if transcript_end > total_duration_ms:
                        self.logger.error(f"âŒ è½¬å½•æ—¶é—´æˆ³è¶…å‡ºéŸ³é¢‘èŒƒå›´: {transcript_end}ms > {total_duration_ms}ms")
                        self.logger.error(f"   è¿™é€šå¸¸æ„å‘³ç€è½¬å½•åŸºäºè§†é¢‘æ—¶é—´è½´ï¼Œä½†éŸ³é¢‘åˆ†ç¦»åæ—¶é—´è½´å‘ç”Ÿåç§»")
                    
                    if transcript_start > total_duration_ms / 2:
                        self.logger.warning(f"âš ï¸ è½¬å½•å¼€å§‹æ—¶é—´è¾ƒæ™š: {transcript_start}msï¼Œå¯èƒ½å­˜åœ¨æ—¶é—´åç§»")
            
            self.logger.info(f"éŸ³é¢‘æ ¼å¼: {audio_info['format']['format_name']}")
            
        except Exception as e:
            self.logger.error(f"ffprobeéŸ³é¢‘ä¿¡æ¯è·å–å¤±è´¥: {e}")
            raise ValueError(f"æ— æ³•è§£æéŸ³é¢‘æ–‡ä»¶: {e}")
        
        segments = []
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åˆ‡ç‰‡ - ä½¿ç”¨ffmpegç›´æ¥åˆ‡åˆ†
        async def process_single_clip_with_ffmpeg(clip_id: str, clip_info: Dict) -> Optional[AudioSegment]:
            """ä½¿ç”¨ffmpegå¤„ç†å•ä¸ªåˆ‡ç‰‡"""
            try:
                # ğŸ¯ ä½¿ç”¨åºå·å‘½åæ–‡ä»¶ï¼ˆæ›´ç›´è§‚ï¼‰
                speaker_clean = clip_info['speaker'].replace(' ', '_').replace('/', '_')
                first_sequence = clip_info.get('first_sequence', 0)
                audio_key = f"{output_prefix}/{first_sequence:04d}_{speaker_clean}.wav"
                
                # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                    output_path = tmp_file.name
                
                try:
                    # ğŸµ æ–°çš„FFmpegå¤„ç†é€»è¾‘ - æ”¯æŒç²¾ç¡®æ—¶é—´æˆ³å’ŒGapæœºåˆ¶
                    # ğŸ” å…¼å®¹æ€§è®¿é—®audio_segmentså­—æ®µ
                    if 'audio_segments' in clip_info:
                        audio_segments = clip_info['audio_segments']
                    elif 'segments_to_concatenate' in clip_info:
                        self.logger.warning(f"ğŸš¨ åˆ‡ç‰‡{clip_id}ä½¿ç”¨æ—§å­—æ®µåsegments_to_concatenate")
                        audio_segments = clip_info['segments_to_concatenate']
                    else:
                        self.logger.error(f"âŒ åˆ‡ç‰‡{clip_id}ç¼ºå°‘éŸ³é¢‘æ®µæ•°æ®: {list(clip_info.keys())}")
                        return None
                    
                    gap_duration_ms = clip_info.get('gap_duration_ms', self.gap_duration_ms)
                    
                    if len(audio_segments) == 1:
                        # ğŸ¯ å•æ®µå¤„ç† - é«˜æ€§èƒ½æµå¤åˆ¶
                        start_ms, end_ms = audio_segments[0]
                        
                        # è¾¹ç•Œæ£€æŸ¥
                        start_ms = max(0, start_ms)
                        end_ms = min(total_duration_ms, end_ms)
                        duration_ms = end_ms - start_ms
                        
                        if duration_ms <= 0:
                            self.logger.warning(f"åˆ‡ç‰‡ {clip_id} æ—¶é•¿æ— æ•ˆï¼Œè·³è¿‡")
                            return None
                        
                        # è½¬æ¢ä¸ºffmpegæ—¶é—´æ ¼å¼
                        start_sec = start_ms / 1000.0
                        duration_sec = duration_ms / 1000.0
                        
                        # éªŒè¯æ—¶é—´èŒƒå›´
                        audio_duration_sec = total_duration_ms / 1000.0
                        self.logger.info(f"ğŸµ å•æ®µåˆ‡ç‰‡ {clip_id}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s (æ—¶é•¿: {duration_sec:.3f}s)")
                        
                        # ğŸš€ é«˜æ€§èƒ½å•æ®µåˆ‡å– - æ— fadeï¼Œçº¯æµå¤åˆ¶
                        ffmpeg_cmd = [
                            'ffmpeg', '-y',
                            '-ss', f'{start_sec:.3f}',  # å¿«é€Ÿseek
                            '-i', audio_path,
                            '-t', f'{duration_sec:.3f}',
                            '-c:a', 'copy',  # æµå¤åˆ¶ï¼Œä¿æŒåŸå§‹è´¨é‡
                            '-avoid_negative_ts', 'make_zero',
                            output_path
                        ]
                        
                        self.logger.info(f"ğŸ“ å•æ®µFFmpeg: {' '.join(ffmpeg_cmd)}")
                        
                    else:
                        # ğŸµ å¤šæ®µå¤„ç† - Gapé™éŸ³æ’å…¥ï¼Œæ— fade
                        input_specs = []
                        filter_parts = []
                        
                        # ä¸ºæ¯ä¸ªéŸ³é¢‘æ®µæ·»åŠ è¾“å…¥
                        for i, (start_ms, end_ms) in enumerate(audio_segments):
                            start_ms = max(0, start_ms)
                            end_ms = min(total_duration_ms, end_ms)
                            duration_ms = end_ms - start_ms
                            
                            if duration_ms <= 0:
                                continue
                                
                            start_sec = start_ms / 1000.0
                            duration_sec = duration_ms / 1000.0
                            
                            # æ·»åŠ éŸ³é¢‘æ®µè¾“å…¥
                            input_specs.extend(['-ss', f'{start_sec:.3f}', '-t', f'{duration_sec:.3f}', '-i', audio_path])
                            
                            self.logger.info(f"  æ®µ{i+1}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s ({duration_sec:.3f}s)")
                        
                        if not input_specs:
                            self.logger.warning(f"åˆ‡ç‰‡ {clip_id} æ— æœ‰æ•ˆéŸ³é¢‘æ®µï¼Œè·³è¿‡")
                            return None
                        
                        # ğŸµ æ„å»ºfilter_complex - Gapé™éŸ³æ’å…¥ï¼Œæ— fade
                        gap_sec = gap_duration_ms / 1000.0
                        
                        if len(audio_segments) == 1:
                            # å®é™…åªæœ‰ä¸€ä¸ªæœ‰æ•ˆæ®µï¼Œç›´æ¥è¾“å‡º
                            filter_complex = '[0:a]anull[out]'
                        else:
                            # å¤šæ®µæ‹¼æ¥ï¼Œæ’å…¥gapé™éŸ³
                            # ç”Ÿæˆgapé™éŸ³æº
                            gap_filter = f'anullsrc=channel_layout=mono:sample_rate=44100:duration={gap_sec:.3f}'
                            
                            # æ„å»ºæ‹¼æ¥åºåˆ—ï¼šéŸ³é¢‘1 + gap + éŸ³é¢‘2 + gap + éŸ³é¢‘3...
                            concat_parts = []
                            for i in range(len(audio_segments)):
                                concat_parts.append(f'[{i}:a]')  # éŸ³é¢‘æ®µ
                                if i < len(audio_segments) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ª
                                    concat_parts.append('[gap]')  # gapé™éŸ³
                            
                            filter_complex = f'{gap_filter}[gap];{"".join(concat_parts)}concat=n={len(concat_parts)}:v=0:a=1[out]'
                        
                        ffmpeg_cmd = ['ffmpeg', '-y'] + input_specs + [
                            '-filter_complex', filter_complex,
                            '-map', '[out]',
                            output_path
                        ]
                        
                        self.logger.info(f"ğŸµ å¤šæ®µåˆ‡ç‰‡ {clip_id}: {len(audio_segments)}æ®µ + {len(audio_segments)-1}ä¸ªGap({gap_sec:.3f}s)")
                        self.logger.info(f"ğŸ“ å¤šæ®µFFmpeg: {' '.join(ffmpeg_cmd[:10])}... (å…±{len(ffmpeg_cmd)}ä¸ªå‚æ•°)")
                    
                    # æ‰§è¡Œffmpegå‘½ä»¤
                    self.logger.info(f"ğŸš€ æ‰§è¡Œffmpegå¤„ç†åˆ‡ç‰‡ {clip_id}: {len(audio_segments)}æ®µ, è¯´è¯äºº={clip_info['speaker']}")
                    
                    result = await asyncio.to_thread(
                        subprocess.run, ffmpeg_cmd,
                        capture_output=True, text=True, check=True
                    )
                    
                    # è¯¦ç»†éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if not os.path.exists(output_path):
                        raise ValueError(f"ffmpegæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶: {output_path}")
                    
                    output_size = os.path.getsize(output_path)
                    if output_size == 0:
                        raise ValueError(f"ffmpegç”Ÿæˆç©ºæ–‡ä»¶: {output_path}")
                    
                    self.logger.info(f"âœ… æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_size} bytes")
                    
                    # ä¸Šä¼ åˆ°R2
                    with open(output_path, 'rb') as f:
                        s3_client.put_object(
                            Bucket=bucket_name,
                            Body=f,
                            Key=audio_key,
                            ContentType='audio/wav'
                        )
                    
                    self.logger.info(f"ğŸ“¤ å·²ä¸Šä¼ åˆ‡ç‰‡åˆ°R2: {audio_key}")
                    
                    # è¾“å‡ºffmpegçš„stderrç”¨äºè°ƒè¯•
                    if result.stderr:
                        self.logger.debug(f"ffmpeg stderr: {result.stderr}")
                    
                    # åˆ›å»ºsegmentå¯¹è±¡
                    segment_data = {
                        'segmentId': clip_id,
                        'audioKey': audio_key,
                        'speaker': clip_info['speaker'],
                        'startMs': audio_segments[0][0],
                        'endMs': audio_segments[-1][1],
                        'durationMs': clip_info['total_duration_ms'],
                        'sentences': clip_info['sentences']
                    }
                    return AudioSegment(**segment_data)
                    
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(output_path):
                        os.unlink(output_path)
                        
            except subprocess.CalledProcessError as e:
                self.logger.error(f"ffmpegå¤„ç†åˆ‡ç‰‡ {clip_id} å¤±è´¥: stderr={e.stderr}")
                return None
            except Exception as e:
                self.logger.error(f"å¤„ç†åˆ‡ç‰‡ {clip_id} å¼‚å¸¸: {e}")
                return None
        
        # ğŸš€ ä¼˜åŒ–ï¼šé™åˆ¶å¹¶å‘æ•°é‡ä»¥é¿å…CPUè¿‡è½½
        max_concurrent = min(3, len(clips_library))  # æœ€å¤š3ä¸ªå¹¶å‘ä»»åŠ¡
        self.logger.info(f"å¼€å§‹å¤„ç† {len(clips_library)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡ (å¹¶å‘æ•°: {max_concurrent})")
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_with_limit(clip_id, clip_info):
            async with semaphore:
                return await process_single_clip_with_ffmpeg(clip_id, clip_info)
        
        tasks = [process_with_limit(clip_id, clip_info) 
                for clip_id, clip_info in clips_library.items()]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æˆåŠŸçš„ç»“æœ
        for result in results:
            if isinstance(result, AudioSegment):
                segments.append(result)
            elif isinstance(result, Exception):
                self.logger.error(f"åˆ‡ç‰‡å¤„ç†å¼‚å¸¸: {result}")
        
        self.logger.info(f"ffmpegå¹¶è¡Œå¤„ç†å®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
        return segments


# åˆ›å»ºR2å®¢æˆ·ç«¯
def create_r2_client(config: R2Config):
    """åˆ›å»ºR2å®¢æˆ·ç«¯"""
    return boto3.client(
        's3',
        endpoint_url=f'https://{config.accountId}.r2.cloudflarestorage.com',
        aws_access_key_id=config.accessKeyId,
        aws_secret_access_key=config.secretAccessKey,
        region_name='auto'
    )


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "audio-segment-container",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@app.post("/segment", response_model=SegmentResponse)
async def segment_audio(request: SegmentRequest):
    """éŸ³é¢‘åˆ‡åˆ†æ¥å£"""
    logger.info(f"æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚: audioKey={request.audioKey}, transcripts={len(request.transcripts)}")
    
    # å·²ç§»é™¤æ€§èƒ½ä¼˜åŒ–å¼€å…³ - æ–°ç®—æ³•å·²å½»åº•ç§»é™¤fadeé€»è¾‘
    
    try:
        # åˆ›å»ºR2å®¢æˆ·ç«¯
        s3_client = create_r2_client(request.r2Config)
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•ååˆ›å»ºä¸´æ—¶æ–‡ä»¶
            original_ext = os.path.splitext(request.audioKey)[1] or '.aac'
            audio_path = Path(temp_dir) / f"input_audio{original_ext}"
            
            # ä»R2ä¸‹è½½éŸ³é¢‘
            try:
                logger.info(f"ä»R2ä¸‹è½½éŸ³é¢‘: {request.audioKey}")
                logger.info(f"ç›®æ ‡è·¯å¾„: {audio_path}")
                
                s3_client.download_file(
                    Bucket=request.r2Config.bucketName,
                    Key=request.audioKey,
                    Filename=str(audio_path)
                )
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                if not audio_path.exists():
                    raise FileNotFoundError(f"ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
                downloaded_size = audio_path.stat().st_size
                logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {downloaded_size} bytes")
                
                if downloaded_size == 0:
                    raise ValueError(f"ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {request.audioKey}")
                    
            except Exception as e:
                logger.error(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ {request.audioKey}: {e}")
            
            # ğŸµ åˆ›å»ºåˆ‡åˆ†å™¨ - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
            segmenter = AudioSegmenter()
            
            # ç”Ÿæˆåˆ‡ç‰‡è®¡åˆ’
            clips_library, sentence_to_clip_map = segmenter._create_audio_clips(request.transcripts)
            
            if not clips_library:
                return SegmentResponse(
                    success=True,
                    segments=[],
                    sentenceToSegmentMap={}
                )
            
            logger.info(f"ç”Ÿæˆäº† {len(clips_library)} ä¸ªåˆ‡ç‰‡è®¡åˆ’")
            
            # æå–å¹¶ä¿å­˜åˆ‡ç‰‡
            s3_client_for_upload = boto3.client(
                's3',
                endpoint_url=f'https://{request.r2Config.accountId}.r2.cloudflarestorage.com',
                aws_access_key_id=request.r2Config.accessKeyId,
                aws_secret_access_key=request.r2Config.secretAccessKey,
                region_name='auto'
            )
            
            segments = await segmenter.extract_and_save_clips(
                str(audio_path),
                clips_library,
                request.outputPrefix,
                s3_client_for_upload,
                request.r2Config.bucketName
            )
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
            
            return SegmentResponse(
                success=True,
                segments=segments,
                sentenceToSegmentMap=sentence_to_clip_map
            )
            
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: {e}", exc_info=True)
        # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_message = str(e)
        if hasattr(e, '__cause__') and e.__cause__:
            error_message += f" (åŸå› : {e.__cause__})"
        
        return SegmentResponse(
            success=False,
            error=f"{error_type}: {error_message}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)