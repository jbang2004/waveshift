#!/usr/bin/env python3
"""
éŸ³é¢‘åˆ‡åˆ†å®¹å™¨æœåŠ¡
åŸºäºè½¬å½•æ•°æ®å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œæ™ºèƒ½éŸ³é¢‘ç‰‡æ®µæå–
"""
import os
import re
import json
import asyncio
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timezone

import boto3
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# é…ç½®æ—¥å¿— - å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(title="Audio Segment Container")

# æ•°æ®æ¨¡å‹
class TranscriptItem(BaseModel):
    sequence: int
    startMs: int  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    endMs: int    # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    speaker: str
    original: str
    translation: Optional[str] = None
    content_type: str = 'speech'

class R2Config(BaseModel):
    accountId: str
    accessKeyId: str
    secretAccessKey: str
    bucketName: str
    publicDomain: str

class SegmentRequest(BaseModel):
    audioKey: str
    transcripts: List[TranscriptItem]
    outputPrefix: str
    r2Config: R2Config

class AudioSegment(BaseModel):
    segmentId: str
    audioKey: str
    speaker: str
    startMs: int
    endMs: int
    durationMs: int
    sentences: List[Dict]

class SegmentResponse(BaseModel):
    success: bool
    segments: Optional[List[AudioSegment]] = None
    sentenceToSegmentMap: Optional[Dict[int, str]] = None
    error: Optional[str] = None


class AudioSegmenter:
    """éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - åŸºäºç²¾ç¡®æ—¶é—´æˆ³å’ŒGapæœºåˆ¶çš„æ™ºèƒ½éŸ³é¢‘åˆ‡ç‰‡"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å‚æ•°
        self.gap_duration_ms = int(os.getenv('GAP_DURATION_MS', '500'))
        self.max_duration_ms = int(os.getenv('MAX_DURATION_MS', '12000'))  
        self.min_duration_ms = int(os.getenv('MIN_DURATION_MS', '1500'))  # æ”¹ä¸º1500ms
        
        self.logger = logger
        self.logger.info(f"ğŸµ AudioSegmenteråˆå§‹åŒ– - Gap:{self.gap_duration_ms}ms, "
                        f"Max:{self.max_duration_ms}ms, Min:{self.min_duration_ms}ms")
        
    # æ—¶é—´è½¬æ¢å‡½æ•°å·²ç§»é™¤ - ç›´æ¥ä½¿ç”¨æ¯«ç§’æ ¼å¼ï¼Œæ— éœ€è½¬æ¢
    
    def _calculate_total_duration_with_gaps(self, block: List[Dict]) -> int:
        """è®¡ç®—åŒ…å«gapçš„æ€»æ—¶é•¿"""
        if not block:
            return 0
        
        # éŸ³é¢‘æ€»æ—¶é•¿
        audio_duration = sum(s['duration'] for s in block)
        
        # Gapæ€»æ—¶é•¿ = (å¥å­æ•°é‡ - 1) * gap_duration_ms
        gap_duration = (len(block) - 1) * self.gap_duration_ms
        
        total = audio_duration + gap_duration
        self.logger.debug(f"æ—¶é•¿è®¡ç®—: éŸ³é¢‘{audio_duration}ms + Gap{gap_duration}ms = {total}ms")
        
        return total
    
    # _truncate_block_with_gapsæ–¹æ³•å·²ç§»é™¤ - æ–°ç®—æ³•ä½¿ç”¨ _split_long_group å®ç°æ›´ä¼˜é›…çš„åˆ†å‰²
    
    # _merge_adjacent_short_blocksæ–¹æ³•å·²ç§»é™¤ - æ–°ç®—æ³•åœ¨åˆ†ç»„é˜¶æ®µå°±æ— æ¡ä»¶åˆå¹¶äº†æ‰€æœ‰ç›¸é‚»åŒè¯´è¯äººç‰‡æ®µ
    
    # _process_speaker_blockæ–¹æ³•å·²ç§»é™¤ - æ–°ç®—æ³•é€šè¿‡ _process_speaker_groups ç»Ÿä¸€å¤„ç†
    
    def _create_audio_clips(self, transcripts: List[TranscriptItem]) -> Tuple[Dict, Dict]:
        """ä¼˜é›…çš„éŸ³é¢‘åˆ‡ç‰‡ç®—æ³•ï¼šå…ˆåˆå¹¶æ‰€æœ‰ç›¸é‚»åŒè¯´è¯äººç‰‡æ®µï¼Œå†æ™ºèƒ½åˆ†å‰²"""
        self.logger.info(f"ğŸ¬ å¼€å§‹å¤„ç† {len(transcripts)} ä¸ªè½¬å½•é¡¹")
        
        # Step 1: é¢„å¤„ç† - æå–æœ‰æ•ˆè¯­éŸ³å¥å­
        sentences = self._extract_speech_sentences(transcripts)
        
        if not sentences:
            self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³å¥å­ï¼Œè¿”å›ç©ºç»“æœ")
            return {}, {}
        
        # Step 2: æŒ‰è¯´è¯äººåˆ†ç»„ - æ— æ¡ä»¶åˆå¹¶æ‰€æœ‰ç›¸é‚»åŒè¯´è¯äººç‰‡æ®µ
        speaker_groups = self._group_by_speaker(sentences)
        
        # Step 3: å¤„ç†æ¯ä¸ªè¯´è¯äººç»„ - åˆ†å‰²é•¿ç»„ï¼Œä¿ç•™åˆç†ç»„
        final_clips = self._process_speaker_groups(speaker_groups)
        
        # Step 4: ç”Ÿæˆclipä¿¡æ¯å’Œå¥å­æ˜ å°„
        clips_library, sentence_to_clip_map = self._generate_clip_info(final_clips)
        
        return clips_library, sentence_to_clip_map
    
    def _extract_speech_sentences(self, transcripts: List[TranscriptItem]) -> List[Dict]:
        """æå–å’Œé¢„å¤„ç†æœ‰æ•ˆçš„è¯­éŸ³å¥å­"""
        sentences = []
        speech_items = [t for t in transcripts if t.content_type == 'speech']
        
        if speech_items:
            min_time = min(t.startMs for t in speech_items)
            max_time = max(t.endMs for t in speech_items)
            self.logger.info(f"ğŸ“Š è½¬å½•æ—¶é—´æˆ³èŒƒå›´: {min_time}ms - {max_time}ms ({(max_time-min_time)/1000:.1f}ç§’)")
        
        for i, item in enumerate(transcripts):
            if item.content_type != 'speech':
                continue
            
            if item.startMs >= item.endMs:
                self.logger.warning(f"æ—¶é—´èŒƒå›´æ— æ•ˆ: sequence={item.sequence}, start={item.startMs}ms >= end={item.endMs}ms")
                continue
            
            duration = item.endMs - item.startMs
            if duration <= 0:
                continue
                
            sentences.append({
                'sequence': item.sequence,
                'speaker': item.speaker,
                'original': item.original,
                'translation': item.translation,
                'time_segment': [item.startMs, item.endMs],
                'duration': duration
            })
        
        self.logger.info(f"ğŸ“ æå–åˆ° {len(sentences)} ä¸ªæœ‰æ•ˆè¯­éŸ³å¥å­")
        return sentences
    
    def _group_by_speaker(self, sentences: List[Dict]) -> List[List[Dict]]:
        """æŒ‰è¯´è¯äººåˆ†ç»„ï¼šåªè¦ç›¸é‚»ä¸”åŒè¯´è¯äººå°±æ— æ¡ä»¶åˆå¹¶"""
        if not sentences:
            return []
            
        speaker_groups = []
        current_group = [sentences[0]]
        
        for sentence in sentences[1:]:
            if sentence['speaker'] == current_group[-1]['speaker']:
                # åŒè¯´è¯äººï¼Œæ— æ¡ä»¶åˆå¹¶
                current_group.append(sentence)
            else:
                # è¯´è¯äººå˜åŒ–ï¼Œä¿å­˜å½“å‰ç»„ï¼Œå¼€å§‹æ–°ç»„
                speaker_groups.append(current_group)
                current_group = [sentence]
        
        # æ·»åŠ æœ€åä¸€ç»„
        speaker_groups.append(current_group)
        
        self.logger.info(f"ğŸ¯ æŒ‰è¯´è¯äººåˆ†ç»„å®Œæˆï¼Œå…± {len(speaker_groups)} ä¸ªç»„")
        for i, group in enumerate(speaker_groups):
            duration = self._calculate_total_duration_with_gaps(group)
            sequences = [s['sequence'] for s in group]
            self.logger.debug(f"  ç»„{i+1}: speaker={group[0]['speaker']}, "
                            f"sentences={len(group)}, duration={duration}ms, sequences={sequences}")
        
        return speaker_groups
    def _process_speaker_groups(self, speaker_groups: List[List[Dict]]) -> List[List[Dict]]:
        """å¤„ç†æ¯ä¸ªè¯´è¯äººç»„ï¼šåˆ†å‰²é•¿ç»„ï¼Œè¿‡æ»¤çŸ­ç»„"""
        final_clips = []
        
        for i, group in enumerate(speaker_groups):
            group_duration = self._calculate_total_duration_with_gaps(group)
            speaker = group[0]['speaker']
            
            self.logger.debug(f"å¤„ç†ç»„{i+1}: speaker={speaker}, "
                            f"sentences={len(group)}, duration={group_duration}ms")
            
            # å¦‚æœç»„å¤ªé•¿ï¼Œæ™ºèƒ½åˆ†å‰²
            if group_duration > self.max_duration_ms:
                sub_clips = self._split_long_group(group)
                self.logger.info(f"ğŸ“ åˆ†å‰²è¶…é•¿ç»„: speaker={speaker}, "
                               f"åŸå§‹{len(group)}å¥({group_duration}ms) â†’ {len(sub_clips)}ä¸ªç‰‡æ®µ")
            else:
                sub_clips = [group]
            
            # è¿‡æ»¤è¿‡çŸ­çš„ç‰‡æ®µ
            for clip in sub_clips:
                clip_duration = self._calculate_total_duration_with_gaps(clip)
                if self._should_keep_clip(clip, clip_duration):
                    final_clips.append(clip)
                    self.logger.debug(f"âœ… ä¿ç•™ç‰‡æ®µ: speaker={speaker}, "
                                     f"sentences={len(clip)}, duration={clip_duration}ms")
                else:
                    sequences = [s['sequence'] for s in clip]
                    self.logger.info(f"ğŸ—‘ï¸ ä¸¢å¼ƒè¿‡çŸ­ç‰‡æ®µ: speaker={speaker}, "
                                   f"sentences={len(clip)}, duration={clip_duration}ms, sequences={sequences}")
        
        self.logger.info(f"ğŸ¯ æœ€ç»ˆç”Ÿæˆ {len(final_clips)} ä¸ªæœ‰æ•ˆéŸ³é¢‘ç‰‡æ®µ")
        return final_clips
    
    def _split_long_group(self, group: List[Dict]) -> List[List[Dict]]:
        """æ™ºèƒ½åˆ†å‰²è¶…é•¿ç»„ï¼šè´ªå¿ƒç®—æ³•ï¼Œå°½å¯èƒ½å¤šåœ°åŒ…å«å¥å­"""
        clips = []
        current_clip = []
        
        for sentence in group:
            # å°è¯•æ·»åŠ å½“å‰å¥å­
            test_clip = current_clip + [sentence]
            test_duration = self._calculate_total_duration_with_gaps(test_clip)
            
            if test_duration <= self.max_duration_ms:
                # å¯ä»¥æ·»åŠ 
                current_clip = test_clip
            else:
                # ä¼šè¶…æ—¶ï¼Œä¿å­˜å½“å‰ç‰‡æ®µå¹¶å¼€å§‹æ–°ç‰‡æ®µ
                if current_clip:
                    clips.append(current_clip)
                current_clip = [sentence]
        
        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        if current_clip:
            clips.append(current_clip)
        
        return clips
    
    def _should_keep_clip(self, clip: List[Dict], duration: int) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¿ç•™éŸ³é¢‘ç‰‡æ®µï¼šå¤šå¥å­ç»„æ›´å®½æ¾"""
        if len(clip) > 1:
            # å¤šå¥å­ç‰‡æ®µæ›´å®½æ¾ï¼šåªè¦è¶…è¿‡1ç§’
            return duration >= 1000
        else:
            # å•å¥å­ç‰‡æ®µä½¿ç”¨æ ‡å‡†é˜ˆå€¼
            return duration >= self.min_duration_ms
    
    def _generate_clip_info(self, final_clips: List[List[Dict]]) -> Tuple[Dict, Dict]:
        """ç”Ÿæˆclipä¿¡æ¯å­—å…¸å’Œå¥å­æ˜ å°„"""
        clips_library = {}
        sentence_to_clip_map = {}
        
        for i, clip in enumerate(final_clips):
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¥å­çš„åºå·ä½œä¸ºæ ‡è¯†
            first_sequence = clip[0]['sequence']
            clip_id = f"sequence_{first_sequence:04d}"
            
            # ç”ŸæˆéŸ³é¢‘æ®µåˆ—è¡¨
            audio_segments = [s['time_segment'] for s in clip]
            
            clips_library[clip_id] = {
                "speaker": clip[0]['speaker'],
                "first_sequence": first_sequence,
                "total_duration_ms": self._calculate_total_duration_with_gaps(clip),
                "audio_segments": audio_segments,
                "gap_duration_ms": self.gap_duration_ms,
                "sentences": [{
                    "sequence": s['sequence'],
                    "original": s['original'],
                    "translation": s['translation']
                } for s in clip]
            }
            
            # æ˜ å°„æ¯ä¸ªå¥å­åˆ°å…¶æ‰€å±çš„clip
            for sentence in clip:
                sentence_to_clip_map[sentence['sequence']] = clip_id
            
            sequences = [s['sequence'] for s in clip]
            self.logger.info(f"âœ… ç”Ÿæˆåˆ‡ç‰‡ {clip_id}: speaker={clip[0]['speaker']}, "
                           f"sequences={sequences}, duration={clips_library[clip_id]['total_duration_ms']}ms")
        
        return clips_library, sentence_to_clip_map
    
    async def extract_and_save_clips(self, audio_path: str, clips_library: Dict, 
                                    output_prefix: str, s3_client, bucket_name: str) -> List[AudioSegment]:
        """ä½¿ç”¨ffmpegç›´æ¥åˆ‡åˆ†éŸ³é¢‘ - é«˜æ€§èƒ½AACåŸç”Ÿæ”¯æŒ"""
        import subprocess
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        self.logger.info(f"éªŒè¯éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        file_size = os.path.getsize(audio_path)
        self.logger.info(f"éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        if file_size == 0:
            raise ValueError(f"éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {audio_path}")
        
        # æ£€æŸ¥ffmpegå¯ç”¨æ€§å’ŒéŸ³é¢‘ä¿¡æ¯
        try:
            # è·å–éŸ³é¢‘æ—¶é•¿ä¿¡æ¯
            probe_cmd = [
                'ffprobe', '-v', 'quiet', '-print_format', 'json', 
                '-show_format', '-show_streams', audio_path
            ]
            probe_result = await asyncio.to_thread(
                subprocess.run, probe_cmd, 
                capture_output=True, text=True, check=True
            )
            
            import json
            audio_info = json.loads(probe_result.stdout)
            duration_str = audio_info['format']['duration']
            total_duration_ms = int(float(duration_str) * 1000)
            
            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥clips_libraryçš„å®é™…å†…å®¹
            self.logger.info(f"ğŸ” è°ƒè¯•clips_libraryç»“æ„:")
            for clip_id, clip_info in clips_library.items():
                self.logger.info(f"  clip_id: {clip_id}")
                self.logger.info(f"  clip_info keys: {list(clip_info.keys())}")
                break  # åªæ˜¾ç¤ºç¬¬ä¸€ä¸ªç”¨äºè°ƒè¯•
            
            # è·å–è½¬å½•æ—¶é—´æˆ³èŒƒå›´ç”¨äºæ—¶é—´è½´éªŒè¯
            speech_transcripts = [t for t in clips_library.values() if t.get('sentences')]
            if speech_transcripts:
                all_segments = []
                for clip_info in speech_transcripts:
                    # ğŸ” æ·»åŠ å®‰å…¨è®¿é—®å’Œè°ƒè¯•ä¿¡æ¯
                    if 'audio_segments' in clip_info:
                        all_segments.extend(clip_info['audio_segments'])
                    elif 'segments_to_concatenate' in clip_info:
                        self.logger.warning(f"ğŸš¨ å‘ç°æ—§å­—æ®µåsegments_to_concatenateï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼")
                        all_segments.extend(clip_info['segments_to_concatenate'])
                    else:
                        self.logger.error(f"âŒ clip_infoç¼ºå°‘éŸ³é¢‘æ®µæ•°æ®ï¼Œavailable keys: {list(clip_info.keys())}")
                        continue
                
                if all_segments:
                    transcript_start = min(seg[0] for seg in all_segments)
                    transcript_end = max(seg[1] for seg in all_segments)
                    transcript_duration = transcript_end - transcript_start
                    
                    self.logger.info(f"ğŸµ éŸ³é¢‘æ–‡ä»¶æ—¶é•¿: {total_duration_ms/1000:.1f}ç§’ ({total_duration_ms}ms)")
                    self.logger.info(f"ğŸ“ è½¬å½•æ—¶é—´æˆ³èŒƒå›´: {transcript_start}ms - {transcript_end}ms ({transcript_duration/1000:.1f}ç§’)")
                    
                    # æ—¶é—´è½´åç§»æ£€æµ‹
                    duration_diff = abs(total_duration_ms - transcript_duration) 
                    if duration_diff > 5000:  # è¶…è¿‡5ç§’å·®å¼‚
                        self.logger.warning(f"âš ï¸ æ—¶é—´è½´å¯èƒ½ä¸åŒ¹é…: éŸ³é¢‘={total_duration_ms/1000:.1f}s vs è½¬å½•={transcript_duration/1000:.1f}s, å·®å¼‚={duration_diff/1000:.1f}s")
                    
                    # æ£€æŸ¥è½¬å½•æ—¶é—´æˆ³æ˜¯å¦è¶…å‡ºéŸ³é¢‘èŒƒå›´
                    if transcript_end > total_duration_ms:
                        self.logger.error(f"âŒ è½¬å½•æ—¶é—´æˆ³è¶…å‡ºéŸ³é¢‘èŒƒå›´: {transcript_end}ms > {total_duration_ms}ms")
                        self.logger.error(f"   è¿™é€šå¸¸æ„å‘³ç€è½¬å½•åŸºäºè§†é¢‘æ—¶é—´è½´ï¼Œä½†éŸ³é¢‘åˆ†ç¦»åæ—¶é—´è½´å‘ç”Ÿåç§»")
                    
                    if transcript_start > total_duration_ms / 2:
                        self.logger.warning(f"âš ï¸ è½¬å½•å¼€å§‹æ—¶é—´è¾ƒæ™š: {transcript_start}msï¼Œå¯èƒ½å­˜åœ¨æ—¶é—´åç§»")
            
            self.logger.info(f"éŸ³é¢‘æ ¼å¼: {audio_info['format']['format_name']}")
            
        except Exception as e:
            self.logger.error(f"ffprobeéŸ³é¢‘ä¿¡æ¯è·å–å¤±è´¥: {e}")
            raise ValueError(f"æ— æ³•è§£æéŸ³é¢‘æ–‡ä»¶: {e}")
        
        segments = []
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åˆ‡ç‰‡ - ä½¿ç”¨ffmpegç›´æ¥åˆ‡åˆ†
        async def process_single_clip_with_ffmpeg(clip_id: str, clip_info: Dict) -> Optional[AudioSegment]:
            """ä½¿ç”¨ffmpegå¤„ç†å•ä¸ªåˆ‡ç‰‡"""
            try:
                # ğŸ¯ ä½¿ç”¨åºå·å‘½åæ–‡ä»¶ï¼ˆæ›´ç›´è§‚ï¼‰
                speaker_clean = clip_info['speaker'].replace(' ', '_').replace('/', '_')
                first_sequence = clip_info.get('first_sequence', 0)
                audio_key = f"{output_prefix}/{first_sequence:04d}_{speaker_clean}.wav"
                
                # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                    output_path = tmp_file.name
                
                try:
                    # ğŸµ æ–°çš„FFmpegå¤„ç†é€»è¾‘ - æ”¯æŒç²¾ç¡®æ—¶é—´æˆ³å’ŒGapæœºåˆ¶
                    # ğŸ” å…¼å®¹æ€§è®¿é—®audio_segmentså­—æ®µ
                    if 'audio_segments' in clip_info:
                        audio_segments = clip_info['audio_segments']
                    elif 'segments_to_concatenate' in clip_info:
                        self.logger.warning(f"ğŸš¨ åˆ‡ç‰‡{clip_id}ä½¿ç”¨æ—§å­—æ®µåsegments_to_concatenate")
                        audio_segments = clip_info['segments_to_concatenate']
                    else:
                        self.logger.error(f"âŒ åˆ‡ç‰‡{clip_id}ç¼ºå°‘éŸ³é¢‘æ®µæ•°æ®: {list(clip_info.keys())}")
                        return None
                    
                    gap_duration_ms = clip_info.get('gap_duration_ms', self.gap_duration_ms)
                    
                    if len(audio_segments) == 1:
                        # ğŸ¯ å•æ®µå¤„ç† - é«˜æ€§èƒ½æµå¤åˆ¶
                        start_ms, end_ms = audio_segments[0]
                        
                        # è¾¹ç•Œæ£€æŸ¥
                        start_ms = max(0, start_ms)
                        end_ms = min(total_duration_ms, end_ms)
                        duration_ms = end_ms - start_ms
                        
                        if duration_ms <= 0:
                            self.logger.warning(f"åˆ‡ç‰‡ {clip_id} æ—¶é•¿æ— æ•ˆï¼Œè·³è¿‡")
                            return None
                        
                        # è½¬æ¢ä¸ºffmpegæ—¶é—´æ ¼å¼
                        start_sec = start_ms / 1000.0
                        duration_sec = duration_ms / 1000.0
                        
                        # éªŒè¯æ—¶é—´èŒƒå›´
                        audio_duration_sec = total_duration_ms / 1000.0
                        self.logger.info(f"ğŸµ å•æ®µåˆ‡ç‰‡ {clip_id}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s (æ—¶é•¿: {duration_sec:.3f}s)")
                        
                        # ğŸš€ é«˜æ€§èƒ½å•æ®µåˆ‡å– - æ— fadeï¼Œçº¯æµå¤åˆ¶
                        ffmpeg_cmd = [
                            'ffmpeg', '-y',
                            '-ss', f'{start_sec:.3f}',  # å¿«é€Ÿseek
                            '-i', audio_path,
                            '-t', f'{duration_sec:.3f}',
                            '-c:a', 'copy',  # æµå¤åˆ¶ï¼Œä¿æŒåŸå§‹è´¨é‡
                            '-avoid_negative_ts', 'make_zero',
                            output_path
                        ]
                        
                        self.logger.info(f"ğŸ“ å•æ®µFFmpeg: {' '.join(ffmpeg_cmd)}")
                        
                    else:
                        # ğŸµ å¤šæ®µå¤„ç† - Gapé™éŸ³æ’å…¥ï¼Œæ— fade
                        input_specs = []
                        filter_parts = []
                        
                        # ä¸ºæ¯ä¸ªéŸ³é¢‘æ®µæ·»åŠ è¾“å…¥
                        for i, (start_ms, end_ms) in enumerate(audio_segments):
                            start_ms = max(0, start_ms)
                            end_ms = min(total_duration_ms, end_ms)
                            duration_ms = end_ms - start_ms
                            
                            if duration_ms <= 0:
                                continue
                                
                            start_sec = start_ms / 1000.0
                            duration_sec = duration_ms / 1000.0
                            
                            # æ·»åŠ éŸ³é¢‘æ®µè¾“å…¥
                            input_specs.extend(['-ss', f'{start_sec:.3f}', '-t', f'{duration_sec:.3f}', '-i', audio_path])
                            
                            self.logger.info(f"  æ®µ{i+1}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s ({duration_sec:.3f}s)")
                        
                        if not input_specs:
                            self.logger.warning(f"åˆ‡ç‰‡ {clip_id} æ— æœ‰æ•ˆéŸ³é¢‘æ®µï¼Œè·³è¿‡")
                            return None
                        
                        # ğŸµ æ„å»ºfilter_complex - Gapé™éŸ³æ’å…¥ï¼Œæ— fade
                        gap_sec = gap_duration_ms / 1000.0
                        
                        if len(audio_segments) == 1:
                            # å®é™…åªæœ‰ä¸€ä¸ªæœ‰æ•ˆæ®µï¼Œç›´æ¥è¾“å‡º
                            filter_complex = '[0:a]anull[out]'
                        else:
                            # å¤šæ®µæ‹¼æ¥ï¼Œæ’å…¥gapé™éŸ³
                            # ç”Ÿæˆgapé™éŸ³æº
                            gap_filter = f'anullsrc=channel_layout=mono:sample_rate=44100:duration={gap_sec:.3f}'
                            
                            # æ„å»ºæ‹¼æ¥åºåˆ—ï¼šéŸ³é¢‘1 + gap + éŸ³é¢‘2 + gap + éŸ³é¢‘3...
                            concat_parts = []
                            for i in range(len(audio_segments)):
                                concat_parts.append(f'[{i}:a]')  # éŸ³é¢‘æ®µ
                                if i < len(audio_segments) - 1:  # ä¸æ˜¯æœ€åä¸€ä¸ª
                                    concat_parts.append('[gap]')  # gapé™éŸ³
                            
                            filter_complex = f'{gap_filter}[gap];{"".join(concat_parts)}concat=n={len(concat_parts)}:v=0:a=1[out]'
                        
                        ffmpeg_cmd = ['ffmpeg', '-y'] + input_specs + [
                            '-filter_complex', filter_complex,
                            '-map', '[out]',
                            output_path
                        ]
                        
                        self.logger.info(f"ğŸµ å¤šæ®µåˆ‡ç‰‡ {clip_id}: {len(audio_segments)}æ®µ + {len(audio_segments)-1}ä¸ªGap({gap_sec:.3f}s)")
                        self.logger.info(f"ğŸ“ å¤šæ®µFFmpeg: {' '.join(ffmpeg_cmd[:10])}... (å…±{len(ffmpeg_cmd)}ä¸ªå‚æ•°)")
                    
                    # æ‰§è¡Œffmpegå‘½ä»¤
                    self.logger.info(f"ğŸš€ æ‰§è¡Œffmpegå¤„ç†åˆ‡ç‰‡ {clip_id}: {len(audio_segments)}æ®µ, è¯´è¯äºº={clip_info['speaker']}")
                    
                    result = await asyncio.to_thread(
                        subprocess.run, ffmpeg_cmd,
                        capture_output=True, text=True, check=True
                    )
                    
                    # è¯¦ç»†éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if not os.path.exists(output_path):
                        raise ValueError(f"ffmpegæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶: {output_path}")
                    
                    output_size = os.path.getsize(output_path)
                    if output_size == 0:
                        raise ValueError(f"ffmpegç”Ÿæˆç©ºæ–‡ä»¶: {output_path}")
                    
                    self.logger.info(f"âœ… æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_size} bytes")
                    
                    # ä¸Šä¼ åˆ°R2
                    with open(output_path, 'rb') as f:
                        s3_client.put_object(
                            Bucket=bucket_name,
                            Body=f,
                            Key=audio_key,
                            ContentType='audio/wav'
                        )
                    
                    self.logger.info(f"ğŸ“¤ å·²ä¸Šä¼ åˆ‡ç‰‡åˆ°R2: {audio_key}")
                    
                    # è¾“å‡ºffmpegçš„stderrç”¨äºè°ƒè¯•
                    if result.stderr:
                        self.logger.debug(f"ffmpeg stderr: {result.stderr}")
                    
                    # åˆ›å»ºsegmentå¯¹è±¡
                    segment_data = {
                        'segmentId': clip_id,
                        'audioKey': audio_key,
                        'speaker': clip_info['speaker'],
                        'startMs': audio_segments[0][0],
                        'endMs': audio_segments[-1][1],
                        'durationMs': clip_info['total_duration_ms'],
                        'sentences': clip_info['sentences']
                    }
                    return AudioSegment(**segment_data)
                    
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(output_path):
                        os.unlink(output_path)
                        
            except subprocess.CalledProcessError as e:
                self.logger.error(f"ffmpegå¤„ç†åˆ‡ç‰‡ {clip_id} å¤±è´¥: stderr={e.stderr}")
                return None
            except Exception as e:
                self.logger.error(f"å¤„ç†åˆ‡ç‰‡ {clip_id} å¼‚å¸¸: {e}")
                return None
        
        # ğŸš€ ä¼˜åŒ–ï¼šé™åˆ¶å¹¶å‘æ•°é‡ä»¥é¿å…CPUè¿‡è½½
        max_concurrent = min(3, len(clips_library))  # æœ€å¤š3ä¸ªå¹¶å‘ä»»åŠ¡
        self.logger.info(f"å¼€å§‹å¤„ç† {len(clips_library)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡ (å¹¶å‘æ•°: {max_concurrent})")
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_with_limit(clip_id, clip_info):
            async with semaphore:
                return await process_single_clip_with_ffmpeg(clip_id, clip_info)
        
        tasks = [process_with_limit(clip_id, clip_info) 
                for clip_id, clip_info in clips_library.items()]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æˆåŠŸçš„ç»“æœ
        for result in results:
            if isinstance(result, AudioSegment):
                segments.append(result)
            elif isinstance(result, Exception):
                self.logger.error(f"åˆ‡ç‰‡å¤„ç†å¼‚å¸¸: {result}")
        
        self.logger.info(f"ffmpegå¹¶è¡Œå¤„ç†å®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
        return segments


# åˆ›å»ºR2å®¢æˆ·ç«¯
def create_r2_client(config: R2Config):
    """åˆ›å»ºR2å®¢æˆ·ç«¯"""
    return boto3.client(
        's3',
        endpoint_url=f'https://{config.accountId}.r2.cloudflarestorage.com',
        aws_access_key_id=config.accessKeyId,
        aws_secret_access_key=config.secretAccessKey,
        region_name='auto'
    )


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "audio-segment-container",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@app.post("/segment", response_model=SegmentResponse)
async def segment_audio(request: SegmentRequest):
    """éŸ³é¢‘åˆ‡åˆ†æ¥å£"""
    logger.info(f"æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚: audioKey={request.audioKey}, transcripts={len(request.transcripts)}")
    
    # å·²ç§»é™¤æ€§èƒ½ä¼˜åŒ–å¼€å…³ - æ–°ç®—æ³•å·²å½»åº•ç§»é™¤fadeé€»è¾‘
    
    try:
        # åˆ›å»ºR2å®¢æˆ·ç«¯
        s3_client = create_r2_client(request.r2Config)
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•ååˆ›å»ºä¸´æ—¶æ–‡ä»¶
            original_ext = os.path.splitext(request.audioKey)[1] or '.aac'
            audio_path = Path(temp_dir) / f"input_audio{original_ext}"
            
            # ä»R2ä¸‹è½½éŸ³é¢‘
            try:
                logger.info(f"ä»R2ä¸‹è½½éŸ³é¢‘: {request.audioKey}")
                logger.info(f"ç›®æ ‡è·¯å¾„: {audio_path}")
                
                s3_client.download_file(
                    Bucket=request.r2Config.bucketName,
                    Key=request.audioKey,
                    Filename=str(audio_path)
                )
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                if not audio_path.exists():
                    raise FileNotFoundError(f"ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
                downloaded_size = audio_path.stat().st_size
                logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {downloaded_size} bytes")
                
                if downloaded_size == 0:
                    raise ValueError(f"ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {request.audioKey}")
                    
            except Exception as e:
                logger.error(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ {request.audioKey}: {e}")
            
            # ğŸµ åˆ›å»ºåˆ‡åˆ†å™¨ - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
            segmenter = AudioSegmenter()
            
            # ç”Ÿæˆåˆ‡ç‰‡è®¡åˆ’
            clips_library, sentence_to_clip_map = segmenter._create_audio_clips(request.transcripts)
            
            if not clips_library:
                return SegmentResponse(
                    success=True,
                    segments=[],
                    sentenceToSegmentMap={}
                )
            
            logger.info(f"ç”Ÿæˆäº† {len(clips_library)} ä¸ªåˆ‡ç‰‡è®¡åˆ’")
            
            # æå–å¹¶ä¿å­˜åˆ‡ç‰‡
            s3_client_for_upload = boto3.client(
                's3',
                endpoint_url=f'https://{request.r2Config.accountId}.r2.cloudflarestorage.com',
                aws_access_key_id=request.r2Config.accessKeyId,
                aws_secret_access_key=request.r2Config.secretAccessKey,
                region_name='auto'
            )
            
            segments = await segmenter.extract_and_save_clips(
                str(audio_path),
                clips_library,
                request.outputPrefix,
                s3_client_for_upload,
                request.r2Config.bucketName
            )
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
            
            return SegmentResponse(
                success=True,
                segments=segments,
                sentenceToSegmentMap=sentence_to_clip_map
            )
            
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: {e}", exc_info=True)
        # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_message = str(e)
        if hasattr(e, '__cause__') and e.__cause__:
            error_message += f" (åŸå› : {e.__cause__})"
        
        return SegmentResponse(
            success=False,
            error=f"{error_type}: {error_message}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)