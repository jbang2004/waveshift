#!/usr/bin/env python3
"""
éŸ³é¢‘åˆ‡åˆ†å®¹å™¨æœåŠ¡
åŸºäºè½¬å½•æ•°æ®å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œæ™ºèƒ½éŸ³é¢‘ç‰‡æ®µæå–
"""
import os
import asyncio
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timezone

import boto3
from fastapi import FastAPI
from pydantic import BaseModel

# é…ç½®æ—¥å¿— - å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(title="Audio Segment Container")

# æ•°æ®æ¨¡å‹
class TranscriptItem(BaseModel):
    sequence: int
    startMs: int  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    endMs: int    # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    speaker: str
    original: str
    translation: Optional[str] = None
    content_type: str = 'speech'

class R2Config(BaseModel):
    accountId: str
    accessKeyId: str
    secretAccessKey: str
    bucketName: str
    publicDomain: str

class AudioSegmentConfig(BaseModel):
    """éŸ³é¢‘åˆ‡åˆ†é…ç½®å‚æ•°"""
    gapDurationMs: int = 500
    maxDurationMs: int = 12000
    minDurationMs: int = 1000
    gapThresholdMultiplier: int = 3

class SegmentRequest(BaseModel):
    audioKey: str
    transcripts: List[TranscriptItem]
    outputPrefix: str
    r2Config: R2Config
    segmentConfig: Optional[AudioSegmentConfig] = None

class AudioSegment(BaseModel):
    segmentId: str
    audioKey: str
    speaker: str
    startMs: int
    endMs: int
    durationMs: int
    sentences: List[Dict]

class SegmentResponse(BaseModel):
    success: bool
    segments: Optional[List[AudioSegment]] = None
    sentenceToSegmentMap: Optional[Dict[int, str]] = None
    error: Optional[str] = None


from enum import Enum
from typing import Optional, NamedTuple

class AccumulatorState(Enum):
    ACCUMULATING = "accumulating"      # æ­£åœ¨ç´¯ç§¯sentences

class BreakDecision(NamedTuple):
    should_break: bool
    reason: str

class StreamingAccumulator:
    """æµå¼ç´¯ç§¯å™¨ï¼šç»´æŠ¤å½“å‰éŸ³é¢‘ç‰‡æ®µçš„å¤„ç†çŠ¶æ€"""
    def __init__(self, first_sentence: Dict):
        self.speaker = first_sentence['speaker']
        self.time_ranges = [[first_sentence['startMs'], first_sentence['endMs']]]
        self.pending_sentences = [first_sentence]
        self.sequence_start = first_sentence['sequence']
        self.state = AccumulatorState.ACCUMULATING
        # éŸ³é¢‘å¤ç”¨å­—æ®µ
        self.generated_audio_key: Optional[str] = None
        self.is_audio_generated: bool = False
        
        
    def get_total_duration(self, gap_duration_ms: int) -> int:
        """è®¡ç®—ç´¯ç§¯å™¨çš„æ€»æ—¶é•¿ï¼ˆåŒ…å«gapsï¼‰"""
        audio_duration = sum(end - start for start, end in self.time_ranges)
        gap_count = max(0, len(self.time_ranges) - 1)
        return audio_duration + (gap_count * gap_duration_ms)
        
    def add_sentence(self, sentence: Dict, gap_threshold_ms: int):
        """æ·»åŠ å¥å­åˆ°ç´¯ç§¯å™¨ï¼Œæ™ºèƒ½å¤„ç†æ—¶é—´èŒƒå›´"""
        if self.state != AccumulatorState.ACCUMULATING:
            raise ValueError("Cannot add sentence to non-accumulating accumulator")
            
        # æ£€æŸ¥é—´éš”å¹¶å†³å®šå¦‚ä½•åˆå¹¶æ—¶é—´èŒƒå›´
        last_end = self.time_ranges[-1][1]
        gap = sentence['startMs'] - last_end
        
        if gap <= gap_threshold_ms:
            # å°é—´éš”ï¼šæ‰©å±•æœ€åä¸€ä¸ªæ—¶é—´èŒƒå›´
            self.time_ranges[-1][1] = sentence['endMs']
        else:
            # å¤§é—´éš”ï¼šæ·»åŠ æ–°æ—¶é—´èŒƒå›´
            self.time_ranges.append([sentence['startMs'], sentence['endMs']])
            
        self.pending_sentences.append(sentence)
    
    def can_reuse_audio(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å·²ç”Ÿæˆçš„éŸ³é¢‘"""
        return (self.state == AccumulatorState.ACCUMULATING and 
                self.is_audio_generated and 
                self.generated_audio_key is not None)


class SegmentationDecision:
    """éŸ³é¢‘åˆ‡åˆ†å†³ç­–é€»è¾‘"""
    
    @staticmethod
    def should_break_accumulation(accumulator: StreamingAccumulator, sentence: Dict) -> BreakDecision:
        """ç»Ÿä¸€çš„ç´¯ç§¯ä¸­æ–­å†³ç­–"""
        if not accumulator:
            return BreakDecision(False, "no_accumulator")
            
        # è¯´è¯äººå˜åŒ–
        if sentence['speaker'] != accumulator.speaker:
            return BreakDecision(True, "speaker_change")
                
        return BreakDecision(False, "continue_accumulation")


class AudioSegmenter:
    """éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - æµå¼å¤„ç†çš„æ™ºèƒ½éŸ³é¢‘åˆ‡ç‰‡"""
    
    def __init__(self, config: Optional[AudioSegmentConfig] = None):
        # ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„é…ç½®å‚æ•°ï¼Œå¦åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–
        if config:
            self.gap_duration_ms = config.gapDurationMs
            self.max_duration_ms = config.maxDurationMs  
            self.min_duration_ms = config.minDurationMs
            self.gap_threshold_multiplier = config.gapThresholdMultiplier
        else:
            # ç¯å¢ƒå˜é‡å›é€€ï¼ˆæ›´æ–°é»˜è®¤å€¼ï¼‰
            self.gap_duration_ms = int(os.getenv('GAP_DURATION_MS', '500'))
            self.max_duration_ms = int(os.getenv('MAX_DURATION_MS', '12000'))  
            self.min_duration_ms = int(os.getenv('MIN_DURATION_MS', '1000'))  # âœ… æ›´æ–°é»˜è®¤å€¼
            self.gap_threshold_multiplier = int(os.getenv('GAP_THRESHOLD_MULTIPLIER', '3'))
            
        self.gap_threshold_ms = self.gap_duration_ms * self.gap_threshold_multiplier
        
        self.logger = logger
        self.logger.info(f"ğŸµ AudioSegmenteråˆå§‹åŒ– - Gap:{self.gap_duration_ms}ms, "
                        f"Max:{self.max_duration_ms}ms, Min:{self.min_duration_ms}ms, "
                        f"GapThreshold:{self.gap_threshold_ms}ms")
        
    async def process_sentences_streaming(self, transcripts: List[TranscriptItem], 
                                        audio_path: str, output_prefix: str, 
                                        s3_client, bucket_name: str) -> Tuple[List[AudioSegment], Dict[int, str]]:
        """æµå¼å¤„ç†ï¼šä¸€æ¬¡éå†ï¼Œå®æ—¶å†³ç­–ï¼Œç«‹å³ä¸Šä¼ """
        segments = []
        sentence_to_segment_map = {}
        accumulator = None
        
        # æå–æœ‰æ•ˆè¯­éŸ³å¥å­ï¼ˆç›´æ¥ä½¿ç”¨TranscriptItemï¼Œé¿å…ä¸å¿…è¦è½¬æ¢ï¼‰
        valid_sentences = [item for item in transcripts 
                          if item.content_type == 'speech' and item.startMs < item.endMs]
        
        self.logger.info(f"ğŸ¬ å¼€å§‹æµå¼å¤„ç† {len(valid_sentences)} ä¸ªè¯­éŸ³å¥å­")
        
        for sentence in valid_sentences:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å‘å°„å½“å‰ç´¯ç§¯å™¨
            decision = SegmentationDecision.should_break_accumulation(
                accumulator, self._sentence_to_dict(sentence)
            )
            
            if decision.should_break:
                await self._process_and_add_segment(
                    accumulator, segments, sentence_to_segment_map, 
                    audio_path, output_prefix, s3_client, bucket_name
                )
                accumulator = None
            
            # æ·»åŠ å½“å‰å¥å­åˆ°ç´¯ç§¯å™¨
            if not accumulator:
                accumulator = StreamingAccumulator(self._sentence_to_dict(sentence))
            else:
                # æ£€æŸ¥æ˜¯å¦å¯ä»¥å¤ç”¨å·²ç”Ÿæˆçš„éŸ³é¢‘
                if accumulator.can_reuse_audio():
                    # å¤ç”¨ç°æœ‰éŸ³é¢‘ï¼šç›´æ¥ä¸ºå½“å‰å¥å­åˆ›å»ºæ˜ å°„ï¼Œæ— éœ€é‡æ–°ç”ŸæˆéŸ³é¢‘
                    current_sentence = self._sentence_to_dict(sentence)
                    audio_key = accumulator.generated_audio_key
                    segment_id = audio_key.split('/')[-1].replace('.wav', '') if audio_key else None
                    
                    if segment_id:
                        sentence_to_segment_map[current_sentence['sequence']] = segment_id
                        self.logger.info(f"ğŸ”„ å¤ç”¨éŸ³é¢‘: segment_id={segment_id}, "
                                       f"å¥å­{current_sentence['sequence']}ç›´æ¥æ˜ å°„")
                else:
                    # æ­£å¸¸æ·»åŠ å¥å­åˆ°ç´¯ç§¯å™¨
                    accumulator.add_sentence(self._sentence_to_dict(sentence), self.gap_threshold_ms)
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è½½å¹¶ç”ŸæˆéŸ³é¢‘ï¼ˆä¿æŒaccumulatorä»¥ä¾›å¤ç”¨ï¼‰
            if self._is_accumulator_full(accumulator):
                await self._process_and_add_segment(
                    accumulator, segments, sentence_to_segment_map, 
                    audio_path, output_prefix, s3_client, bucket_name
                )
                # æ³¨æ„ï¼šä¸å†é‡ç½®accumulatorï¼Œä¿æŒä»¥ä¾›åŒè¯´è¯äººå¥å­å¤ç”¨
        
        # å¤„ç†æœ€åçš„ç´¯ç§¯å™¨
        if accumulator and accumulator.pending_sentences:
            await self._process_and_add_segment(
                accumulator, segments, sentence_to_segment_map, 
                audio_path, output_prefix, s3_client, bucket_name
            )
        
        self.logger.info(f"âœ… æµå¼å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
        return segments, sentence_to_segment_map
    
    def _sentence_to_dict(self, item: TranscriptItem) -> Dict:
        """è½¬æ¢TranscriptItemä¸ºå­—å…¸ï¼ˆä»…åœ¨éœ€è¦æ—¶è½¬æ¢ï¼‰"""
        return {
            'sequence': item.sequence,
            'speaker': item.speaker,
            'original': item.original,
            'translation': item.translation,
            'startMs': item.startMs,
            'endMs': item.endMs,
            'duration': item.endMs - item.startMs
        }
    
    async def _process_and_add_segment(self, accumulator: StreamingAccumulator, 
                                     segments: List, sentence_map: Dict[int, str],
                                     audio_path: str, output_prefix: str, 
                                     s3_client, bucket_name: str) -> None:
        """ç»Ÿä¸€çš„accumulatorå¤„ç†é€»è¾‘ï¼šå®Œæˆã€æ·»åŠ åˆ°segmentsã€æ›´æ–°mapping"""
        if not accumulator:
            return
            
        segment = await self._finalize_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
        if segment:
            segments.append(segment)
            self._update_sentence_mapping(accumulator, segment.segmentId, sentence_map)
    
    def _update_sentence_mapping(self, accumulator: StreamingAccumulator, segment_id: str, 
                                sentence_map: Dict[int, str]):
        """ç»Ÿä¸€çš„å¥å­æ˜ å°„æ›´æ–°é€»è¾‘"""
        for sentence in accumulator.pending_sentences:
            sentence_map[sentence['sequence']] = segment_id
    
    def _is_accumulator_full(self, accumulator: StreamingAccumulator) -> bool:
        """æ£€æŸ¥ç´¯ç§¯å™¨æ˜¯å¦æ»¡è½½ä¸”éœ€è¦å¤„ç†"""
        if not accumulator or accumulator.state != AccumulatorState.ACCUMULATING:
            return False
        
        # å¦‚æœæœªè¾¾åˆ°æœ€å¤§æ—¶é•¿ï¼Œç»§ç»­ç´¯ç§¯
        if accumulator.get_total_duration(self.gap_duration_ms) < self.max_duration_ms:
            return False
            
        # å¦‚æœè¾¾åˆ°æœ€å¤§æ—¶é•¿ä½†è¿˜æ²¡ç”ŸæˆéŸ³é¢‘ï¼Œéœ€è¦å¤„ç†ï¼ˆç”ŸæˆéŸ³é¢‘ï¼‰
        if not accumulator.is_audio_generated:
            return True
            
        # å¦‚æœå·²ç”ŸæˆéŸ³é¢‘ï¼Œå¯ä»¥ç»§ç»­å¤ç”¨ï¼Œä¸éœ€è¦å¤„ç†
        return False
    
    def _reuse_existing_audio(self, accumulator: StreamingAccumulator, 
                            sentence_map: Dict[int, str]) -> None:
        """å¤ç”¨å·²ç”Ÿæˆçš„éŸ³é¢‘ï¼Œæ›´æ–°å¥å­æ˜ å°„å…³ç³»"""
        if not accumulator.can_reuse_audio():
            return
            
        # ä»generated_audio_keyæå–segment_idï¼ˆå»æ‰è·¯å¾„å‰ç¼€ï¼‰
        audio_key = accumulator.generated_audio_key
        segment_id = audio_key.split('/')[-1].replace('.wav', '') if audio_key else None
        
        if segment_id:
            # æ›´æ–°æ˜ å°„å…³ç³»ï¼šå°†å½“å‰å¥å­æ˜ å°„åˆ°å·²ç”Ÿæˆçš„segment
            for sentence in accumulator.pending_sentences:
                sentence_map[sentence['sequence']] = segment_id
                
            self.logger.info(f"ğŸ”„ å¤ç”¨éŸ³é¢‘: segment_id={segment_id}, "
                           f"æ–°å¢{len(accumulator.pending_sentences)}ä¸ªå¥å­æ˜ å°„")
    
    async def _finalize_accumulator(self, accumulator: StreamingAccumulator, 
                                   audio_path: str, output_prefix: str, 
                                   s3_client, bucket_name: str) -> Optional[AudioSegment]:
        """å®Œæˆç´¯ç§¯å™¨ï¼šç”ŸæˆéŸ³é¢‘å¹¶ä¸Šä¼ """
        if not accumulator or not accumulator.pending_sentences:
            return None
        
        # æ£€æŸ¥æœ€å°æ—¶é•¿
        total_duration = accumulator.get_total_duration(self.gap_duration_ms)
        if len(accumulator.pending_sentences) == 1 and total_duration < self.min_duration_ms:
            sentence_details = [(s['sequence'], s['startMs'], s['endMs'], s['endMs']-s['startMs']) 
                               for s in accumulator.pending_sentences]
            self.logger.warning(f"ğŸ—‘ï¸ ä¸¢å¼ƒè¿‡çŸ­å•å¥ç‰‡æ®µ: speaker={accumulator.speaker}, "
                              f"è®¡ç®—æ—¶é•¿={total_duration}ms < æœ€å°æ—¶é•¿={self.min_duration_ms}ms, "
                              f"å¥å­è¯¦æƒ…(sequence,start,end,å®é™…æ—¶é•¿)={sentence_details}")
            return None
        
        # ç”Ÿæˆclipä¿¡æ¯
        clip_id = f"sequence_{accumulator.sequence_start:04d}"
        audio_key = f"{output_prefix}/{clip_id}_{accumulator.speaker}.wav"
        
        self.logger.info(f"ğŸµ å®ŒæˆéŸ³é¢‘ç‰‡æ®µ {clip_id}: speaker={accumulator.speaker}, "
                        f"ranges={len(accumulator.time_ranges)}, sentences={len(accumulator.pending_sentences)}, "
                        f"duration={total_duration}ms")
        
        # ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘
        success = await self._process_audio_with_ffmpeg(
            audio_path, accumulator.time_ranges, audio_key, s3_client, bucket_name
        )
        
        if not success:
            return None
        
        # æ ‡è®°éŸ³é¢‘å·²ç”Ÿæˆï¼Œæ”¯æŒåç»­å¤ç”¨
        accumulator.generated_audio_key = audio_key
        accumulator.is_audio_generated = True
        
        # åˆ›å»ºsegmentå¯¹è±¡
        return AudioSegment(
            segmentId=clip_id,
            audioKey=audio_key,
            speaker=accumulator.speaker,
            startMs=accumulator.time_ranges[0][0],
            endMs=accumulator.time_ranges[-1][1],
            durationMs=total_duration,
            sentences=[{
                'sequence': s['sequence'],
                'original': s['original'],
                'translation': s.get('translation')
            } for s in accumulator.pending_sentences]
        )
    
    async def _process_audio_with_ffmpeg(self, audio_path: str, time_ranges: List[List[int]], 
                                       audio_key: str, s3_client, bucket_name: str) -> bool:
        """ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘å¹¶ä¸Šä¼ åˆ°R2"""
        import subprocess
        import tempfile
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            output_path = tmp_file.name
        
        try:
            if len(time_ranges) == 1:
                # ğŸ¯ å•æ®µå¤„ç† - é«˜æ€§èƒ½æµå¤åˆ¶
                start_ms, end_ms = time_ranges[0]
                start_sec = start_ms / 1000.0
                duration_sec = (end_ms - start_ms) / 1000.0
                
                ffmpeg_cmd = [
                    'ffmpeg', '-y',
                    '-ss', f'{start_sec:.3f}',
                    '-i', audio_path,
                    '-t', f'{duration_sec:.3f}',
                    '-c:a', 'copy',
                    '-avoid_negative_ts', 'make_zero',
                    output_path
                ]
                
                self.logger.info(f"ğŸ“ å•æ®µFFmpeg: {' '.join(ffmpeg_cmd)}")
                
            else:
                # ğŸµ å¤šæ®µå¤„ç† - Gapé™éŸ³æ’å…¥
                input_specs = []
                
                # ä¸ºæ¯ä¸ªéŸ³é¢‘æ®µæ·»åŠ è¾“å…¥
                for i, (start_ms, end_ms) in enumerate(time_ranges):
                    start_sec = start_ms / 1000.0
                    duration_sec = (end_ms - start_ms) / 1000.0
                    
                    input_specs.extend(['-ss', f'{start_sec:.3f}', '-t', f'{duration_sec:.3f}', '-i', audio_path])
                    
                    self.logger.info(f"  æ®µ{i+1}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s ({duration_sec:.3f}s)")
                
                # æ„å»ºfilter_complex - Gapé™éŸ³æ’å…¥
                gap_sec = self.gap_duration_ms / 1000.0
                gap_filter = f'anullsrc=channel_layout=mono:sample_rate=44100:duration={gap_sec:.3f}'
                
                # æ„å»ºæ‹¼æ¥åºåˆ—ï¼šéŸ³é¢‘1 + gap + éŸ³é¢‘2 + gap + éŸ³é¢‘3...
                concat_parts = []
                for i in range(len(time_ranges)):
                    concat_parts.append(f'[{i}:a]')
                    if i < len(time_ranges) - 1:
                        concat_parts.append('[gap]')
                
                filter_complex = f'{gap_filter}[gap];{"".join(concat_parts)}concat=n={len(concat_parts)}:v=0:a=1[out]'
                
                ffmpeg_cmd = ['ffmpeg', '-y'] + input_specs + [
                    '-filter_complex', filter_complex,
                    '-map', '[out]',
                    output_path
                ]
                
                self.logger.info(f"ğŸµ å¤šæ®µå¤„ç†: {len(time_ranges)}æ®µ + {len(time_ranges)-1}ä¸ªGap({gap_sec:.3f}s)")
            
            # æ‰§è¡Œffmpegå‘½ä»¤
            await asyncio.to_thread(
                subprocess.run, ffmpeg_cmd,
                capture_output=True, text=True, check=True
            )
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
                self.logger.error(f"FFmpegæœªç”Ÿæˆæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
                return False
            
            # ä¸Šä¼ åˆ°R2
            with open(output_path, 'rb') as f:
                s3_client.put_object(
                    Bucket=bucket_name,
                    Body=f,
                    Key=audio_key,
                    ContentType='audio/wav'
                )
            
            self.logger.info(f"ğŸ“¤ å·²ä¸Šä¼ éŸ³é¢‘åˆ°R2: {audio_key}")
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"FFmpegå¤„ç†å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            self.logger.error(f"å¤„ç†éŸ³é¢‘å¼‚å¸¸: {e}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(output_path):
                os.unlink(output_path)
    
    # æ‰€æœ‰æ—§çš„å¤„ç†é€»è¾‘å·²ç§»é™¤ï¼Œä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
    # åŸæœ‰æ–¹æ³•ï¼š
    # - _calculate_total_duration_with_gaps
    # - _create_audio_clips
    # - _extract_speech_sentences
    # - _group_by_speaker
    # - _process_speaker_groups
    # - _split_long_group
    # - _should_keep_clip
    # - _generate_clip_info
    # å·²å…¨éƒ¨è¢«æµå¼å¤„ç†æ–¹æ³•å–ä»£


# åˆ›å»ºR2å®¢æˆ·ç«¯
def create_r2_client(config: R2Config):
    """åˆ›å»ºR2å®¢æˆ·ç«¯"""
    return boto3.client(
        's3',
        endpoint_url=f'https://{config.accountId}.r2.cloudflarestorage.com',
        aws_access_key_id=config.accessKeyId,
        aws_secret_access_key=config.secretAccessKey,
        region_name='auto'
    )


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "audio-segment-container",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@app.post("/segment", response_model=SegmentResponse)
async def segment_audio(request: SegmentRequest):
    """éŸ³é¢‘åˆ‡åˆ†æ¥å£"""
    logger.info(f"æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚: audioKey={request.audioKey}, transcripts={len(request.transcripts)}")
    
    # å·²ç§»é™¤æ€§èƒ½ä¼˜åŒ–å¼€å…³ - æ–°ç®—æ³•å·²å½»åº•ç§»é™¤fadeé€»è¾‘
    
    try:
        # åˆ›å»ºR2å®¢æˆ·ç«¯
        s3_client = create_r2_client(request.r2Config)
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•ååˆ›å»ºä¸´æ—¶æ–‡ä»¶
            original_ext = os.path.splitext(request.audioKey)[1] or '.aac'
            audio_path = Path(temp_dir) / f"input_audio{original_ext}"
            
            # ä»R2ä¸‹è½½éŸ³é¢‘
            try:
                logger.info(f"ä»R2ä¸‹è½½éŸ³é¢‘: {request.audioKey}")
                logger.info(f"ç›®æ ‡è·¯å¾„: {audio_path}")
                
                s3_client.download_file(
                    Bucket=request.r2Config.bucketName,
                    Key=request.audioKey,
                    Filename=str(audio_path)
                )
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                if not audio_path.exists():
                    raise FileNotFoundError(f"ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
                downloaded_size = audio_path.stat().st_size
                logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {downloaded_size} bytes")
                
                if downloaded_size == 0:
                    raise ValueError(f"ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {request.audioKey}")
                    
            except Exception as e:
                logger.error(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ {request.audioKey}: {e}")
            
            # ğŸµ åˆ›å»ºåˆ‡åˆ†å™¨ - ä½¿ç”¨è¯·æ±‚å‚æ•°é…ç½®ï¼ˆä¼˜å…ˆï¼‰æˆ–ç¯å¢ƒå˜é‡
            segmenter = AudioSegmenter(request.segmentConfig)
            
            # ğŸš€ ä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
            s3_client_for_upload = boto3.client(
                's3',
                endpoint_url=f'https://{request.r2Config.accountId}.r2.cloudflarestorage.com',
                aws_access_key_id=request.r2Config.accessKeyId,
                aws_secret_access_key=request.r2Config.secretAccessKey,
                region_name='auto'
            )
            
            segments, sentence_to_segment_map = await segmenter.process_sentences_streaming(
                request.transcripts,
                str(audio_path),
                request.outputPrefix,
                s3_client_for_upload,
                request.r2Config.bucketName
            )
            
            if not segments:
                return SegmentResponse(
                    success=True,
                    segments=[],
                    sentenceToSegmentMap={}
                )
            
            logger.info(f"âœ… æµå¼å¤„ç†æˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
            
            return SegmentResponse(
                success=True,
                segments=segments,
                sentenceToSegmentMap=sentence_to_segment_map
            )
            
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: {e}", exc_info=True)
        # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_message = str(e)
        if hasattr(e, '__cause__') and e.__cause__:
            error_message += f" (åŸå› : {e.__cause__})"
        
        return SegmentResponse(
            success=False,
            error=f"{error_type}: {error_message}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)