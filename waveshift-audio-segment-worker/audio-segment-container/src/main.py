#!/usr/bin/env python3
"""
éŸ³é¢‘åˆ‡åˆ†å®¹å™¨æœåŠ¡
åŸºäºè½¬å½•æ•°æ®å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œæ™ºèƒ½éŸ³é¢‘ç‰‡æ®µæå–
"""
import os
import re
import json
import asyncio
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timezone

import boto3
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# é…ç½®æ—¥å¿— - å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(title="Audio Segment Container")

# æ•°æ®æ¨¡å‹
class TranscriptItem(BaseModel):
    sequence: int
    startMs: int  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    endMs: int    # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    speaker: str
    original: str
    translation: Optional[str] = None
    content_type: str = 'speech'

class R2Config(BaseModel):
    accountId: str
    accessKeyId: str
    secretAccessKey: str
    bucketName: str
    publicDomain: str

class SegmentRequest(BaseModel):
    audioKey: str
    transcripts: List[TranscriptItem]
    goalDurationMs: int = 10000  # é»˜è®¤10ç§’
    minDurationMs: int = 3000    # é»˜è®¤3ç§’
    paddingMs: int = 500         # é»˜è®¤500ms
    outputPrefix: str
    r2Config: R2Config

class AudioSegment(BaseModel):
    segmentId: str
    audioKey: str
    speaker: str
    startMs: int
    endMs: int
    durationMs: int
    sentences: List[Dict]

class SegmentResponse(BaseModel):
    success: bool
    segments: Optional[List[AudioSegment]] = None
    sentenceToSegmentMap: Optional[Dict[int, str]] = None
    error: Optional[str] = None


class AudioSegmenter:
    """éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - åŸºäºè¯´è¯äººåˆ†ç»„çš„æ™ºèƒ½éŸ³é¢‘åˆ‡ç‰‡"""
    
    def __init__(self, goal_duration_ms: int, min_duration_ms: int, padding_ms: int):
        self.goal_duration_ms = goal_duration_ms
        self.min_duration_ms = min_duration_ms
        self.padding_ms = padding_ms
        self.logger = logger
        
    # æ—¶é—´è½¬æ¢å‡½æ•°å·²ç§»é™¤ - ç›´æ¥ä½¿ç”¨æ¯«ç§’æ ¼å¼ï¼Œæ— éœ€è½¬æ¢
    
    def _create_audio_clips(self, transcripts: List[TranscriptItem]) -> Tuple[Dict, Dict]:
        """æ ¹æ®è½¬å½•æ•°æ®åˆ›å»ºéŸ³é¢‘åˆ‡ç‰‡è®¡åˆ’"""
        self.logger.info(f"ğŸ¬ å¼€å§‹å¤„ç† {len(transcripts)} ä¸ªè½¬å½•é¡¹")
        
        # åˆ†ææ—¶é—´æˆ³èŒƒå›´
        speech_items = [t for t in transcripts if t.content_type == 'speech']
        if speech_items:
            min_time = min(t.startMs for t in speech_items)
            max_time = max(t.endMs for t in speech_items)
            self.logger.info(f"ğŸ“Š è½¬å½•æ—¶é—´æˆ³èŒƒå›´: {min_time}ms - {max_time}ms ({(max_time-min_time)/1000:.1f}ç§’)")
        
        # é¢„å¤„ç†ï¼šåªå¤„ç†speechç±»å‹çš„å†…å®¹
        sentences = []
        for i, item in enumerate(transcripts):
            self.logger.debug(f"è½¬å½•é¡¹ {i}: sequence={item.sequence}, type={item.content_type}, "
                            f"start={item.startMs}ms, end={item.endMs}ms, speaker='{item.speaker}', "
                            f"text='{item.original[:50]}...'")
            
            if item.content_type != 'speech':
                self.logger.debug(f"  è·³è¿‡éè¯­éŸ³å†…å®¹: {item.content_type}")
                continue
            
            start_ms = item.startMs
            end_ms = item.endMs
            
            if start_ms >= end_ms:
                self.logger.warning(f"  æ—¶é—´èŒƒå›´æ— æ•ˆ: start={start_ms}ms >= end={end_ms}msï¼Œè·³è¿‡")
                continue
            
            # æ·»åŠ padding
            padded_start = max(0, start_ms - self.padding_ms)
            padded_end = end_ms + self.padding_ms
            duration = padded_end - padded_start
            
            self.logger.debug(f"  æ—¶é—´è®¡ç®—: åŸå§‹[{start_ms}-{end_ms}]ms ({end_ms-start_ms}ms), "
                            f"padding[{padded_start}-{padded_end}]ms ({duration}ms)")
            
            sentence_data = {
                'sequence': item.sequence,
                'speaker': item.speaker,
                'original': item.original,
                'translation': item.translation,
                'original_segment': [start_ms, end_ms],
                'padded_segment': [padded_start, padded_end],
                'segment_duration': duration
            }
            
            if sentence_data['segment_duration'] > 0:
                sentences.append(sentence_data)
                self.logger.debug(f"  âœ… æ·»åŠ æœ‰æ•ˆå¥å­: {duration}ms")
            else:
                self.logger.warning(f"  âŒ å¥å­æ—¶é•¿æ— æ•ˆ: {duration}ms")

        self.logger.info(f"ğŸ“ é¢„å¤„ç†å®Œæˆï¼Œè·å¾— {len(sentences)} ä¸ªæœ‰æ•ˆè¯­éŸ³å¥å­")
        if not sentences:
            self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„è¯­éŸ³å¥å­ï¼Œè¿”å›ç©ºç»“æœ")
            return {}, {}

        # è¯†åˆ«åŒè¯´è¯äººè¿ç»­å—
        large_blocks = []
        if sentences:
            current_block = [sentences[0]]
            for i in range(1, len(sentences)):
                current_sentence = sentences[i]
                last_sentence = current_block[-1]
                
                # æ£€æŸ¥è¯´è¯äººæ˜¯å¦ç›¸åŒä¸”åºåˆ—è¿ç»­
                same_speaker = current_sentence['speaker'] == last_sentence['speaker']
                continuous = current_sentence['sequence'] == last_sentence['sequence'] + 1
                
                if same_speaker and continuous:
                    current_block.append(current_sentence)
                else:
                    large_blocks.append(current_block)
                    current_block = [current_sentence]
            large_blocks.append(current_block)

        # ç”Ÿæˆåˆ‡ç‰‡
        clips_library = {}
        sentence_to_clip_id_map = {}
        clip_id_counter = 0

        for block in large_blocks:
            block_total_duration = sum(s['segment_duration'] for s in block)
            
            # åªå¤„ç†æ€»æ—¶é•¿å¤§äºç­‰äºmin_duration_msçš„å—
            if block_total_duration >= self.min_duration_ms:
                clip_id_counter += 1
                clip_id = f"segment_{clip_id_counter:04d}"
                
                # å¦‚æœæ€»æ—¶é•¿è¶…è¿‡goal_duration_msï¼Œéœ€è¦æˆªå–
                if block_total_duration > self.goal_duration_ms:
                    accumulated_duration = 0
                    sentences_to_include = []
                    
                    for sentence in block:
                        if accumulated_duration + sentence['segment_duration'] <= self.goal_duration_ms:
                            sentences_to_include.append(sentence)
                            accumulated_duration += sentence['segment_duration']
                        else:
                            # æ·»åŠ éƒ¨åˆ†å¥å­
                            remaining_duration = self.goal_duration_ms - accumulated_duration
                            if remaining_duration > 0:
                                truncated_sentence = sentence.copy()
                                truncated_sentence['segment_duration'] = remaining_duration
                                start_time = truncated_sentence['padded_segment'][0]
                                truncated_sentence['padded_segment'] = [start_time, start_time + remaining_duration]
                                sentences_to_include.append(truncated_sentence)
                            break
                    
                    final_sentences = sentences_to_include
                else:
                    final_sentences = block
                
                # åˆå¹¶é‡å çš„segments
                merged_segments = self._merge_overlapping_segments(final_sentences)
                
                clips_library[clip_id] = {
                    "speaker": block[0]['speaker'],
                    "total_duration_ms": sum(end - start for start, end in merged_segments),
                    "segments_to_concatenate": merged_segments,
                    "sentences": [{
                        "sequence": s['sequence'], 
                        "original": s['original'], 
                        "translation": s['translation']
                    } for s in final_sentences]
                }
                
                # æ˜ å°„sentenceåˆ°clip
                for sentence in block:
                    sentence_to_clip_id_map[sentence['sequence']] = clip_id

        return clips_library, sentence_to_clip_id_map
    
    def _merge_overlapping_segments(self, block: List[Dict]) -> List[List[int]]:
        """åˆå¹¶é‡å çš„segments"""
        if not block:
            return []
        
        segments = [s['padded_segment'] for s in block]
        segments.sort(key=lambda x: x[0])
        
        merged = [segments[0]]
        for current in segments[1:]:
            last = merged[-1]
            
            if current[0] <= last[1]:
                merged[-1] = [last[0], max(last[1], current[1])]
            else:
                merged.append(current)
        
        return merged
    
    async def extract_and_save_clips(self, audio_path: str, clips_library: Dict, 
                                    output_prefix: str, s3_client, bucket_name: str) -> List[AudioSegment]:
        """ä½¿ç”¨ffmpegç›´æ¥åˆ‡åˆ†éŸ³é¢‘ - é«˜æ€§èƒ½AACåŸç”Ÿæ”¯æŒ"""
        import subprocess
        
        # éªŒè¯éŸ³é¢‘æ–‡ä»¶
        self.logger.info(f"éªŒè¯éŸ³é¢‘æ–‡ä»¶: {audio_path}")
        if not os.path.exists(audio_path):
            raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
        
        file_size = os.path.getsize(audio_path)
        self.logger.info(f"éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} bytes")
        
        if file_size == 0:
            raise ValueError(f"éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {audio_path}")
        
        # æ£€æŸ¥ffmpegå¯ç”¨æ€§å’ŒéŸ³é¢‘ä¿¡æ¯
        try:
            # è·å–éŸ³é¢‘æ—¶é•¿ä¿¡æ¯
            probe_cmd = [
                'ffprobe', '-v', 'quiet', '-print_format', 'json', 
                '-show_format', '-show_streams', audio_path
            ]
            probe_result = await asyncio.to_thread(
                subprocess.run, probe_cmd, 
                capture_output=True, text=True, check=True
            )
            
            import json
            audio_info = json.loads(probe_result.stdout)
            duration_str = audio_info['format']['duration']
            total_duration_ms = int(float(duration_str) * 1000)
            
            # è·å–è½¬å½•æ—¶é—´æˆ³èŒƒå›´ç”¨äºæ—¶é—´è½´éªŒè¯
            speech_transcripts = [t for t in clips_library.values() if t.get('sentences')]
            if speech_transcripts:
                all_segments = []
                for clip_info in speech_transcripts:
                    all_segments.extend(clip_info['segments_to_concatenate'])
                
                if all_segments:
                    transcript_start = min(seg[0] for seg in all_segments)
                    transcript_end = max(seg[1] for seg in all_segments)
                    transcript_duration = transcript_end - transcript_start
                    
                    self.logger.info(f"ğŸµ éŸ³é¢‘æ–‡ä»¶æ—¶é•¿: {total_duration_ms/1000:.1f}ç§’ ({total_duration_ms}ms)")
                    self.logger.info(f"ğŸ“ è½¬å½•æ—¶é—´æˆ³èŒƒå›´: {transcript_start}ms - {transcript_end}ms ({transcript_duration/1000:.1f}ç§’)")
                    
                    # æ—¶é—´è½´åç§»æ£€æµ‹
                    duration_diff = abs(total_duration_ms - transcript_duration) 
                    if duration_diff > 5000:  # è¶…è¿‡5ç§’å·®å¼‚
                        self.logger.warning(f"âš ï¸ æ—¶é—´è½´å¯èƒ½ä¸åŒ¹é…: éŸ³é¢‘={total_duration_ms/1000:.1f}s vs è½¬å½•={transcript_duration/1000:.1f}s, å·®å¼‚={duration_diff/1000:.1f}s")
                    
                    # æ£€æŸ¥è½¬å½•æ—¶é—´æˆ³æ˜¯å¦è¶…å‡ºéŸ³é¢‘èŒƒå›´
                    if transcript_end > total_duration_ms:
                        self.logger.error(f"âŒ è½¬å½•æ—¶é—´æˆ³è¶…å‡ºéŸ³é¢‘èŒƒå›´: {transcript_end}ms > {total_duration_ms}ms")
                        self.logger.error(f"   è¿™é€šå¸¸æ„å‘³ç€è½¬å½•åŸºäºè§†é¢‘æ—¶é—´è½´ï¼Œä½†éŸ³é¢‘åˆ†ç¦»åæ—¶é—´è½´å‘ç”Ÿåç§»")
                    
                    if transcript_start > total_duration_ms / 2:
                        self.logger.warning(f"âš ï¸ è½¬å½•å¼€å§‹æ—¶é—´è¾ƒæ™š: {transcript_start}msï¼Œå¯èƒ½å­˜åœ¨æ—¶é—´åç§»")
            
            self.logger.info(f"éŸ³é¢‘æ ¼å¼: {audio_info['format']['format_name']}")
            
        except Exception as e:
            self.logger.error(f"ffprobeéŸ³é¢‘ä¿¡æ¯è·å–å¤±è´¥: {e}")
            raise ValueError(f"æ— æ³•è§£æéŸ³é¢‘æ–‡ä»¶: {e}")
        
        segments = []
        
        # å¹¶è¡Œå¤„ç†æ‰€æœ‰åˆ‡ç‰‡ - ä½¿ç”¨ffmpegç›´æ¥åˆ‡åˆ†
        async def process_single_clip_with_ffmpeg(clip_id: str, clip_info: Dict) -> Optional[AudioSegment]:
            """ä½¿ç”¨ffmpegå¤„ç†å•ä¸ªåˆ‡ç‰‡"""
            try:
                speaker_clean = clip_info['speaker'].replace(' ', '_').replace('/', '_')
                audio_key = f"{output_prefix}/{clip_id}_{speaker_clean}.wav"
                
                # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
                    output_path = tmp_file.name
                
                try:
                    # æ„å»ºffmpegå‘½ä»¤ - æ”¯æŒå¤šæ®µåˆ‡åˆ†å’Œåˆå¹¶
                    segments_to_concat = clip_info['segments_to_concatenate']
                    
                    if len(segments_to_concat) == 1:
                        # å•æ®µåˆ‡åˆ† - ç®€å•æƒ…å†µ
                        start_ms, end_ms = segments_to_concat[0]
                        
                        # è¾¹ç•Œæ£€æŸ¥
                        start_ms = max(0, start_ms)
                        end_ms = min(total_duration_ms, end_ms)
                        duration_ms = end_ms - start_ms
                        
                        if duration_ms <= 0:
                            self.logger.warning(f"åˆ‡ç‰‡ {clip_id} æ—¶é•¿æ— æ•ˆï¼Œè·³è¿‡")
                            return None
                        
                        # è½¬æ¢ä¸ºffmpegæ—¶é—´æ ¼å¼
                        start_sec = start_ms / 1000.0
                        duration_sec = duration_ms / 1000.0
                        end_sec = start_sec + duration_sec
                        
                        # éªŒè¯æ—¶é—´èŒƒå›´
                        audio_duration_sec = total_duration_ms / 1000.0
                        self.logger.info(f"ğŸµ åˆ‡ç‰‡ {clip_id}: æ—¶é—´èŒƒå›´æ£€æŸ¥")
                        self.logger.info(f"  éŸ³é¢‘æ€»é•¿åº¦: {audio_duration_sec:.3f}s ({total_duration_ms}ms)")
                        self.logger.info(f"  åˆ‡åˆ†èŒƒå›´: {start_sec:.3f}s - {end_sec:.3f}s (æ—¶é•¿: {duration_sec:.3f}s)")
                        self.logger.info(f"  åŸå§‹æ—¶é—´æˆ³: {start_ms}ms - {end_ms}ms")
                        
                        # è¾¹ç•Œè­¦å‘Š
                        if start_sec >= audio_duration_sec:
                            self.logger.warning(f"âš ï¸ å¼€å§‹æ—¶é—´è¶…å‡ºéŸ³é¢‘é•¿åº¦: {start_sec:.3f}s >= {audio_duration_sec:.3f}s")
                        if end_sec > audio_duration_sec:
                            self.logger.warning(f"âš ï¸ ç»“æŸæ—¶é—´è¶…å‡ºéŸ³é¢‘é•¿åº¦: {end_sec:.3f}s > {audio_duration_sec:.3f}sï¼Œå°†æˆªå–")
                        
                        # ğŸš€ ä¼˜åŒ–ï¼šä½¿ç”¨stream copyé¿å…é‡ç¼–ç 
                        # åªåœ¨å¿…è¦æ—¶åº”ç”¨éŸ³é¢‘æ»¤é•œ
                        use_filters = getattr(self, 'use_audio_filters', False)
                        
                        if use_filters:
                            # å¸¦æ»¤é•œçš„å¤„ç†ï¼ˆè¾ƒæ…¢ï¼‰
                            fade_duration = min(self.padding_ms / 1000.0, 0.5)
                            ffmpeg_cmd = [
                                'ffmpeg', '-y',
                                '-i', audio_path,
                                '-ss', f'{start_sec:.3f}',
                                '-t', f'{duration_sec:.3f}',
                                '-af', f'afade=in:d={fade_duration:.3f},afade=out:d={fade_duration:.3f}',
                                '-c:a', 'aac',  # ä¿æŒAACæ ¼å¼
                                '-b:a', '128k',  # åˆç†çš„æ¯”ç‰¹ç‡
                                output_path
                            ]
                        else:
                            # ğŸš€ å¿«é€Ÿæ¨¡å¼ï¼šæµå¤åˆ¶ï¼Œä¸é‡ç¼–ç 
                            ffmpeg_cmd = [
                                'ffmpeg', '-y',
                                '-ss', f'{start_sec:.3f}',  # æ”¾åœ¨-iå‰é¢ï¼Œä½¿ç”¨å¿«é€Ÿseek
                                '-i', audio_path,
                                '-t', f'{duration_sec:.3f}',
                                '-c:a', 'copy',  # ç›´æ¥å¤åˆ¶éŸ³é¢‘æµï¼Œä¸é‡ç¼–ç 
                                '-avoid_negative_ts', 'make_zero',  # é¿å…æ—¶é—´æˆ³é—®é¢˜
                                output_path
                            ]
                        
                        self.logger.info(f"ğŸ“ ffmpegå‘½ä»¤: {' '.join(ffmpeg_cmd)}")
                        
                    else:
                        # å¤šæ®µåˆå¹¶ - å¤æ‚æƒ…å†µï¼Œä½¿ç”¨filter_complex
                        filter_parts = []
                        input_specs = []
                        
                        for i, (start_ms, end_ms) in enumerate(segments_to_concat):
                            start_ms = max(0, start_ms)
                            end_ms = min(total_duration_ms, end_ms)
                            duration_ms = end_ms - start_ms
                            
                            if duration_ms <= 0:
                                continue
                                
                            start_sec = start_ms / 1000.0
                            duration_sec = duration_ms / 1000.0
                            
                            # ä¸ºæ¯ä¸ªæ®µæ·»åŠ è¾“å…¥
                            input_specs.extend(['-ss', f'{start_sec:.3f}', '-t', f'{duration_sec:.3f}', '-i', audio_path])
                            
                            # ä¸ºæ¯ä¸ªæ®µæ·»åŠ éŸ³é¢‘å¤„ç†
                            fade_duration = min(self.padding_ms / 1000.0, 0.2)
                            if i == 0:
                                # ç¬¬ä¸€æ®µï¼šæ·¡å…¥
                                filter_parts.append(f'[{i}:a]afade=in:d={fade_duration:.3f}[a{i}]')
                            elif i == len(segments_to_concat) - 1:
                                # æœ€åä¸€æ®µï¼šæ·¡å‡º
                                filter_parts.append(f'[{i}:a]afade=out:d={fade_duration:.3f}[a{i}]')
                            else:
                                # ä¸­é—´æ®µï¼šè½»å¾®æ·¡å…¥æ·¡å‡º
                                filter_parts.append(f'[{i}:a]afade=in:d={fade_duration/2:.3f},afade=out:d={fade_duration/2:.3f}[a{i}]')
                        
                        if not filter_parts:
                            self.logger.warning(f"åˆ‡ç‰‡ {clip_id} æ— æœ‰æ•ˆæ®µï¼Œè·³è¿‡")
                            return None
                        
                        # åˆå¹¶æ‰€æœ‰æ®µ
                        concat_inputs = ''.join(f'[a{i}]' for i in range(len(filter_parts)))
                        filter_parts.append(f'{concat_inputs}concat=n={len(filter_parts)}:v=0:a=1,loudnorm[out]')
                        
                        filter_complex = ';'.join(filter_parts)
                        
                        ffmpeg_cmd = ['ffmpeg', '-y'] + input_specs + [
                            '-filter_complex', filter_complex,
                            '-map', '[out]',
                            '-ac', '1',  # å•å£°é“
                            '-ar', '22050',  # é‡‡æ ·ç‡
                            output_path
                        ]
                    
                    # æ‰§è¡Œffmpegå‘½ä»¤
                    self.logger.info(f"ğŸš€ æ‰§è¡Œffmpegå¤„ç†åˆ‡ç‰‡ {clip_id}: {len(segments_to_concat)}æ®µ, è¯´è¯äºº={clip_info['speaker']}")
                    
                    result = await asyncio.to_thread(
                        subprocess.run, ffmpeg_cmd,
                        capture_output=True, text=True, check=True
                    )
                    
                    # è¯¦ç»†éªŒè¯è¾“å‡ºæ–‡ä»¶
                    if not os.path.exists(output_path):
                        raise ValueError(f"ffmpegæœªç”Ÿæˆè¾“å‡ºæ–‡ä»¶: {output_path}")
                    
                    output_size = os.path.getsize(output_path)
                    if output_size == 0:
                        raise ValueError(f"ffmpegç”Ÿæˆç©ºæ–‡ä»¶: {output_path}")
                    
                    # ğŸš€ ä¼˜åŒ–ï¼šåªåœ¨è°ƒè¯•æ¨¡å¼ä¸‹éªŒè¯
                    if getattr(self, 'debug_mode', False):
                        # ä½¿ç”¨ffprobeéªŒè¯ç”Ÿæˆçš„éŸ³é¢‘æ–‡ä»¶
                        try:
                            probe_cmd = [
                                'ffprobe', '-v', 'quiet', '-print_format', 'json', 
                                '-show_format', output_path
                            ]
                            probe_result = await asyncio.to_thread(
                                subprocess.run, probe_cmd,
                                capture_output=True, text=True, check=True
                            )
                            
                            import json
                            output_info = json.loads(probe_result.stdout)
                            output_duration = float(output_info['format']['duration'])
                            
                            self.logger.info(f"âœ… æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_size} bytes, æ—¶é•¿: {output_duration:.3f}s")
                        except Exception as e:
                            self.logger.warning(f"ffprobeéªŒè¯å¤±è´¥: {e}")
                    else:
                        self.logger.info(f"âœ… æ–‡ä»¶ç”ŸæˆæˆåŠŸ: {output_size} bytes")
                    
                    # ä¸Šä¼ åˆ°R2
                    with open(output_path, 'rb') as f:
                        s3_client.put_object(
                            Bucket=bucket_name,
                            Body=f,
                            Key=audio_key,
                            ContentType='audio/wav'
                        )
                    
                    self.logger.info(f"ğŸ“¤ å·²ä¸Šä¼ åˆ‡ç‰‡åˆ°R2: {audio_key}")
                    
                    # è¾“å‡ºffmpegçš„stderrç”¨äºè°ƒè¯•
                    if result.stderr:
                        self.logger.debug(f"ffmpeg stderr: {result.stderr}")
                    
                    # åˆ›å»ºsegmentå¯¹è±¡
                    segment_data = {
                        'segmentId': clip_id,
                        'audioKey': audio_key,
                        'speaker': clip_info['speaker'],
                        'startMs': clip_info['segments_to_concatenate'][0][0],
                        'endMs': clip_info['segments_to_concatenate'][-1][1],
                        'durationMs': clip_info['total_duration_ms'],
                        'sentences': clip_info['sentences']
                    }
                    return AudioSegment(**segment_data)
                    
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(output_path):
                        os.unlink(output_path)
                        
            except subprocess.CalledProcessError as e:
                self.logger.error(f"ffmpegå¤„ç†åˆ‡ç‰‡ {clip_id} å¤±è´¥: stderr={e.stderr}")
                return None
            except Exception as e:
                self.logger.error(f"å¤„ç†åˆ‡ç‰‡ {clip_id} å¼‚å¸¸: {e}")
                return None
        
        # ğŸš€ ä¼˜åŒ–ï¼šé™åˆ¶å¹¶å‘æ•°é‡ä»¥é¿å…CPUè¿‡è½½
        max_concurrent = min(3, len(clips_library))  # æœ€å¤š3ä¸ªå¹¶å‘ä»»åŠ¡
        self.logger.info(f"å¼€å§‹å¤„ç† {len(clips_library)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡ (å¹¶å‘æ•°: {max_concurrent})")
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def process_with_limit(clip_id, clip_info):
            async with semaphore:
                return await process_single_clip_with_ffmpeg(clip_id, clip_info)
        
        tasks = [process_with_limit(clip_id, clip_info) 
                for clip_id, clip_info in clips_library.items()]
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # æ”¶é›†æˆåŠŸçš„ç»“æœ
        for result in results:
            if isinstance(result, AudioSegment):
                segments.append(result)
            elif isinstance(result, Exception):
                self.logger.error(f"åˆ‡ç‰‡å¤„ç†å¼‚å¸¸: {result}")
        
        self.logger.info(f"ffmpegå¹¶è¡Œå¤„ç†å®Œæˆï¼ŒæˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
        return segments


# åˆ›å»ºR2å®¢æˆ·ç«¯
def create_r2_client(config: R2Config):
    """åˆ›å»ºR2å®¢æˆ·ç«¯"""
    return boto3.client(
        's3',
        endpoint_url=f'https://{config.accountId}.r2.cloudflarestorage.com',
        aws_access_key_id=config.accessKeyId,
        aws_secret_access_key=config.secretAccessKey,
        region_name='auto'
    )


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "audio-segment-container",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@app.post("/segment", response_model=SegmentResponse)
async def segment_audio(request: SegmentRequest):
    """éŸ³é¢‘åˆ‡åˆ†æ¥å£"""
    logger.info(f"æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚: audioKey={request.audioKey}, transcripts={len(request.transcripts)}")
    
    # ğŸš€ æ€§èƒ½ä¼˜åŒ–å¼€å…³
    use_optimization = request.performanceMode if hasattr(request, 'performanceMode') else True
    logger.info(f"ä½¿ç”¨ä¼˜åŒ–æ¨¡å¼: {use_optimization}")
    
    try:
        # åˆ›å»ºR2å®¢æˆ·ç«¯
        s3_client = create_r2_client(request.r2Config)
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•ååˆ›å»ºä¸´æ—¶æ–‡ä»¶
            original_ext = os.path.splitext(request.audioKey)[1] or '.aac'
            audio_path = Path(temp_dir) / f"input_audio{original_ext}"
            
            # ä»R2ä¸‹è½½éŸ³é¢‘
            try:
                logger.info(f"ä»R2ä¸‹è½½éŸ³é¢‘: {request.audioKey}")
                logger.info(f"ç›®æ ‡è·¯å¾„: {audio_path}")
                
                s3_client.download_file(
                    Bucket=request.r2Config.bucketName,
                    Key=request.audioKey,
                    Filename=str(audio_path)
                )
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                if not audio_path.exists():
                    raise FileNotFoundError(f"ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
                downloaded_size = audio_path.stat().st_size
                logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {downloaded_size} bytes")
                
                if downloaded_size == 0:
                    raise ValueError(f"ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {request.audioKey}")
                    
            except Exception as e:
                logger.error(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ {request.audioKey}: {e}")
            
            # åˆ›å»ºåˆ‡åˆ†å™¨
            segmenter = AudioSegmenter(
                goal_duration_ms=request.goalDurationMs,
                min_duration_ms=request.minDurationMs,
                padding_ms=request.paddingMs
            )
            # è®¾ç½®ä¼˜åŒ–æ ‡å¿—
            segmenter.use_audio_filters = not use_optimization  # ä¼˜åŒ–æ¨¡å¼ä¸‹ä¸ä½¿ç”¨æ»¤é•œ
            segmenter.debug_mode = False  # ç”Ÿäº§ç¯å¢ƒå…³é—­è°ƒè¯•
            
            # ç”Ÿæˆåˆ‡ç‰‡è®¡åˆ’
            clips_library, sentence_to_clip_map = segmenter._create_audio_clips(request.transcripts)
            
            if not clips_library:
                return SegmentResponse(
                    success=True,
                    segments=[],
                    sentenceToSegmentMap={}
                )
            
            logger.info(f"ç”Ÿæˆäº† {len(clips_library)} ä¸ªåˆ‡ç‰‡è®¡åˆ’")
            
            # æå–å¹¶ä¿å­˜åˆ‡ç‰‡
            s3_client_for_upload = boto3.client(
                's3',
                endpoint_url=f'https://{request.r2Config.accountId}.r2.cloudflarestorage.com',
                aws_access_key_id=request.r2Config.accessKeyId,
                aws_secret_access_key=request.r2Config.secretAccessKey,
                region_name='auto'
            )
            
            segments = await segmenter.extract_and_save_clips(
                str(audio_path),
                clips_library,
                request.outputPrefix,
                s3_client_for_upload,
                request.r2Config.bucketName
            )
            
            logger.info(f"æˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
            
            return SegmentResponse(
                success=True,
                segments=segments,
                sentenceToSegmentMap=sentence_to_clip_map
            )
            
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: {e}", exc_info=True)
        # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_message = str(e)
        if hasattr(e, '__cause__') and e.__cause__:
            error_message += f" (åŸå› : {e.__cause__})"
        
        return SegmentResponse(
            success=False,
            error=f"{error_type}: {error_message}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)