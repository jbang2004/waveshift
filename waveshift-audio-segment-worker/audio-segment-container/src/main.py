#!/usr/bin/env python3
"""
éŸ³é¢‘åˆ‡åˆ†å®¹å™¨æœåŠ¡
åŸºäºè½¬å½•æ•°æ®å’Œè¯´è¯äººä¿¡æ¯è¿›è¡Œæ™ºèƒ½éŸ³é¢‘ç‰‡æ®µæå–
"""
import os
import re
import json
import asyncio
import logging
import tempfile
from pathlib import Path
from typing import List, Dict, Tuple, Optional
from datetime import datetime, timezone

import boto3
import httpx
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel

# é…ç½®æ—¥å¿— - å¯ç”¨è¯¦ç»†è°ƒè¯•ä¿¡æ¯
logging.basicConfig(
    level=logging.DEBUG,  # æ”¹ä¸ºDEBUGçº§åˆ«ä»¥æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPIåº”ç”¨
app = FastAPI(title="Audio Segment Container")

# æ•°æ®æ¨¡å‹
class TranscriptItem(BaseModel):
    sequence: int
    startMs: int  # å¼€å§‹æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    endMs: int    # ç»“æŸæ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
    speaker: str
    original: str
    translation: Optional[str] = None
    content_type: str = 'speech'

class R2Config(BaseModel):
    accountId: str
    accessKeyId: str
    secretAccessKey: str
    bucketName: str
    publicDomain: str

class SegmentRequest(BaseModel):
    audioKey: str
    transcripts: List[TranscriptItem]
    outputPrefix: str
    r2Config: R2Config

class AudioSegment(BaseModel):
    segmentId: str
    audioKey: str
    speaker: str
    startMs: int
    endMs: int
    durationMs: int
    sentences: List[Dict]

class SegmentResponse(BaseModel):
    success: bool
    segments: Optional[List[AudioSegment]] = None
    sentenceToSegmentMap: Optional[Dict[int, str]] = None
    error: Optional[str] = None


class StreamingAccumulator:
    """æµå¼ç´¯ç§¯å™¨ï¼šç»´æŠ¤å½“å‰éŸ³é¢‘ç‰‡æ®µçš„å¤„ç†çŠ¶æ€"""
    def __init__(self, first_sentence: Dict):
        self.speaker = first_sentence['speaker']
        self.time_ranges = [[first_sentence['startMs'], first_sentence['endMs']]]
        self.pending_sentences = [first_sentence]
        self.audio_url = None  # ä¸Šä¼ åçš„éŸ³é¢‘åœ°å€ï¼Œä¾›åç»­å¥å­å¤ç”¨
        self.sequence_start = first_sentence['sequence']
        
    def get_total_duration(self, gap_duration_ms: int) -> int:
        """è®¡ç®—ç´¯ç§¯å™¨çš„æ€»æ—¶é•¿ï¼ˆåŒ…å«gapsï¼‰"""
        audio_duration = sum(end - start for start, end in self.time_ranges)
        gap_count = max(0, len(self.time_ranges) - 1)
        return audio_duration + (gap_count * gap_duration_ms)
        
    def clear_sentences(self):
        """æ¸…ç©ºå¾…å¤„ç†å¥å­ä½†ä¿ç•™speakerå’Œaudio_url"""
        self.pending_sentences = []
        self.time_ranges = []


class AudioSegmenter:
    """éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - æµå¼å¤„ç†çš„æ™ºèƒ½éŸ³é¢‘åˆ‡ç‰‡"""
    
    def __init__(self):
        # ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®å‚æ•°
        self.gap_duration_ms = int(os.getenv('GAP_DURATION_MS', '500'))
        self.max_duration_ms = int(os.getenv('MAX_DURATION_MS', '12000'))  
        self.min_duration_ms = int(os.getenv('MIN_DURATION_MS', '3000'))
        self.gap_threshold_multiplier = int(os.getenv('GAP_THRESHOLD_MULTIPLIER', '3'))
        
        self.logger = logger
        self.logger.info(f"ğŸµ AudioSegmenteråˆå§‹åŒ– - Gap:{self.gap_duration_ms}ms, "
                        f"Max:{self.max_duration_ms}ms, Min:{self.min_duration_ms}ms, "
                        f"GapThreshold:{self.gap_duration_ms * self.gap_threshold_multiplier}ms")
        
    async def process_sentences_streaming(self, transcripts: List[TranscriptItem], 
                                        audio_path: str, output_prefix: str, 
                                        s3_client, bucket_name: str) -> Tuple[List[AudioSegment], Dict[int, str]]:
        """æµå¼å¤„ç†ï¼šä¸€æ¬¡éå†ï¼Œå®æ—¶å†³ç­–ï¼Œç«‹å³ä¸Šä¼ """
        segments = []
        sentence_to_segment_map = {}
        accumulator = None
        
        # æå–æœ‰æ•ˆè¯­éŸ³å¥å­
        sentences = []
        for item in transcripts:
            if item.content_type != 'speech':
                continue
            if item.startMs >= item.endMs:
                continue
            
            sentences.append({
                'sequence': item.sequence,
                'speaker': item.speaker,
                'original': item.original,
                'translation': item.translation,
                'startMs': item.startMs,
                'endMs': item.endMs,
                'duration': item.endMs - item.startMs
            })
        
        self.logger.info(f"ğŸ¬ å¼€å§‹æµå¼å¤„ç† {len(sentences)} ä¸ªè¯­éŸ³å¥å­")
        
        for sentence in sentences:
            # åˆ¤æ–­æ˜¯å¦éœ€è¦å‘å°„å½“å‰ç´¯ç§¯å™¨
            if accumulator and (
                sentence['speaker'] != accumulator.speaker or  # è¯´è¯äººå˜åŒ–
                self._should_start_new_accumulation(accumulator, sentence)  # é—´éš”è¿‡å¤§
            ):
                # å‘å°„å½“å‰ç´¯ç§¯å™¨
                segment = await self._emit_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
                if segment:
                    segments.append(segment)
                    # æ›´æ–°å¥å­æ˜ å°„
                    for s in accumulator.pending_sentences:
                        sentence_to_segment_map[s['sequence']] = segment.segmentId
                accumulator = None
            
            # ç´¯ç§¯å½“å‰å¥å­
            if not accumulator:
                accumulator = StreamingAccumulator(sentence)
            else:
                self._accumulate_sentence(accumulator, sentence)
            
            # æ£€æŸ¥æ˜¯å¦æ»¡è½½
            if accumulator and self._is_accumulator_full(accumulator):
                segment = await self._emit_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
                if segment:
                    segments.append(segment)
                    for s in accumulator.pending_sentences:
                        sentence_to_segment_map[s['sequence']] = segment.segmentId
                # ä¿ç•™speakerå’Œaudio_urlä¾›åç»­å¤ç”¨
                accumulator.clear_sentences()
        
        # å¤„ç†æœ€åçš„ç´¯ç§¯å™¨
        if accumulator and accumulator.pending_sentences:
            segment = await self._emit_accumulator(accumulator, audio_path, output_prefix, s3_client, bucket_name)
            if segment:
                segments.append(segment)
                for s in accumulator.pending_sentences:
                    sentence_to_segment_map[s['sequence']] = segment.segmentId
        
        self.logger.info(f"âœ… æµå¼å¤„ç†å®Œæˆï¼Œç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ")
        return segments, sentence_to_segment_map
    
    def _should_start_new_accumulation(self, accumulator: StreamingAccumulator, sentence: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å¼€å§‹æ–°çš„ç´¯ç§¯ï¼ˆé—´éš”è¿‡å¤§ï¼‰"""
        if not accumulator.time_ranges:
            return False
        
        last_end = accumulator.time_ranges[-1][1]
        gap = sentence['startMs'] - last_end
        threshold = self.gap_duration_ms * self.gap_threshold_multiplier
        
        return gap > threshold
    
    def _accumulate_sentence(self, accumulator: StreamingAccumulator, sentence: Dict):
        """ç´¯ç§¯å¥å­ï¼Œæ™ºèƒ½å¤„ç†æ—¶é—´èŒƒå›´"""
        if accumulator.audio_url:
            # å·²æœ‰éŸ³é¢‘åœ°å€ï¼Œç›´æ¥å¤ç”¨ï¼ˆä»…é™åŒè¯´è¯äººï¼‰
            sentence['audio_url'] = accumulator.audio_url
            return
        
        # æ£€æŸ¥é—´éš”
        last_end = accumulator.time_ranges[-1][1]
        gap = sentence['startMs'] - last_end
        threshold = self.gap_duration_ms * self.gap_threshold_multiplier
        
        if gap <= threshold:
            # å°é—´éš”ï¼šæ‰©å±•æœ€åä¸€ä¸ªæ—¶é—´èŒƒå›´
            accumulator.time_ranges[-1][1] = sentence['endMs']
            self.logger.debug(f"æ‰©å±•æ—¶é—´èŒƒå›´: [{accumulator.time_ranges[-1][0]}, {accumulator.time_ranges[-1][1]}]")
        else:
            # å¤§é—´éš”ï¼šæ·»åŠ æ–°æ—¶é—´èŒƒå›´
            accumulator.time_ranges.append([sentence['startMs'], sentence['endMs']])
            self.logger.debug(f"æ·»åŠ æ–°æ—¶é—´èŒƒå›´: [{sentence['startMs']}, {sentence['endMs']}]")
        
        accumulator.pending_sentences.append(sentence)
    
    def _is_accumulator_full(self, accumulator: StreamingAccumulator) -> bool:
        """æ£€æŸ¥ç´¯ç§¯å™¨æ˜¯å¦æ»¡è½½"""
        if not accumulator.time_ranges:
            return False
        
        total_duration = accumulator.get_total_duration(self.gap_duration_ms)
        return total_duration >= self.max_duration_ms
    
    async def _emit_accumulator(self, accumulator: StreamingAccumulator, 
                               audio_path: str, output_prefix: str, 
                               s3_client, bucket_name: str) -> Optional[AudioSegment]:
        """å‘å°„ç´¯ç§¯å™¨ï¼šç”ŸæˆéŸ³é¢‘å¹¶ä¸Šä¼ """
        if not accumulator.pending_sentences:
            return None
        
        # æ£€æŸ¥æœ€å°æ—¶é•¿
        total_duration = accumulator.get_total_duration(self.gap_duration_ms)
        if len(accumulator.pending_sentences) == 1 and total_duration < self.min_duration_ms:
            sequences = [s['sequence'] for s in accumulator.pending_sentences]
            self.logger.info(f"ğŸ—‘ï¸ ä¸¢å¼ƒè¿‡çŸ­çš„å•å¥ç‰‡æ®µ: speaker={accumulator.speaker}, "
                           f"duration={total_duration}ms, sequences={sequences}")
            return None
        
        # ç”Ÿæˆclipä¿¡æ¯
        clip_id = f"sequence_{accumulator.sequence_start:04d}"
        audio_key = f"{output_prefix}/{clip_id}_{accumulator.speaker}.wav"
        
        self.logger.info(f"ğŸµ å‘å°„éŸ³é¢‘ç‰‡æ®µ {clip_id}: speaker={accumulator.speaker}, "
                        f"ranges={len(accumulator.time_ranges)}, sentences={len(accumulator.pending_sentences)}, "
                        f"duration={total_duration}ms")
        
        # ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘
        success = await self._process_audio_with_ffmpeg(
            audio_path, accumulator.time_ranges, audio_key, s3_client, bucket_name
        )
        
        if not success:
            return None
        
        # è®¾ç½®audio_urlä¾›åç»­å¤ç”¨
        accumulator.audio_url = audio_key
        
        # åˆ›å»ºsegmentå¯¹è±¡
        return AudioSegment(
            segmentId=clip_id,
            audioKey=audio_key,
            speaker=accumulator.speaker,
            startMs=accumulator.time_ranges[0][0],
            endMs=accumulator.time_ranges[-1][1],
            durationMs=total_duration,
            sentences=[{
                'sequence': s['sequence'],
                'original': s['original'],
                'translation': s.get('translation')
            } for s in accumulator.pending_sentences]
        )
    
    async def _process_audio_with_ffmpeg(self, audio_path: str, time_ranges: List[List[int]], 
                                       audio_key: str, s3_client, bucket_name: str) -> bool:
        """ä½¿ç”¨FFmpegå¤„ç†éŸ³é¢‘å¹¶ä¸Šä¼ åˆ°R2"""
        import subprocess
        import tempfile
        
        # åˆ›å»ºä¸´æ—¶è¾“å‡ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:
            output_path = tmp_file.name
        
        try:
            if len(time_ranges) == 1:
                # ğŸ¯ å•æ®µå¤„ç† - é«˜æ€§èƒ½æµå¤åˆ¶
                start_ms, end_ms = time_ranges[0]
                start_sec = start_ms / 1000.0
                duration_sec = (end_ms - start_ms) / 1000.0
                
                ffmpeg_cmd = [
                    'ffmpeg', '-y',
                    '-ss', f'{start_sec:.3f}',
                    '-i', audio_path,
                    '-t', f'{duration_sec:.3f}',
                    '-c:a', 'copy',
                    '-avoid_negative_ts', 'make_zero',
                    output_path
                ]
                
                self.logger.info(f"ğŸ“ å•æ®µFFmpeg: {' '.join(ffmpeg_cmd)}")
                
            else:
                # ğŸµ å¤šæ®µå¤„ç† - Gapé™éŸ³æ’å…¥
                input_specs = []
                
                # ä¸ºæ¯ä¸ªéŸ³é¢‘æ®µæ·»åŠ è¾“å…¥
                for i, (start_ms, end_ms) in enumerate(time_ranges):
                    start_sec = start_ms / 1000.0
                    duration_sec = (end_ms - start_ms) / 1000.0
                    
                    input_specs.extend(['-ss', f'{start_sec:.3f}', '-t', f'{duration_sec:.3f}', '-i', audio_path])
                    
                    self.logger.info(f"  æ®µ{i+1}: {start_sec:.3f}s - {start_sec + duration_sec:.3f}s ({duration_sec:.3f}s)")
                
                # æ„å»ºfilter_complex - Gapé™éŸ³æ’å…¥
                gap_sec = self.gap_duration_ms / 1000.0
                gap_filter = f'anullsrc=channel_layout=mono:sample_rate=44100:duration={gap_sec:.3f}'
                
                # æ„å»ºæ‹¼æ¥åºåˆ—ï¼šéŸ³é¢‘1 + gap + éŸ³é¢‘2 + gap + éŸ³é¢‘3...
                concat_parts = []
                for i in range(len(time_ranges)):
                    concat_parts.append(f'[{i}:a]')
                    if i < len(time_ranges) - 1:
                        concat_parts.append('[gap]')
                
                filter_complex = f'{gap_filter}[gap];{"".join(concat_parts)}concat=n={len(concat_parts)}:v=0:a=1[out]'
                
                ffmpeg_cmd = ['ffmpeg', '-y'] + input_specs + [
                    '-filter_complex', filter_complex,
                    '-map', '[out]',
                    output_path
                ]
                
                self.logger.info(f"ğŸµ å¤šæ®µå¤„ç†: {len(time_ranges)}æ®µ + {len(time_ranges)-1}ä¸ªGap({gap_sec:.3f}s)")
            
            # æ‰§è¡Œffmpegå‘½ä»¤
            result = await asyncio.to_thread(
                subprocess.run, ffmpeg_cmd,
                capture_output=True, text=True, check=True
            )
            
            # éªŒè¯è¾“å‡ºæ–‡ä»¶
            if not os.path.exists(output_path) or os.path.getsize(output_path) == 0:
                self.logger.error(f"FFmpegæœªç”Ÿæˆæœ‰æ•ˆè¾“å‡ºæ–‡ä»¶")
                return False
            
            # ä¸Šä¼ åˆ°R2
            with open(output_path, 'rb') as f:
                s3_client.put_object(
                    Bucket=bucket_name,
                    Body=f,
                    Key=audio_key,
                    ContentType='audio/wav'
                )
            
            self.logger.info(f"ğŸ“¤ å·²ä¸Šä¼ éŸ³é¢‘åˆ°R2: {audio_key}")
            return True
            
        except subprocess.CalledProcessError as e:
            self.logger.error(f"FFmpegå¤„ç†å¤±è´¥: {e.stderr}")
            return False
        except Exception as e:
            self.logger.error(f"å¤„ç†éŸ³é¢‘å¼‚å¸¸: {e}")
            return False
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(output_path):
                os.unlink(output_path)
    
    # æ‰€æœ‰æ—§çš„å¤„ç†é€»è¾‘å·²ç§»é™¤ï¼Œä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
    # åŸæœ‰æ–¹æ³•ï¼š
    # - _calculate_total_duration_with_gaps
    # - _create_audio_clips
    # - _extract_speech_sentences
    # - _group_by_speaker
    # - _process_speaker_groups
    # - _split_long_group
    # - _should_keep_clip
    # - _generate_clip_info
    # å·²å…¨éƒ¨è¢«æµå¼å¤„ç†æ–¹æ³•å–ä»£


# åˆ›å»ºR2å®¢æˆ·ç«¯
def create_r2_client(config: R2Config):
    """åˆ›å»ºR2å®¢æˆ·ç«¯"""
    return boto3.client(
        's3',
        endpoint_url=f'https://{config.accountId}.r2.cloudflarestorage.com',
        aws_access_key_id=config.accessKeyId,
        aws_secret_access_key=config.secretAccessKey,
        region_name='auto'
    )


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "service": "audio-segment-container",
        "timestamp": datetime.now(timezone.utc).isoformat()
    }


@app.post("/segment", response_model=SegmentResponse)
async def segment_audio(request: SegmentRequest):
    """éŸ³é¢‘åˆ‡åˆ†æ¥å£"""
    logger.info(f"æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚: audioKey={request.audioKey}, transcripts={len(request.transcripts)}")
    
    # å·²ç§»é™¤æ€§èƒ½ä¼˜åŒ–å¼€å…³ - æ–°ç®—æ³•å·²å½»åº•ç§»é™¤fadeé€»è¾‘
    
    try:
        # åˆ›å»ºR2å®¢æˆ·ç«¯
        s3_client = create_r2_client(request.r2Config)
        
        # ä¸‹è½½éŸ³é¢‘æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            # æ ¹æ®åŸå§‹æ–‡ä»¶æ‰©å±•ååˆ›å»ºä¸´æ—¶æ–‡ä»¶
            original_ext = os.path.splitext(request.audioKey)[1] or '.aac'
            audio_path = Path(temp_dir) / f"input_audio{original_ext}"
            
            # ä»R2ä¸‹è½½éŸ³é¢‘
            try:
                logger.info(f"ä»R2ä¸‹è½½éŸ³é¢‘: {request.audioKey}")
                logger.info(f"ç›®æ ‡è·¯å¾„: {audio_path}")
                
                s3_client.download_file(
                    Bucket=request.r2Config.bucketName,
                    Key=request.audioKey,
                    Filename=str(audio_path)
                )
                
                # éªŒè¯ä¸‹è½½çš„æ–‡ä»¶
                if not audio_path.exists():
                    raise FileNotFoundError(f"ä¸‹è½½å¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
                
                downloaded_size = audio_path.stat().st_size
                logger.info(f"éŸ³é¢‘æ–‡ä»¶ä¸‹è½½æˆåŠŸ: {downloaded_size} bytes")
                
                if downloaded_size == 0:
                    raise ValueError(f"ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: {request.audioKey}")
                    
            except Exception as e:
                logger.error(f"ä¸‹è½½éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {e}")
                raise ValueError(f"æ— æ³•ä¸‹è½½éŸ³é¢‘æ–‡ä»¶ {request.audioKey}: {e}")
            
            # ğŸµ åˆ›å»ºåˆ‡åˆ†å™¨ - ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
            segmenter = AudioSegmenter()
            
            # ğŸš€ ä½¿ç”¨æ–°çš„æµå¼å¤„ç†æ–¹æ³•
            s3_client_for_upload = boto3.client(
                's3',
                endpoint_url=f'https://{request.r2Config.accountId}.r2.cloudflarestorage.com',
                aws_access_key_id=request.r2Config.accessKeyId,
                aws_secret_access_key=request.r2Config.secretAccessKey,
                region_name='auto'
            )
            
            segments, sentence_to_segment_map = await segmenter.process_sentences_streaming(
                request.transcripts,
                str(audio_path),
                request.outputPrefix,
                s3_client_for_upload,
                request.r2Config.bucketName
            )
            
            if not segments:
                return SegmentResponse(
                    success=True,
                    segments=[],
                    sentenceToSegmentMap={}
                )
            
            logger.info(f"âœ… æµå¼å¤„ç†æˆåŠŸç”Ÿæˆ {len(segments)} ä¸ªéŸ³é¢‘åˆ‡ç‰‡")
            
            return SegmentResponse(
                success=True,
                segments=segments,
                sentenceToSegmentMap=sentence_to_segment_map
            )
            
    except ValueError as e:
        logger.error(f"å‚æ•°é”™è¯¯: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except FileNotFoundError as e:
        logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {e}")
        return SegmentResponse(
            success=False,
            error=str(e)
        )
    except Exception as e:
        logger.error(f"éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: {e}", exc_info=True)
        # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
        error_type = type(e).__name__
        error_message = str(e)
        if hasattr(e, '__cause__') and e.__cause__:
            error_message += f" (åŸå› : {e.__cause__})"
        
        return SegmentResponse(
            success=False,
            error=f"{error_type}: {error_message}"
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)