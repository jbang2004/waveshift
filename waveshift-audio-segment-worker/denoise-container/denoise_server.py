#!/usr/bin/env python3
"""
é™å™ªæœåŠ¡å™¨ - å¤„ç†éŸ³é¢‘é™å™ªè¯·æ±‚
åŸºäº ZipEnhancer æ¨¡å‹çš„æµå¼éŸ³é¢‘é™å™ªæœåŠ¡
ğŸ”§ ä¼˜åŒ–ç‰ˆï¼šæ‡’åŠ è½½æ¨¡å‹ï¼Œå¿«é€Ÿå¯åŠ¨ï¼Œé¿å…å®¹å™¨è¶…æ—¶
"""

from fastapi import FastAPI, Response, Header, HTTPException
from fastapi.responses import JSONResponse
import io
import numpy as np
import soundfile as sf
import torch
import gc
import os
import time
from typing import Optional
from zipenhancer_streaming import StreamingZipEnhancer, streaming_denoise
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# è®¾ç½®PyTorchçº¿ç¨‹æ•°é™åˆ¶ï¼ˆå®¹å™¨ç¯å¢ƒä¼˜åŒ–ï¼‰
torch.set_num_threads(2)  # å‡å°‘çº¿ç¨‹æ•°ä»¥èŠ‚çœå†…å­˜

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="ZipEnhancer Denoise Service", 
    version="2.0.0",
    description="å¿«é€Ÿå¯åŠ¨çš„éŸ³é¢‘é™å™ªæœåŠ¡ - æ‡’åŠ è½½æ¨¡å‹"
)

# å…¨å±€é™å™ªå™¨å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
global_enhancer = None
model_loading = False

def get_enhancer():
    """æ‡’åŠ è½½ï¼šè·å–æˆ–åˆ›å»ºé™å™ªå™¨å®ä¾‹"""
    global global_enhancer, model_loading
    
    if global_enhancer is None and not model_loading:
        model_loading = True
        try:
            model_path = './speech_zipenhancer_ans_multiloss_16k_base/onnx_model.onnx'
            if not os.path.exists(model_path):
                raise RuntimeError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            logger.info(f"ğŸ”„ æ‡’åŠ è½½é™å™ªæ¨¡å‹: {model_path}")
            start_time = time.time()
            
            global_enhancer = StreamingZipEnhancer(
                onnx_model_path=model_path,
                chunk_duration=1.0,  # 1ç§’å—å¤„ç†
                overlap_duration=0.5  # 0.5ç§’é‡å 
            )
            
            load_time = time.time() - start_time
            logger.info(f"âœ… é™å™ªæ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f}s")
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            global_enhancer = None
            raise
        finally:
            model_loading = False
    
    return global_enhancer

@app.get("/")
async def root():
    """å¿«é€Ÿå¥åº·æ£€æŸ¥ç«¯ç‚¹ï¼ˆæ— æ¨¡å‹åŠ è½½ï¼‰"""
    return {
        "status": "healthy",
        "service": "denoise-container",
        "version": "2.0.0",
        "model": "zipenhancer_16k_base",
        "features": ["streaming", "real-time", "memory-efficient", "lazy-loading"],
        "model_loaded": global_enhancer is not None,
        "ready_for_processing": True
    }

@app.get("/health")
async def health_check():
    """è¯¦ç»†å¥åº·æ£€æŸ¥ï¼ˆå¯é€‰åŠ è½½æ¨¡å‹ï¼‰"""
    global model_loading
    
    return {
        "status": "healthy",
        "service_ready": True,
        "model_loaded": global_enhancer is not None,
        "model_loading": model_loading,
        "memory_usage_mb": 0,  # ç®€åŒ–å†…å­˜æ£€æŸ¥é¿å…GPUä¾èµ–
        "timestamp": time.time(),
        "torch_threads": torch.get_num_threads()
    }

@app.post("/")
async def denoise_audio(
    audio_data: bytes,
    x_segment_id: Optional[str] = Header(None),
    x_speaker: Optional[str] = Header(None),
    x_enable_streaming: Optional[str] = Header("true")
):
    """
    å¤„ç†éŸ³é¢‘é™å™ªè¯·æ±‚
    
    Args:
        audio_data: WAVæ ¼å¼çš„éŸ³é¢‘äºŒè¿›åˆ¶æ•°æ®
        x_segment_id: éŸ³é¢‘ç‰‡æ®µIDï¼ˆç”¨äºæ—¥å¿—ï¼‰
        x_speaker: è¯´è¯äººæ ‡è¯†ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        x_enable_streaming: æ˜¯å¦å¯ç”¨æµå¼å¤„ç†
    
    Returns:
        é™å™ªåçš„WAVéŸ³é¢‘æ•°æ®
    """
    start_time = time.time()
    segment_id = x_segment_id or "unknown"
    speaker = x_speaker or "unknown"
    enable_streaming = x_enable_streaming.lower() == "true"
    
    logger.info(f"ğŸµ å¤„ç†é™å™ªè¯·æ±‚: segment={segment_id}, speaker={speaker}, size={len(audio_data)} bytes")
    
    try:
        # 1. ä»äºŒè¿›åˆ¶æ•°æ®è¯»å–éŸ³é¢‘
        audio, sr = sf.read(io.BytesIO(audio_data))
        logger.info(f"éŸ³é¢‘åŠ è½½æˆåŠŸ: shape={audio.shape}, sr={sr}")
        
        # 2. éªŒè¯é‡‡æ ·ç‡ (audio-segment-containerå·²ç¡®ä¿16kHzè¾“å‡º)
        if sr != 16000:
            logger.error(f"âŒ é‡‡æ ·ç‡é”™è¯¯: {sr}Hz, é¢„æœŸ16kHz")
            raise ValueError(f"éŸ³é¢‘é‡‡æ ·ç‡å¿…é¡»ä¸º16kHzï¼Œå®é™…ä¸º{sr}Hzã€‚è¯·æ£€æŸ¥audio-segment-containeré…ç½®ã€‚")
        
        logger.info(f"âœ… é‡‡æ ·ç‡éªŒè¯é€šè¿‡: {sr}Hz")
        
        # 3. è·å–é™å™ªå™¨å¹¶å¤„ç†
        try:
            enhancer = get_enhancer()
            if enhancer is None:
                raise RuntimeError("é™å™ªæ¨¡å‹æœªèƒ½æˆåŠŸåŠ è½½")
                
        except Exception as model_error:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {model_error}")
            return Response(
                content=f"æ¨¡å‹åŠ è½½å¤±è´¥: {model_error}",
                status_code=503,
                headers={
                    "X-Processing-Success": "false",
                    "X-Segment-Id": segment_id,
                    "X-Error": f"Model loading failed: {model_error}"
                }
            )
        
        # 4. æ‰§è¡Œé™å™ªå¤„ç†
        try:
            if enable_streaming:
                # æµå¼å¤„ç†ï¼ˆå†…å­˜æ•ˆç‡é«˜ï¼‰
                enhanced_chunks = []
                for chunk in enhancer.stream_process(audio):
                    enhanced_chunks.append(chunk)
                enhanced_audio = np.concatenate(enhanced_chunks)
                logger.info(f"æµå¼é™å™ªå®Œæˆ: {len(enhanced_chunks)} chunks")
            else:
                # ä¸€æ¬¡æ€§å¤„ç†ï¼ˆé€‚åˆçŸ­éŸ³é¢‘ï¼‰
                enhanced_audio = enhancer.process(audio)
                logger.info("å•æ¬¡é™å™ªå®Œæˆ")
                
        except Exception as processing_error:
            logger.error(f"âŒ éŸ³é¢‘å¤„ç†å¤±è´¥: {processing_error}")
            return Response(
                content=f"éŸ³é¢‘å¤„ç†å¤±è´¥: {processing_error}",
                status_code=500,
                headers={
                    "X-Processing-Success": "false",
                    "X-Segment-Id": segment_id,
                    "X-Error": f"Audio processing failed: {processing_error}"
                }
            )
        
        # 5. ç¡®ä¿è¾“å‡ºèŒƒå›´æ­£ç¡®
        enhanced_audio = np.clip(enhanced_audio, -1.0, 1.0)
        
        # 6. è½¬æ¢å›WAVäºŒè¿›åˆ¶
        output_buffer = io.BytesIO()
        sf.write(output_buffer, enhanced_audio, sr, format='WAV', subtype='PCM_16')
        output_buffer.seek(0)
        
        # 7. å‡†å¤‡å“åº”
        output_data = output_buffer.read()
        process_time = time.time() - start_time
        
        logger.info(f"âœ… é™å™ªå®Œæˆ: segment={segment_id}, "
                   f"è¾“å…¥={len(audio_data)} bytes, "
                   f"è¾“å‡º={len(output_data)} bytes, "
                   f"è€—æ—¶={process_time:.2f}s")
        
        # 8. æ¸…ç†å†…å­˜
        del audio
        del enhanced_audio
        gc.collect()
        
        return Response(
            content=output_data,
            media_type="audio/wav",
            headers={
                "X-Processing-Success": "true",
                "X-Segment-Id": segment_id,
                "X-Processing-Time": f"{process_time:.3f}",
                "X-Input-Size": str(len(audio_data)),
                "X-Output-Size": str(len(output_data)),
                "X-Model-Loaded": "true"
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ é™å™ªå¤±è´¥: segment={segment_id}, error={e}")
        
        # è¿”å›é”™è¯¯å“åº”
        return Response(
            content=str(e),
            status_code=500,
            headers={
                "X-Processing-Success": "false",
                "X-Segment-Id": segment_id,
                "X-Error": str(e)
            }
        )

@app.post("/batch")
async def batch_denoise(
    # é¢„ç•™æ‰¹é‡å¤„ç†æ¥å£ï¼Œæœªæ¥å¯èƒ½éœ€è¦
):
    """æ‰¹é‡é™å™ªæ¥å£ï¼ˆé¢„ç•™ï¼‰"""
    return {"error": "Batch processing not implemented yet"}

if __name__ == "__main__":
    import uvicorn
    # å¯åŠ¨æœåŠ¡å™¨
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8080,
        log_level="info",
        access_log=True
    )