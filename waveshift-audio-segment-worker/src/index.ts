import { Hono } from 'hono';
import { cors } from 'hono/cors';
import type { AudioSegmentRequest, AudioSegmentResponse, Env } from './types';
import { WorkerEntrypoint } from 'cloudflare:workers';
import { AudioSegmentContainer } from './container';
import { 
  AudioSegmenter, 
  StreamingAccumulator, 
  type AudioSegmentConfig 
} from './streaming-processor';
import { StreamingProcessor } from './streaming-processor-v2';

// æ–°å¢Watchæ¥å£å®šä¹‰
export interface WatchRequest {
  audioKey: string;
  transcriptionId: string;
  outputPrefix: string;
  taskId?: string;
}

export interface WatchResponse {
  success: boolean;
  segmentCount?: number;
  sentenceToSegmentMap?: Record<number, string>;
  error?: string;
  stats?: {
    totalPolls: number;
    totalSentencesProcessed: number;
    totalDuration: number;
  };
}

// Serviceæ¥å£å®šä¹‰ - åŒ¹é…workflow/env.d.tsä¸­çš„å®šä¹‰
export interface AudioSegmentService {
  segment(request: AudioSegmentRequest): Promise<AudioSegmentResponse>;
  watch(params: {
    audioKey: string;
    transcriptionId: string;
    outputPrefix: string;
    taskId?: string;
  }): Promise<{
    success: boolean;
    segmentCount?: number;
    sentenceToSegmentMap?: Record<number, string>;
    error?: string;
    stats?: {
      totalPolls: number;
      totalSentencesProcessed: number;
      totalDuration: number;
    };
  }>;
}

const app = new Hono<{ Bindings: Env }>();

// æ·»åŠ CORSä¸­é—´ä»¶
app.use('*', cors({
  origin: '*',
  allowHeaders: ['Content-Type', 'Authorization'],
  allowMethods: ['GET', 'POST', 'OPTIONS'],
}));

// å¥åº·æ£€æŸ¥ç«¯ç‚¹
app.get('/health', (c) => {
  return c.json({ 
    status: 'healthy',
    service: 'audio-segment-worker',
    version: '3.0',
    timestamp: new Date().toISOString(),
    note: 'Smart audio segmentation with reuse optimization'
  });
});

// ä¸»é¡µ
app.get('/', (c) => {
  return c.html(`
    <h1>WaveShift Audio Segment Service</h1>
    <p>æ™ºèƒ½éŸ³é¢‘åˆ‡åˆ†æœåŠ¡ - åŸºäºè½¬å½•æ•°æ®è¿›è¡ŒéŸ³é¢‘ç‰‡æ®µæ™ºèƒ½æå–å’Œå¤ç”¨</p>
    <h2>ç‰¹æ€§:</h2>
    <ul>
      <li>ğŸ¯ æ™ºèƒ½éŸ³é¢‘åˆ‡åˆ†ï¼ˆæœ€é•¿12ç§’ï¼‰</li>
      <li>ğŸ”„ éŸ³é¢‘å¤ç”¨ä¼˜åŒ–</li>
      <li>ğŸ“Š å®æ—¶D1æ•°æ®åº“æ›´æ–°</li>
      <li>ğŸš€ é«˜æ€§èƒ½Containerå¤„ç†</li>
    </ul>
    <h2>Architecture:</h2>
    <p>Worker (ä¸šåŠ¡é€»è¾‘ + R2/D1) + Container (çº¯FFmpegå¤„ç†)</p>
    <h3>âœ… Production Ready</h3>
  `);
});

// WorkerEntrypoint ç±»å®šä¹‰ - ç”¨äºService Binding RPCè°ƒç”¨
export class AudioSegmentWorker extends WorkerEntrypoint<Env> implements AudioSegmentService {
  
  /**
   * ğŸ”§ æ–°å¢ï¼šç»Ÿä¸€URLè§„èŒƒåŒ–æ–¹æ³•
   */
  private normalizeAudioUrl(audioKey: string): string {
    // å¦‚æœå·²ç»æ˜¯å®Œæ•´URLï¼Œç›´æ¥è¿”å›
    if (audioKey.startsWith('http')) {
      return audioKey;
    }
    
    // æ„å»ºå®Œæ•´çš„R2å…¬å…±URL
    const r2PublicDomain = this.env.R2_PUBLIC_DOMAIN;
    if (r2PublicDomain) {
      return `https://${r2PublicDomain}/${audioKey}`;
    }
    
    // fallback: è¿”å›ç›¸å¯¹è·¯å¾„
    console.warn(`âš ï¸ R2_PUBLIC_DOMAINæœªé…ç½®ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„: ${audioKey}`);
    return audioKey;
  }
  
  /**
   * ğŸ”¥ æ–°å¢watchæ–¹æ³• - è½®è¯¢D1å¹¶å®æ—¶å¤„ç†
   * ğŸ”§ ä¿®å¤ï¼šå‚æ•°ç±»å‹åŒ¹é…Service Bindingæ¥å£å®šä¹‰
   */
  async watch(params: {
    audioKey: string;
    transcriptionId: string;
    outputPrefix: string;
    taskId?: string;
  }): Promise<{
    success: boolean;
    segmentCount?: number;
    sentenceToSegmentMap?: Record<number, string>;
    error?: string;
    stats?: {
      totalPolls: number;
      totalSentencesProcessed: number;
      totalDuration: number;
    };
  }> {
    const startTime = Date.now();
    console.log(`ğŸ”„ å¼€å§‹ç›‘å¬æ¨¡å¼: transcriptionId=${params.transcriptionId}`);
    
    // ğŸ”§ ä¿®å¤ï¼šå‚æ•°éªŒè¯
    if (!params.outputPrefix || !params.outputPrefix.trim()) {
      console.error(`âŒ watchæ–¹æ³•å‚æ•°é”™è¯¯: outputPrefixä¸ºç©ºæˆ–æ— æ•ˆ: "${params.outputPrefix}"`);
      return {
        success: false,
        error: `æ— æ•ˆçš„outputPrefix: "${params.outputPrefix}"`
      };
    }
    
    if (!params.audioKey || !params.transcriptionId) {
      console.error(`âŒ watchæ–¹æ³•å‚æ•°é”™è¯¯: audioKeyæˆ–transcriptionIdä¸ºç©º`);
      return {
        success: false,
        error: `ç¼ºå°‘å¿…è¦å‚æ•°: audioKey=${params.audioKey}, transcriptionId=${params.transcriptionId}`
      };
    }
    
    console.log(`âœ… å‚æ•°éªŒè¯é€šè¿‡: outputPrefix="${params.outputPrefix}", audioKey="${params.audioKey}"`);
    
    try {
      
      // 1. é¢„åŠ è½½éŸ³é¢‘æ•°æ®ï¼ˆåªåŠ è½½ä¸€æ¬¡ï¼‰- å¢åŠ é‡è¯•æœºåˆ¶
      let audioBytes: Uint8Array | undefined;
      let retryCount = 0;
      const maxRetries = 3;
      
      while (retryCount < maxRetries) {
        try {
          const audioObject = await this.env.R2_BUCKET.get(params.audioKey);
          if (!audioObject) {
            throw new Error(`éŸ³é¢‘æ–‡ä»¶æœªæ‰¾åˆ°: ${params.audioKey}`);
          }
          
          const audioData = await audioObject.arrayBuffer();
          if (audioData.byteLength === 0) {
            throw new Error(`éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: ${params.audioKey}`);
          }
          
          audioBytes = new Uint8Array(audioData);
          console.log(`ğŸ“¦ éŸ³é¢‘åŠ è½½å®Œæˆ: ${audioBytes.length} bytes`);
          break;
          
        } catch (audioError) {
          retryCount++;
          console.error(`âŒ éŸ³é¢‘åŠ è½½å¤±è´¥ (å°è¯• ${retryCount}/${maxRetries}):`, audioError);
          
          if (retryCount >= maxRetries) {
            return {
              success: false,
              error: `éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œå·²é‡è¯•${maxRetries}æ¬¡: ${audioError instanceof Error ? audioError.message : String(audioError)}`
            };
          }
          
          // ç­‰å¾…åé‡è¯•
          await new Promise(resolve => setTimeout(resolve, 1000 * retryCount));
        }
      }
      
      // æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æˆåŠŸåŠ è½½
      if (!audioBytes) {
        return {
          success: false,
          error: `éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œå·²é‡è¯•${maxRetries}æ¬¡`
        };
      }
      
      // 2. åˆ›å»ºå¤„ç†å™¨å®ä¾‹ï¼ˆæ•´ä¸ªç›‘å¬å‘¨æœŸå¤ç”¨ï¼‰
      const processor = new StreamingProcessor(
        this.env.AUDIO_SEGMENT_CONTAINER,
        this.env.R2_BUCKET,
        this.env,
        this.env.DB  // ä¼ å…¥DBå®ä¾‹ç”¨äºå®æ—¶æ›´æ–°
      );
      
      // 3. è½®è¯¢çŠ¶æ€
      const pollState = {
        lastProcessedSequence: 0,
        totalSegments: 0,
        totalPolls: 0,
        totalSentencesProcessed: 0,
        allSentenceToSegmentMap: {} as Record<number, string>
      };
      
      // 4. è½®è¯¢ä¸»å¾ªç¯
      while (true) {
        pollState.totalPolls++;
        
        // 4.1 æŸ¥è¯¢æ–°å¥å­ï¼ˆåŸºäºsequenceé€’å¢ï¼‰
        const newSegments = await this.env.DB.prepare(`
          SELECT 
            sequence,
            start_ms as startMs,
            end_ms as endMs,
            speaker,
            original,
            translation,
            content_type,
            is_last
          FROM transcription_segments 
          WHERE transcription_id = ? 
          AND sequence > ?
          ORDER BY sequence ASC
          LIMIT 50
        `).bind(params.transcriptionId, pollState.lastProcessedSequence).all();
        
        if (newSegments.results && newSegments.results.length > 0) {
          const sentenceCount = newSegments.results.length;
          const sequenceRange = `${newSegments.results[0].sequence}-${newSegments.results[sentenceCount-1].sequence}`;
          console.log(`ğŸ“¥ è½®è¯¢#${pollState.totalPolls}: è·å–åˆ° ${sentenceCount} ä¸ªæ–°å¥å­ [${sequenceRange}]`);
          
          // 4.2 è½¬æ¢æ•°æ®æ ¼å¼
          const transcripts = newSegments.results.map((row: any) => ({
            sequence: row.sequence,
            startMs: row.startMs,
            endMs: row.endMs,
            speaker: row.speaker,
            original: row.original,
            translation: row.translation,
            content_type: row.content_type as 'speech' | 'non-speech'
          }));
          
          // 4.3 å¤„ç†æ–°å¥å­ï¼ˆStreamingProcessorä¼šå®æ—¶æ›´æ–°D1ï¼‰
          let result;
          try {
            result = await processor.processTranscripts({
              audioData: audioBytes,
              transcripts,
              outputPrefix: params.outputPrefix,
              transcriptionId: params.transcriptionId
            });
            
            if (!result.success) {
              console.error(`âŒ å¤„ç†éŸ³é¢‘ç‰‡æ®µå¤±è´¥: ${result.error}`);
              // ç»§ç»­å¤„ç†ä¸‹ä¸€æ‰¹ï¼Œä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
              result = { success: true, segments: [], sentenceToSegmentMap: {} };
            }
          } catch (processingError) {
            console.error(`âŒ éŸ³é¢‘å¤„ç†å¼‚å¸¸:`, processingError);
            // å®¹é”™å¤„ç†ï¼šç»§ç»­è½®è¯¢ï¼Œä½†è®°å½•é”™è¯¯
            result = { success: true, segments: [], sentenceToSegmentMap: {} };
          }
          
          // 4.4 æ›´æ–°ç»Ÿè®¡
          pollState.lastProcessedSequence = Math.max(...transcripts.map(t => t.sequence));
          pollState.totalSegments += result.segments?.length || 0;
          pollState.totalSentencesProcessed += sentenceCount;
          Object.assign(pollState.allSentenceToSegmentMap, result.sentenceToSegmentMap);
          
          console.log(`âœ… å¤„ç†å®Œæˆ: ç”Ÿæˆ ${result.segments?.length || 0} ä¸ªéŸ³é¢‘ç‰‡æ®µ`);
          
          // 4.5 æ£€æŸ¥æ˜¯å¦é‡åˆ°æœ€åä¸€ä¸ªå¥å­
          const hasLastSegment = newSegments.results.some((r: any) => r.is_last === 1);
          if (hasLastSegment) {
            console.log(`ğŸ æ£€æµ‹åˆ°æœ€åä¸€ä¸ªå¥å­(is_last=1)ï¼Œç»“æŸè½®è¯¢`);
            break;
          }
        } else {
          console.log(`ğŸ“­ è½®è¯¢#${pollState.totalPolls}: æš‚æ— æ–°å¥å­`);
        }
        
        // 4.6 æ£€æŸ¥è½¬å½•æ˜¯å¦å®Œæˆï¼ˆåŒé‡ä¿é™©ï¼‰
        const transcription = await this.env.DB.prepare(`
          SELECT total_segments, processing_time_ms
          FROM transcriptions 
          WHERE id = ?
        `).bind(params.transcriptionId).first();
        
        if (transcription && 
            transcription.processing_time_ms && 
            typeof transcription.total_segments === 'number' &&
            transcription.total_segments > 0 &&
            pollState.lastProcessedSequence >= transcription.total_segments) {
          console.log(`ğŸ è½¬å½•å·²å®Œæˆï¼Œå·²å¤„ç†æ‰€æœ‰ ${transcription.total_segments} ä¸ªç‰‡æ®µ`);
          break;
        }
        
        // 4.7 åŠ¨æ€è°ƒæ•´è½®è¯¢é—´éš”
        const pollInterval = newSegments.results?.length > 0 ? 2000 : 5000;
        await new Promise(resolve => setTimeout(resolve, pollInterval));
        
        // 4.8 è¶…æ—¶ä¿æŠ¤
        const elapsedTime = Date.now() - startTime;
        if (elapsedTime > 10 * 60 * 1000) { // 10åˆ†é’Ÿ
          console.warn(`âš ï¸ è½®è¯¢è¶…æ—¶(10åˆ†é’Ÿ)ï¼Œå¼ºåˆ¶ç»“æŸ`);
          break;
        }
      }
      
      const totalDuration = Date.now() - startTime;
      console.log(`âœ… éŸ³é¢‘åˆ‡åˆ†ç›‘å¬å®Œæˆ:`);
      console.log(`  - æ€»è€—æ—¶: ${totalDuration}ms`);
      console.log(`  - è½®è¯¢æ¬¡æ•°: ${pollState.totalPolls}`);
      console.log(`  - å¤„ç†å¥å­æ•°: ${pollState.totalSentencesProcessed}`);
      console.log(`  - ç”ŸæˆéŸ³é¢‘ç‰‡æ®µ: ${pollState.totalSegments}`);
      
      return {
        success: true,
        segmentCount: pollState.totalSegments,
        sentenceToSegmentMap: pollState.allSentenceToSegmentMap,
        stats: {
          totalPolls: pollState.totalPolls,
          totalSentencesProcessed: pollState.totalSentencesProcessed,
          totalDuration
        }
      };
      
    } catch (error) {
      console.error(`âŒ éŸ³é¢‘åˆ‡åˆ†ç›‘å¬å¤±è´¥:`, error);
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }
  
  /**
   * éŸ³é¢‘åˆ‡åˆ†æ–¹æ³•ï¼Œä¾›Service Bindingè°ƒç”¨ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
   * æ–°æ¶æ„ï¼šWorker å¤„ç†ä¸šåŠ¡é€»è¾‘ + æ··åˆæ›´æ–°ç­–ç•¥
   */
  async segment(request: AudioSegmentRequest): Promise<AudioSegmentResponse> {
    console.log('[AudioSegmentWorker] æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚:', {
      audioKey: request.audioKey,
      transcriptCount: request.transcripts.length,
      outputPrefix: request.outputPrefix,
      transcriptionId: request.transcriptionId
    });

    try {
      // ğŸ¯ æ­¥éª¤1: Worker ä¸‹è½½éŸ³é¢‘æ•°æ®
      const audioData = await this.downloadAudioFromR2(request.audioKey);
      
      // ğŸ¯ æ­¥éª¤2: Worker æ‰§è¡Œæµå¼å¤„ç†é€»è¾‘
      const segmentConfig: AudioSegmentConfig = {
        gapDurationMs: parseInt(this.env.GAP_DURATION_MS || '500'),
        maxDurationMs: parseInt(this.env.MAX_DURATION_MS || '12000'),
        minDurationMs: parseInt(this.env.MIN_DURATION_MS || '1000'),
        gapThresholdMultiplier: parseInt(this.env.GAP_THRESHOLD_MULTIPLIER || '3')
      };
      
      const segmenter = new AudioSegmenter(segmentConfig);
      const accumulators = segmenter.processTranscriptsStreaming(request.transcripts);
      
      if (accumulators.length === 0) {
        console.log('[AudioSegmentWorker] æ²¡æœ‰éœ€è¦å¤„ç†çš„éŸ³é¢‘ç‰‡æ®µ');
        return { success: true, segments: [], sentenceToSegmentMap: {} };
      }
      
      // ğŸ¯ æ­¥éª¤3: æµå¼å¤„ç†æ¯ä¸ªç´¯ç§¯å™¨ï¼Œå®æ—¶ä¸Šä¼  R2
      const segments = [];
      const d1Updates: Array<{sequence: number, audioKey: string}> = [];
      
      for (const accumulator of accumulators) {
        // ğŸ”„ ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœaccumulatoråªåŒ…å«å¤ç”¨å¥å­ï¼Œè·³è¿‡éŸ³é¢‘ç”Ÿæˆ
        if (accumulator.pendingSentences.length === 0 && accumulator.reusedSentences.length > 0) {
          console.log(`ğŸ”„ è·³è¿‡çº¯å¤ç”¨ç‰‡æ®µ: ${accumulator.generateSegmentId()}, ` +
                      `å¤ç”¨å¥å­æ•°=${accumulator.reusedSentences.length}`);
          
          // ç›´æ¥æ”¶é›† D1 æ›´æ–°æ•°æ®ï¼ˆä½¿ç”¨å·²å­˜åœ¨çš„éŸ³é¢‘keyï¼‰
          if (accumulator.generatedAudioKey) {
            const normalizedAudioUrl = this.normalizeAudioUrl(accumulator.generatedAudioKey);
            
            for (const sentence of accumulator.reusedSentences) {
              d1Updates.push({
                sequence: sentence.sequence,
                audioKey: normalizedAudioUrl
              });
            }
          }
          continue;
        }
        
        // æ£€æŸ¥æ˜¯å¦ç¬¦åˆæœ€å°æ—¶é•¿è¦æ±‚
        if (!segmenter.shouldKeepSegment(accumulator)) {
          console.log(`ğŸ—‘ï¸ è·³è¿‡è¿‡çŸ­ç‰‡æ®µ: ${accumulator.generateSegmentId()}, ` +
                      `æ—¶é•¿=${accumulator.getTotalDuration(segmentConfig.gapDurationMs)}ms < æœ€å°æ—¶é•¿=${segmentConfig.minDurationMs}ms`);
          continue;
        }
        
        // Container å¤„ç†éŸ³é¢‘ï¼ˆåªå¤„ç†pendingSentencesï¼‰
        const segment = await this.processAccumulatorWithContainer(
          accumulator, 
          audioData, 
          request.outputPrefix,
          segmentConfig.gapDurationMs
        );
        
        if (!segment) {
          console.error(`[AudioSegmentWorker] å¤„ç†ç‰‡æ®µå¤±è´¥: ${accumulator.generateSegmentId()}`);
          continue;
        }
        
        // ğŸš€ ç«‹å³ä¸Šä¼ åˆ° R2 ï¼ˆä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼‰
        const relativeAudioKey = segment.audioKey; // è¿™é‡Œæ˜¯ç›¸å¯¹è·¯å¾„
        await this.env.R2_BUCKET.put(relativeAudioKey, segment.audioData, {
          httpMetadata: { contentType: 'audio/wav' }
        });
        
        console.log(`âœ… R2ä¸Šä¼ å®Œæˆ: ${relativeAudioKey}`);
        
        // ğŸ”§ ä¿®å¤ï¼šç”Ÿæˆå®Œæ•´URLç”¨äºD1å­˜å‚¨å’Œå¤ç”¨
        const fullAudioUrl = this.normalizeAudioUrl(relativeAudioKey);
        
        // ğŸ“ æ”¶é›† D1 æ›´æ–°æ•°æ®ï¼ˆä½¿ç”¨å®Œæ•´URLï¼‰
        for (const sentence of accumulator.pendingSentences) {
          d1Updates.push({
            sequence: sentence.sequence,
            audioKey: fullAudioUrl
          });
        }
        
        // ğŸ”„ åŒæ—¶æ”¶é›†å¤ç”¨å¥å­çš„D1æ›´æ–°æ•°æ®ï¼ˆä½¿ç”¨ç›¸åŒçš„éŸ³é¢‘URLï¼‰
        for (const sentence of accumulator.reusedSentences) {
          d1Updates.push({
            sequence: sentence.sequence,
            audioKey: fullAudioUrl
          });
        }
        
        // ğŸ”§ æ›´æ–°segmentè¿”å›çš„audioKeyä¸ºå®Œæ•´URL
        segment.audioKey = fullAudioUrl;
        
        // ç§»é™¤ audioData å‡å°‘å†…å­˜å ç”¨
        delete segment.audioData;
        segments.push(segment);
      }
      
      // ğŸ¯ æ­¥éª¤4: æ‰¹é‡æ›´æ–° D1 æ•°æ®åº“
      if (d1Updates.length > 0 && request.transcriptionId) {
        await this.batchUpdateD1AudioKeys(request.transcriptionId, d1Updates);
        console.log(`âœ… D1æ‰¹é‡æ›´æ–°å®Œæˆ: ${d1Updates.length} æ¡è®°å½•`);
      }
      
      // ğŸ¯ æ­¥éª¤5: ç”Ÿæˆå¥å­æ˜ å°„å…³ç³»
      const sentenceToSegmentMap: Record<number, string> = {};
      for (const accumulator of accumulators) {
        const segmentId = accumulator.generateSegmentId();
        // æ˜ å°„å¾…å¤„ç†å¥å­
        for (const sentence of accumulator.pendingSentences) {
          sentenceToSegmentMap[sentence.sequence] = segmentId;
        }
        // ğŸ”„ æ˜ å°„å¤ç”¨å¥å­
        for (const sentence of accumulator.reusedSentences) {
          sentenceToSegmentMap[sentence.sequence] = segmentId;
        }
      }
      
      console.log('[AudioSegmentWorker] åˆ‡åˆ†å®Œæˆ:', {
        success: true,
        segmentCount: segments.length,
        d1UpdateCount: d1Updates.length
      });

      return {
        success: true,
        segments,
        sentenceToSegmentMap
      };

    } catch (error) {
      console.error('[AudioSegmentWorker] å¤„ç†å¤±è´¥:', error);
      return {
        success: false,
        error: error instanceof Error ? error.message : 'Unknown error'
      };
    }
  }

  /**
   * ä» R2 ä¸‹è½½éŸ³é¢‘æ–‡ä»¶
   */
  private async downloadAudioFromR2(audioKey: string): Promise<ArrayBuffer> {
    console.log(`ğŸ“¥ ä» R2 ä¸‹è½½éŸ³é¢‘: ${audioKey}`);
    
    // ğŸ”§ ä¿®å¤ï¼šæ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œè°ƒè¯•æ—¥å¿—
    try {
      const audioObject = await this.env.R2_BUCKET.get(audioKey);
      if (!audioObject) {
        // åˆ—å‡ºR2æ¡¶ä¸­çš„æ–‡ä»¶è¿›è¡Œè°ƒè¯•
        console.error(`âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: ${audioKey}`);
        
        // å°è¯•åˆ—å‡ºç›¸è¿‘çš„æ–‡ä»¶ï¼ˆç”¨äºè°ƒè¯•ï¼‰
        const list = await this.env.R2_BUCKET.list({ prefix: audioKey.split('/')[0] || '', limit: 5 });
        console.log(`ğŸ” R2æ¡¶ä¸­ç›¸è¿‘æ–‡ä»¶:`, list.objects.map(obj => obj.key));
        
        throw new Error(`éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: ${audioKey} (è¯·æ£€æŸ¥R2æ¡¶ä¸­æ˜¯å¦æœ‰æ­¤æ–‡ä»¶)`);
      }
      
      const audioData = await audioObject.arrayBuffer();
      if (audioData.byteLength === 0) {
        throw new Error(`éŸ³é¢‘æ–‡ä»¶ä¸ºç©º: ${audioKey}`);
      }
      
      console.log(`ğŸ“¥ éŸ³é¢‘ä¸‹è½½å®Œæˆ: ${audioData.byteLength} bytes`);
      return audioData;
      
    } catch (error) {
      console.error(`âŒ R2éŸ³é¢‘ä¸‹è½½å¤±è´¥: ${audioKey}`, error);
      throw error;
    }
  }

  /**
   * ä½¿ç”¨ Container å¤„ç†å•ä¸ªç´¯ç§¯å™¨
   */
  private async processAccumulatorWithContainer(
    accumulator: StreamingAccumulator,
    audioData: ArrayBuffer,
    outputPrefix: string,
    gapDurationMs: number
  ): Promise<any> {
    // ğŸ”§ ä¿®å¤ï¼šå‚æ•°éªŒè¯
    if (!outputPrefix || !outputPrefix.trim()) {
      console.error(`âŒ outputPrefixä¸ºç©ºæˆ–æ— æ•ˆ: "${outputPrefix}"`);
      return null;
    }
    
    const segmentId = accumulator.generateSegmentId();
    const audioKey = accumulator.generateAudioKey(outputPrefix); // ç›¸å¯¹è·¯å¾„
    
    console.log(`ğŸµ å¤„ç†éŸ³é¢‘ç‰‡æ®µ: ${segmentId}, æ—¶é—´èŒƒå›´: ${accumulator.timeRanges.length}æ®µ`);
    
    // è·å– Container å®ä¾‹
    const container = this.env.AUDIO_SEGMENT_CONTAINER.get(
      this.env.AUDIO_SEGMENT_CONTAINER.idFromName("audio-segment")
    );
    
    // è°ƒç”¨ Container çš„æ ¹è·¯å¾„æ¥å£ - ç±»ä¼¼FFmpeg Containeræ¨¡å¼
    const response = await container.fetch(new Request('https://audio-segment/', {
      method: 'POST',
      body: audioData,
      headers: {
        'Content-Type': 'application/octet-stream',
        'X-Time-Ranges': JSON.stringify(accumulator.timeRanges),
        'X-Segment-Id': segmentId,
        'X-Speaker': accumulator.speaker,
        'X-Gap-Duration': gapDurationMs.toString()
      }
    }));
    
    if (!response.ok) {
      const error = await response.text();
      console.error(`Container å¤„ç†å¤±è´¥: ${error}`);
      return null;
    }
    
    const result = await response.arrayBuffer();
    
    return {
      segmentId,
      audioKey,
      speaker: accumulator.speaker,
      startMs: accumulator.timeRanges[0][0],
      endMs: accumulator.timeRanges[accumulator.timeRanges.length - 1][1],
      durationMs: accumulator.getTotalDuration(gapDurationMs),
      sentences: accumulator.getAllSentences().map((s: any) => ({
        sequence: s.sequence,
        original: s.original,
        translation: s.translation
      })),
      audioData: result  // ç”¨äº R2 ä¸Šä¼ 
    };
  }

  /**
   * æ‰¹é‡æ›´æ–° D1 æ•°æ®åº“ä¸­çš„ audio_key å­—æ®µ
   */
  private async batchUpdateD1AudioKeys(
    transcriptionId: string,
    updates: Array<{sequence: number, audioKey: string}>
  ): Promise<void> {
    console.log(`ğŸ’¾ å¼€å§‹æ‰¹é‡æ›´æ–° D1: transcriptionId=${transcriptionId}, æ›´æ–°æ•°é‡=${updates.length}`);
    
    // ğŸš€ æŒ‰ audioKey åˆ†ç»„ï¼Œå‡å°‘ SQL è°ƒç”¨æ¬¡æ•°
    const groupedUpdates = new Map<string, number[]>();
    
    for (const update of updates) {
      if (!groupedUpdates.has(update.audioKey)) {
        groupedUpdates.set(update.audioKey, []);
      }
      groupedUpdates.get(update.audioKey)!.push(update.sequence);
    }
    
    console.log(`ğŸ“ åˆ†ç»„ä¼˜åŒ–: ${updates.length} æ¡æ›´æ–° â†’ ${groupedUpdates.size} ä¸ªSQLè¯­å¥`);
    
    // ğŸ¯ å¹¶è¡Œæ‰§è¡Œåˆ†ç»„æ›´æ–°
    const updatePromises = Array.from(groupedUpdates.entries()).map(
      async ([audioKey, sequences]) => {
        try {
          const placeholders = sequences.map(() => '?').join(',');
          
          const result = await this.env.DB.prepare(`
            UPDATE transcription_segments 
            SET audio_key = ? 
            WHERE transcription_id = ? 
            AND sequence IN (${placeholders})
          `).bind(audioKey, transcriptionId, ...sequences).run();
          
          console.log(`âœ… D1æ›´æ–°æˆåŠŸ: ${audioKey} â†’ ${sequences.length}å¥ (å½±å“${result.meta.changes}è¡Œ)`);
          
          return { success: true, audioKey, updateCount: sequences.length, changes: result.meta.changes };
        } catch (error) {
          console.error(`âŒ D1æ›´æ–°å¤±è´¥: ${audioKey}`, error);
          return { success: false, audioKey, error: error instanceof Error ? error.message : 'Unknown error' };
        }
      }
    );
    
    // ç­‰å¾…æ‰€æœ‰æ›´æ–°å®Œæˆ
    const results = await Promise.all(updatePromises);
    
    // ç»Ÿè®¡ç»“æœ
    const successCount = results.filter(r => r.success).length;
    const failureCount = results.filter(r => !r.success).length;
    const totalChanges = results
      .filter(r => r.success && 'changes' in r)
      .reduce((sum, r) => sum + (r.changes || 0), 0);
    
    console.log(`ğŸ“Š D1æ‰¹é‡æ›´æ–°å®Œæˆ: æˆåŠŸ${successCount}/${results.length}, æ€»å½±å“è¡Œæ•°=${totalChanges}`);
    
    if (failureCount > 0) {
      const failures = results.filter(r => !r.success);
      console.warn(`âš ï¸ éƒ¨åˆ†æ›´æ–°å¤±è´¥:`, failures.map(f => ({ audioKey: f.audioKey, error: f.error })));
    }
  }

  // ğŸ”¥ ç§»é™¤fetchæ–¹æ³•ï¼Œä¿æŒWorkerEntrypointçº¯å‡€ï¼Œåªå¤„ç†RPCè°ƒç”¨
}


// æ·»åŠ  /segment è·¯ç”±åˆ°ä¸»åº”ç”¨ - ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨é™æ€å®ä¾‹è°ƒç”¨
app.post('/segment', async (c) => {
  try {
    const data = await c.req.json() as AudioSegmentRequest;
    
    console.log('[HTTP /segment] æ”¶åˆ°åˆ‡åˆ†è¯·æ±‚:', {
      audioKey: data.audioKey,
      transcriptCount: data.transcripts?.length || 0,
      outputPrefix: data.outputPrefix,
      transcriptionId: data.transcriptionId
    });

    // ğŸ¯ ä¿®å¤ï¼šåˆ›å»º AudioSegmentWorker å®ä¾‹ç”¨äºHTTPè°ƒç”¨
    const worker = new AudioSegmentWorker(c.executionCtx, c.env);
    const result = await worker.segment(data);

    console.log('[HTTP /segment] å¤„ç†å®Œæˆ:', {
      success: result.success,
      segmentCount: result.segments?.length || 0,
      hasTranscriptionId: !!data.transcriptionId
    });

    return c.json(result);
    
  } catch (error) {
    console.error('[HTTP /segment] å¤„ç†å¤±è´¥:', error);
    
    return c.json({
      success: false,
      error: error instanceof Error ? error.message : 'Request processing failed'
    });
  }
});

// å¯¼å‡º - ğŸ”§ ä¿®å¤Service Binding entrypointé—®é¢˜  
export { AudioSegmentContainer };
// AudioSegmentWorkerå·²åœ¨ç±»å®šä¹‰å¤„exportï¼Œæ— éœ€é‡å¤å¯¼å‡º

// HTTPå¤„ç†å™¨ - å¤„ç†æ™®é€šHTTPè¯·æ±‚ï¼ˆå¥åº·æ£€æŸ¥ã€è°ƒè¯•ç­‰ï¼‰
export default {
  async fetch(request: Request, env: Env): Promise<Response> {
    return app.fetch(request, env);
  }
};