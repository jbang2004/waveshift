import { WorkflowEntrypoint, WorkflowStep, WorkflowEvent } from 'cloudflare:workers';
import { Env, SepTransWorkflowParams } from './types/env.d';
import { updateMediaTaskStatus, updateMediaTaskUrls, createTranscription, completeMediaTask, setMediaTaskError, updateTranscriptionTotalSegments, markLastTranscriptionSegment } from './utils/database';
import { createMediaUrlManager } from './utils/url-utils';
import { 
  initRealtimeMergeState, 
  processSegmentRealtime, 
  storeSegmentToD1, 
  TranscriptionSegment,
  RealtimeMergeState 
} from './utils/transcription-merger';

export class SepTransWorkflow extends WorkflowEntrypoint<Env, SepTransWorkflowParams> {
	async run(event: WorkflowEvent<SepTransWorkflowParams>, step: WorkflowStep) {
		const env = this.env;
		const { originalFile, fileType, options } = event.payload;
		const taskId = event.instanceId;
		
		console.log(`ÂºÄÂßã SepTransWorkflow ‰ªªÂä°: ${taskId}, Êñá‰ª∂Á±ªÂûã: ${fileType}`);
		
		try {
			// Ê≠•È™§0: Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ‰∏∫ÂàÜÁ¶ª‰∏≠
			await step.do("update-status-separating", async () => {
				console.log(`Ê≠•È™§0: Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ‰∏∫ÂàÜÁ¶ª‰∏≠ ${taskId}`);
				await updateMediaTaskStatus(env, taskId, 'separating', 10);
			});
			
			// Ê≠•È™§1: Èü≥ËßÜÈ¢ëÂàÜÁ¶ª (ÂßîÊâòÁªô ffmpeg-worker)
			const { audioUrl, videoUrl, audioKey } = await step.do("separate-media", async () => {
				console.log(`Ê≠•È™§1: ÂºÄÂßãÈü≥ËßÜÈ¢ëÂàÜÁ¶ª ${taskId}`);
				
				// ‰ªéÂéüÂßãÊñá‰ª∂Ë∑ØÂæÑ‰∏≠ÊèêÂèñuserIdÔºàÊ†ºÂºè: users/{userId}/{taskId}/original.{ext}Ôºâ
				const pathParts = originalFile.split('/');
				const userId = pathParts[1];
				
				// ÂÆö‰πâËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑÔºà‰øùÂ≠òÂú®Âêå‰∏ÄÁõÆÂΩï‰∏ãÔºâ
				const audioOutputKey = `users/${userId}/${taskId}/audio.aac`;
				const videoOutputKey = `users/${userId}/${taskId}/video.mp4`;
				
				// Ë∞ÉÁî® ffmpeg-worker (Service Binding)
				const result = await env.FFMPEG_SERVICE.separate({
					inputKey: originalFile,
					audioOutputKey,
					videoOutputKey
				});
				
				// ‰ΩøÁî®Áªü‰∏ÄÁöÑURLÁÆ°ÁêÜÂô®ÁîüÊàêÂÖ¨ÂÖ±URL
				const urlManager = createMediaUrlManager(env.R2_PUBLIC_DOMAIN);
				const audioUrl = urlManager.buildPublicUrl(audioOutputKey);
				const videoUrl = urlManager.buildPublicUrl(videoOutputKey);
				
				// Êõ¥Êñ∞Êï∞ÊçÆÂ∫ì (Â≠òÂÇ®Áõ∏ÂØπË∑ØÂæÑËÄåÈùûÂÆåÊï¥URL)
				await updateMediaTaskUrls(env, taskId, audioOutputKey, videoOutputKey);
				await updateMediaTaskStatus(env, taskId, 'transcribing', 40);
				
				console.log(`Èü≥ËßÜÈ¢ëÂàÜÁ¶ªÂÆåÊàê - ËßÜÈ¢ë: ${videoUrl}, Èü≥È¢ë: ${audioUrl}`);
				console.log(`Êñá‰ª∂Â§ßÂ∞è - ËßÜÈ¢ë: ${result.videoSize} bytes, Èü≥È¢ë: ${result.audioSize} bytes`);
				
				return { 
					audioKey: audioOutputKey, 
					videoKey: videoOutputKey,
					audioUrl,
					videoUrl
				};
			});
			
			// Ê≠•È™§2: ÂàõÂª∫ËΩ¨ÂΩïËÆ∞ÂΩïÔºà‰∏∫Âπ∂Ë°åÂ§ÑÁêÜÂáÜÂ§áÔºâ
			const transcriptionId = await step.do("create-transcription", async () => {
				const id = await createTranscription(
					env,
					taskId,
					options.targetLanguage,
					options.style || 'normal',
					{ startTime: new Date().toISOString() }
				);
				console.log(`üìù ÂàõÂª∫ËΩ¨ÂΩïËÆ∞ÂΩï: ${id}`);
				return id;
			});
			
			// üî• Ê≠•È™§3: Âπ∂Ë°åÂ§ÑÁêÜ - ÂêåÊó∂ÂêØÂä®ËΩ¨ÂΩïÂíåÈü≥È¢ëÂàáÂàÜ
			const parallelStartTime = Date.now();
			console.log(`üöÄ ÂºÄÂßãÂπ∂Ë°åÂ§ÑÁêÜ: ËΩ¨ÂΩï + Èü≥È¢ëÂàáÂàÜ`);
			
			const [transcriptionResult, audioSegmentResult] = await Promise.all([
				// 3a. ËΩ¨ÂΩïÊúçÂä°ÔºàÊµÅÂºèÂÜôÂÖ•D1Ôºâ
				step.do("realtime-transcribe", async () => {
					console.log(`üéôÔ∏è ÂêØÂä®ËΩ¨ÂΩïÊúçÂä°...`);
					return await this.runTranscription(env, {
						audioKey,
						transcriptionId,
						options,
						taskId
					});
				}),
				
				// 3b. Èü≥È¢ëÂàáÂàÜÊúçÂä°ÔºàËΩÆËØ¢D1Ôºâ
				step.do("watch-audio-segment", async () => {
					// ÁªôËΩ¨ÂΩïÊúçÂä°‰∏ÄÁÇπÂêØÂä®Êó∂Èó¥ÔºåÈÅøÂÖçÁ©∫ËΩÆËØ¢
					console.log(`‚è≥ Á≠âÂæÖ3ÁßíÂêéÂêØÂä®Èü≥È¢ëÂàáÂàÜ...`);
					await new Promise(resolve => setTimeout(resolve, 3000));
					
					console.log(`‚úÇÔ∏è ÂêØÂä®Èü≥È¢ëÂàáÂàÜÊúçÂä°...`);
					const pathParts = originalFile.split('/');
					const userId = pathParts[1];
					const outputPrefix = `users/${userId}/${taskId}/audio-segments`;
					
					return await env.AUDIO_SEGMENT_SERVICE.watch({
						audioKey,
						transcriptionId,
						outputPrefix,
						taskId
					});
				})
			]);
			
			const parallelDuration = Date.now() - parallelStartTime;
			console.log(`‚úÖ Âπ∂Ë°åÂ§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: ${parallelDuration}ms`);
			
			// Ê≠•È™§4: ÂÆåÊàêÂ§ÑÁêÜ
			await step.do("finalize", async () => {
				await completeMediaTask(env, taskId, true);
				const totalDuration = Date.now() - parallelStartTime;
				console.log(`üìä Â§ÑÁêÜÁªüËÆ°:`);
				console.log(`  - ÊÄªËÄóÊó∂: ${totalDuration}ms`);
				console.log(`  - Âπ∂Ë°åÂ§ÑÁêÜËÄóÊó∂: ${parallelDuration}ms`);
				console.log(`  - ËΩ¨ÂΩïÁâáÊÆµÊï∞: ${transcriptionResult.totalSegments}`);
				console.log(`  - Èü≥È¢ëÂàáÁâáÊï∞: ${audioSegmentResult.segmentCount}`);
				console.log(`  - ËßÜÈ¢ëURL: ${videoUrl}`);
				console.log(`  - Èü≥È¢ëURL: ${audioUrl}`);
			});
			
				
				// 3. Ëé∑ÂèñÈü≥È¢ëÊï∞ÊçÆÂπ∂ÂèëÈÄÅËΩ¨ÂΩïËØ∑Ê±Ç
				const audioObject = await env.MEDIA_STORAGE.get(audioKey);
				if (!audioObject) {
					throw new Error(`R2 Èü≥È¢ëÂØπË±°Êú™ÊâæÂà∞: ${audioKey}`);
				}
				const audioData = await audioObject.arrayBuffer();
				console.log(`Èü≥È¢ëËØªÂèñÂÆåÊàêÔºåÂ§ßÂ∞è: ${audioData.byteLength} bytes`);
				
				// 4. ÂèëÈÄÅËΩ¨ÂΩïËØ∑Ê±Ç
				const formData = new FormData();
				formData.append('file', new Blob([audioData], { type: 'audio/aac' }), 'audio.aac');
				formData.append('targetLanguage', options.targetLanguage);
				formData.append('style', options.style || 'normal');

				const result = await env.TRANSCRIBE_SERVICE.fetch(new Request('https://transcribe/transcribe', {
					method: 'POST',
					body: formData
				}));

				if (!result.ok) {
					throw new Error(`ËΩ¨ÂΩïÊúçÂä°Ë∞ÉÁî®Â§±Ë¥•: ${result.status}`);
				}

				// 5. ÂÆûÊó∂Â§ÑÁêÜSSEÊµÅ
				const reader = result.body?.getReader();
				if (!reader) {
					throw new Error('Êó†Ê≥ïËØªÂèñËΩ¨ÂΩïÊúçÂä°ÂìçÂ∫îÊµÅ');
				}

				const decoder = new TextDecoder();
				let metadata: any = null;
				
				// üî• Êî∂ÈõÜÊâÄÊúâÂ∑≤Â≠òÂÇ®ÁöÑsegments
				const allStoredSegments: TranscriptionSegment[] = [];

				// Êó∂Èó¥Ê†ºÂºèËß£ÊûêÂáΩÊï∞: "XmYsZms" -> ÊØ´ÁßíÊï∞
				const parseTimeToMs = (timeStr: string): number => {
					const match = timeStr.match(/(\d+)m(\d+)s(\d+)ms/);
					if (!match) return 0;
					const [, minutes, seconds, ms] = match;
					return parseInt(minutes) * 60000 + parseInt(seconds) * 1000 + parseInt(ms);
				};

				try {
					while (true) {
						const { done, value } = await reader.read();
						if (done) break;

						const chunk = decoder.decode(value, { stream: true });
						const lines = chunk.split('\n');

						for (const line of lines) {
							if (line.startsWith('data: ')) {
								try {
									const data = JSON.parse(line.slice(6));

									if (data.type === 'start') {
										metadata = data.metadata;
										console.log(`üéØ ÂºÄÂßãÂÆûÊó∂ËΩ¨ÂΩïÂ§ÑÁêÜ: ${metadata.fileName}`);
									} else if (data.type === 'segment') {
										// ÊûÑÈÄ†ËΩ¨ÂΩïÁâáÊÆµ
										const segment: TranscriptionSegment = {
											sequence: data.segment.sequence,
											start_ms: parseTimeToMs(data.segment.start || '0m0s0ms'),
											end_ms: parseTimeToMs(data.segment.end || '0m0s0ms'),
											content_type: data.segment.content_type || 'speech',
											speaker: data.segment.speaker || 'unknown',
											original: data.segment.original || '',
											translation: data.segment.translation || ''
										};
										
										// üî• Ê†∏ÂøÉÊîπËøõÔºöÂÆûÊó∂Â§ÑÁêÜÊØè‰∏™ÁâáÊÆµ
										const storedSegment = await processSegmentRealtime(env, mergeState, segment);
										
										// üî• Êî∂ÈõÜÂ∑≤Â≠òÂÇ®ÁöÑsegmentÔºàÂ¶ÇÊûúÊúâÔºâ
										if (storedSegment) {
											allStoredSegments.push(storedSegment);
										}
									} else if (data.type === 'error') {
										throw new Error(`ËΩ¨ÂΩïÊúçÂä°ÈîôËØØ: ${data.error}`);
									}
								} catch (parseError) {
									// ÂøΩÁï•Ëß£ÊûêÈîôËØØÁöÑË°å
								}
							}
						}
					}
				} finally {
					reader.releaseLock();
				}

				// 6. Â§ÑÁêÜÊúÄÂêé‰∏Ä‰∏™ÂæÖÂêàÂπ∂ÁöÑÁªÑ
				if (mergeState.currentGroup) {
					const isFirst = !mergeState.isFirstSegmentStored;
					await storeSegmentToD1(env, mergeState.transcriptionId, mergeState.currentGroup, ++mergeState.lastStoredSequence, isFirst);
					console.log(`üíæ Â≠òÂÇ®ÊúÄÂêé‰∏Ä‰∏™ÂêàÂπ∂ÁªÑ: sequence=${mergeState.lastStoredSequence}, is_first=${isFirst}`);
					
					// üî• Êî∂ÈõÜÊúÄÂêé‰∏Ä‰∏™Â≠òÂÇ®ÁöÑsegment
					allStoredSegments.push({
						...mergeState.currentGroup,
						sequence: mergeState.lastStoredSequence,
						is_first: isFirst,
						is_last: false
					});
				}

				// 7. Ê†áËÆ∞ÊúÄÂêé‰∏Ä‰∏™ÁâáÊÆµ‰∏∫ is_last=true
				if (mergeState.lastStoredSequence > 0) {
					await markLastTranscriptionSegment(env, transcriptionId);
					console.log(`üèÅ Ê†áËÆ∞ÊúÄÂêéÁâáÊÆµÂÆåÊàê: transcription_id=${transcriptionId}`);
					
					// üî• Êõ¥Êñ∞ÊúÄÂêé‰∏Ä‰∏™segmentÁöÑis_lastÊ†áËÆ∞
					if (allStoredSegments.length > 0) {
						allStoredSegments[allStoredSegments.length - 1].is_last = true;
					}
				}

				// 8. Êõ¥Êñ∞ËΩ¨ÂΩïËÆ∞ÂΩïÁöÑÊÄªÁâáÊÆµÊï∞
				await updateTranscriptionTotalSegments(env, transcriptionId, mergeState.lastStoredSequence);
				
				// 9. Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ
				await updateMediaTaskStatus(env, taskId, 'completed', 90);
				
				console.log(`‚úÖ ÂÆûÊó∂ËΩ¨ÂΩïÂÆåÊàê: ID=${transcriptionId}, ÊúÄÁªàÁâáÊÆµÊï∞=${mergeState.lastStoredSequence}`);
				console.log(`üìä Êî∂ÈõÜÂà∞ ${allStoredSegments.length} ‰∏™Â∑≤Â≠òÂÇ®ÁöÑsegments`);
				
				return {
					transcriptionId,
					totalSegments: mergeState.lastStoredSequence,
					metadata,
					segments: allStoredSegments  // üî• ËøîÂõûÊâÄÊúâÂ∑≤Â≠òÂÇ®ÁöÑsegments
				};
			});
			
			// Ê≠•È™§3: Èü≥È¢ëÂàáÂàÜ (Êñ∞Â¢û)
			const audioSegmentResult = await step.do("audio-segment", async () => {
				console.log(`Ê≠•È™§3: ÂºÄÂßãÈü≥È¢ëÂàáÂàÜ ${taskId}`);
				
				// üî• ‰ΩøÁî®‰∏ä‰∏ÄÊ≠•Êî∂ÈõÜÁöÑÊï∞ÊçÆÔºåÈÅøÂÖçÊü•ËØ¢D1
				if (!transcriptionResult.segments || transcriptionResult.segments.length === 0) {
					console.log(`Ë∑≥ËøáÈü≥È¢ëÂàáÂàÜ: Ê≤°ÊúâËΩ¨ÂΩïÊï∞ÊçÆ`);
					return { success: false, message: 'Ê≤°ÊúâËΩ¨ÂΩïÊï∞ÊçÆ' };
				}
				
				// üî• Áõ¥Êé•‰ΩøÁî®ÊØ´ÁßíÊ†ºÂºèÔºåÊ∂àÈô§ÂÜó‰ΩôËΩ¨Êç¢
				const transcripts = transcriptionResult.segments.map((segment: TranscriptionSegment) => ({
					sequence: segment.sequence,
					startMs: segment.start_ms,
					endMs: segment.end_ms,
					speaker: segment.speaker,
					original: segment.original,
					translation: segment.translation,
					content_type: segment.content_type
				}));
				
				console.log(`üéØ ËΩ¨ÂΩïÊï∞ÊçÆÊ†∑Êú¨ (Ââç3Êù°):`, transcripts.slice(0, 3).map(t => ({
					sequence: t.sequence,
					timeRange: `${t.startMs}ms - ${t.endMs}ms`,
					speaker: t.speaker,
					text: t.original.substring(0, 30) + '...'
				})));
				
				console.log(`ÂáÜÂ§áÂàáÂàÜÈü≥È¢ë: ÂÖ± ${transcripts.length} ‰∏™ËΩ¨ÂΩïÁâáÊÆµ`);
				
				// 3. Ë∞ÉÁî®Èü≥È¢ëÂàáÂàÜÊúçÂä°
				const pathParts = originalFile.split('/');
				const userId = pathParts[1];
				const outputPrefix = `users/${userId}/${taskId}/audio-segments`;
				
				const result = await env.AUDIO_SEGMENT_SERVICE.segment({
					audioKey: audioKey,
					transcripts,
					outputPrefix,
					transcriptionId: transcriptionResult.transcriptionId  // üîß ‰øÆÂ§çÔºöÊ∑ªÂä†ËΩ¨ÂΩïIDÁî®‰∫éD1Êõ¥Êñ∞
					// Ê≥®ÊÑèÔºöÂàáÂàÜÂèÇÊï∞Áé∞Âú®ÈÄöËøáÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÔºöGAP_DURATION_MS, MAX_DURATION_MS, MIN_DURATION_MS
				});
				
				if (!result.success) {
					console.error(`Èü≥È¢ëÂàáÂàÜÂ§±Ë¥•: ${result.error}`);
					return { success: false, error: result.error };
				}
				
				console.log(`‚úÖ Èü≥È¢ëÂàáÂàÜÂÆåÊàê: ÁîüÊàê ${result.segments?.length || 0} ‰∏™Èü≥È¢ëÁâáÊÆµ`);
				
				// 4. Â∞ÜÂàáÂàÜ‰ø°ÊÅØÂ≠òÂÇ®Âà∞Êï∞ÊçÆÂ∫ì(ÂèØÈÄâ)
				if (result.segments && result.segments.length > 0) {
					// ÂèØ‰ª•Âú®ËøôÈáåÂ≠òÂÇ®Èü≥È¢ëÁâáÊÆµ‰ø°ÊÅØÂà∞Êï∞ÊçÆÂ∫ì
					console.log(`üéµ Èü≥È¢ëÂàáÁâáËØ¶ÊÉÖ:`, result.segments.map(s => ({
						id: s.segmentId,
						speaker: s.speaker,
						duration: `${s.durationMs}ms`,
						sentences: s.sentences.length
					})));
				}
				
				return {
					success: true,
					segmentCount: result.segments?.length || 0,
					sentenceToSegmentMap: result.sentenceToSegmentMap
				};
			});
			
			// Ê≠•È™§4: Ê∏ÖÁêÜ‰∏¥Êó∂Êñá‰ª∂ÔºàÂéüÂßãÊñá‰ª∂‰øùÁïôÂú®videosÊ°∂Ôºâ
			await step.do("cleanup", async () => {
				console.log(`Ê≠•È™§4: Ê∏ÖÁêÜÂÆåÊàêÔºå‰øùÁïôÂéüÂßãÊñá‰ª∂: ${originalFile}`);
				// ‰∏çÂà†Èô§ÂéüÂßãÊñá‰ª∂Ôºå‰øùÁïôÂú®videosÊ°∂‰∏≠‰æõÁî®Êà∑‰∏ãËΩΩ
			});
			
			// Ê≠•È™§5: Êõ¥Êñ∞ÊúÄÁªàÁä∂ÊÄÅ
			await step.do("finalize", async () => {
				console.log(`Ê≠•È™§5: ‰ªªÂä°ÂÆåÊàê ${taskId}`);
				
				await completeMediaTask(env, taskId, true);
				
				console.log(`SepTransWorkflow ÊàêÂäüÂÆåÊàê: ${taskId}`);
			});
			
			// Ê≠•È™§6: ÂÆåÊàêÊó•Âøó
			await step.do("complete-logging", async () => {
				console.log(`Ê≠•È™§6: Â∑•‰ΩúÊµÅÂÆåÊàê ${taskId}`);
				console.log(`üìä ÁªìÊûúÁªüËÆ°: ËßÜÈ¢ë=${videoUrl}, Èü≥È¢ë=${audioUrl}, ËΩ¨ÂΩïÁâáÊÆµ=${transcriptionResult.totalSegments}, Èü≥È¢ëÂàáÁâá=${audioSegmentResult.segmentCount}`);
			});
			
		} catch (error: any) {
			console.error(`SepTransWorkflow Â§±Ë¥•: ${taskId}`, error);
			
			// Êõ¥Êñ∞‰ªªÂä°Áä∂ÊÄÅ‰∏∫Â§±Ë¥•
			await step.do("mark-failed", async () => {
				await setMediaTaskError(env, taskId, error.message, error.stack);
			});
			
			// ËÆ∞ÂΩïÈîôËØØ‰ø°ÊÅØ
			await step.do("log-error", async () => {
				console.error(`‚ùå Â∑•‰ΩúÊµÅÂ§±Ë¥•ËØ¶ÊÉÖ ${taskId}:`, {
					message: error.message,
					stack: error.stack?.substring(0, 500)
				});
			});
			
			throw error;
		}
	}
}