import { WorkflowEntrypoint, WorkflowStep, WorkflowEvent } from 'cloudflare:workers';
import { Env, SepTransWorkflowParams } from './types/env.d';
import { updateMediaTaskStatus, updateMediaTaskUrls, createTranscription, completeMediaTask, setMediaTaskError, updateTranscriptionTotalSegments, markLastTranscriptionSegment } from './utils/database';
import { createMediaUrlManager } from './utils/url-utils';
import { 
  initRealtimeMergeState, 
  processSegmentRealtime, 
  storeSegmentToD1, 
  TranscriptionSegment,
  RealtimeMergeState 
} from './utils/transcription-merger';

export class SepTransWorkflow extends WorkflowEntrypoint<Env, SepTransWorkflowParams> {
	async run(event: WorkflowEvent<SepTransWorkflowParams>, step: WorkflowStep) {
		const env = this.env;
		const { originalFile, fileType, options } = event.payload;
		const taskId = event.instanceId;
		
		console.log(`å¼€å§‹ SepTransWorkflow ä»»åŠ¡: ${taskId}, æ–‡ä»¶ç±»å‹: ${fileType}`);
		
		try {
			// æ­¥éª¤0: æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºåˆ†ç¦»ä¸­
			await step.do("update-status-separating", async () => {
				console.log(`æ­¥éª¤0: æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºåˆ†ç¦»ä¸­ ${taskId}`);
				await updateMediaTaskStatus(env, taskId, 'separating', 10);
			});
			
			// æ­¥éª¤1: éŸ³è§†é¢‘åˆ†ç¦» (å§”æ‰˜ç»™ ffmpeg-worker)
			const { audioUrl, videoUrl, audioKey } = await step.do("separate-media", async () => {
				console.log(`æ­¥éª¤1: å¼€å§‹éŸ³è§†é¢‘åˆ†ç¦» ${taskId}`);
				
				// ä»åŸå§‹æ–‡ä»¶è·¯å¾„ä¸­æå–userIdï¼ˆæ ¼å¼: users/{userId}/{taskId}/original.{ext}ï¼‰
				const pathParts = originalFile.split('/');
				const userId = pathParts[1];
				
				// å®šä¹‰è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆä¿å­˜åœ¨åŒä¸€ç›®å½•ä¸‹ï¼‰
				const audioOutputKey = `users/${userId}/${taskId}/audio.aac`;
				const videoOutputKey = `users/${userId}/${taskId}/video.mp4`;
				
				// è°ƒç”¨ ffmpeg-worker (Service Binding)
				const result = await env.FFMPEG_SERVICE.separate({
					inputKey: originalFile,
					audioOutputKey,
					videoOutputKey
				});
				
				// ä½¿ç”¨ç»Ÿä¸€çš„URLç®¡ç†å™¨ç”Ÿæˆå…¬å…±URL
				const urlManager = createMediaUrlManager(env.R2_PUBLIC_DOMAIN);
				const audioUrl = urlManager.buildPublicUrl(audioOutputKey);
				const videoUrl = urlManager.buildPublicUrl(videoOutputKey);
				
				// æ›´æ–°æ•°æ®åº“ (å­˜å‚¨ç›¸å¯¹è·¯å¾„è€Œéå®Œæ•´URL)
				await updateMediaTaskUrls(env, taskId, audioOutputKey, videoOutputKey);
				await updateMediaTaskStatus(env, taskId, 'transcribing', 40);
				
				console.log(`éŸ³è§†é¢‘åˆ†ç¦»å®Œæˆ - è§†é¢‘: ${videoUrl}, éŸ³é¢‘: ${audioUrl}`);
				console.log(`æ–‡ä»¶å¤§å° - è§†é¢‘: ${result.videoSize} bytes, éŸ³é¢‘: ${result.audioSize} bytes`);
				
				return { 
					audioKey: audioOutputKey, 
					videoKey: videoOutputKey,
					audioUrl,
					videoUrl
				};
			});
			
			// æ­¥éª¤2: å®æ—¶è½¬å½•å’Œå­˜å‚¨
			const transcriptionResult = await step.do("realtime-transcribe-and-store", async (): Promise<any> => {
				console.log(`æ­¥éª¤2: å¼€å§‹å®æ—¶éŸ³é¢‘è½¬å½•å’Œå­˜å‚¨ï¼Œè¯­è¨€: ${options.targetLanguage}`);
				
				// 1. æå‰åˆ›å»ºè½¬å½•è®°å½•
				const transcriptionId = await createTranscription(
					env,
					taskId,
					options.targetLanguage,
					options.style || 'normal',
					{
						startTime: new Date().toISOString()
					}
				);
				console.log(`âœ… åˆ›å»ºè½¬å½•è®°å½•: ${transcriptionId}`);
				
				// 2. åˆå§‹åŒ–å®æ—¶åˆå¹¶çŠ¶æ€
				const mergeState: RealtimeMergeState = initRealtimeMergeState(transcriptionId, options.targetLanguage);
				
				// 3. è·å–éŸ³é¢‘æ•°æ®å¹¶å‘é€è½¬å½•è¯·æ±‚
				const audioObject = await env.MEDIA_STORAGE.get(audioKey);
				if (!audioObject) {
					throw new Error(`R2 éŸ³é¢‘å¯¹è±¡æœªæ‰¾åˆ°: ${audioKey}`);
				}
				const audioData = await audioObject.arrayBuffer();
				console.log(`éŸ³é¢‘è¯»å–å®Œæˆï¼Œå¤§å°: ${audioData.byteLength} bytes`);
				
				// 4. å‘é€è½¬å½•è¯·æ±‚
				const formData = new FormData();
				formData.append('file', new Blob([audioData], { type: 'audio/aac' }), 'audio.aac');
				formData.append('targetLanguage', options.targetLanguage);
				formData.append('style', options.style || 'normal');

				const result = await env.TRANSCRIBE_SERVICE.fetch(new Request('https://transcribe/transcribe', {
					method: 'POST',
					body: formData
				}));

				if (!result.ok) {
					throw new Error(`è½¬å½•æœåŠ¡è°ƒç”¨å¤±è´¥: ${result.status}`);
				}

				// 5. å®æ—¶å¤„ç†SSEæµ
				const reader = result.body?.getReader();
				if (!reader) {
					throw new Error('æ— æ³•è¯»å–è½¬å½•æœåŠ¡å“åº”æµ');
				}

				const decoder = new TextDecoder();
				let metadata: any = null;
				
				// ğŸ”¥ æ”¶é›†æ‰€æœ‰å·²å­˜å‚¨çš„segments
				const allStoredSegments: TranscriptionSegment[] = [];

				// æ—¶é—´æ ¼å¼è§£æå‡½æ•°: "XmYsZms" -> æ¯«ç§’æ•°
				const parseTimeToMs = (timeStr: string): number => {
					const match = timeStr.match(/(\d+)m(\d+)s(\d+)ms/);
					if (!match) return 0;
					const [, minutes, seconds, ms] = match;
					return parseInt(minutes) * 60000 + parseInt(seconds) * 1000 + parseInt(ms);
				};

				try {
					while (true) {
						const { done, value } = await reader.read();
						if (done) break;

						const chunk = decoder.decode(value, { stream: true });
						const lines = chunk.split('\n');

						for (const line of lines) {
							if (line.startsWith('data: ')) {
								try {
									const data = JSON.parse(line.slice(6));

									if (data.type === 'start') {
										metadata = data.metadata;
										console.log(`ğŸ¯ å¼€å§‹å®æ—¶è½¬å½•å¤„ç†: ${metadata.fileName}`);
									} else if (data.type === 'segment') {
										// æ„é€ è½¬å½•ç‰‡æ®µ
										const segment: TranscriptionSegment = {
											sequence: data.segment.sequence,
											start_ms: parseTimeToMs(data.segment.start || '0m0s0ms'),
											end_ms: parseTimeToMs(data.segment.end || '0m0s0ms'),
											content_type: data.segment.content_type || 'speech',
											speaker: data.segment.speaker || 'unknown',
											original_text: data.segment.original || '',
											translated_text: data.segment.translation || ''
										};
										
										// ğŸ”¥ æ ¸å¿ƒæ”¹è¿›ï¼šå®æ—¶å¤„ç†æ¯ä¸ªç‰‡æ®µ
										const storedSegment = await processSegmentRealtime(env, mergeState, segment);
										
										// ğŸ”¥ æ”¶é›†å·²å­˜å‚¨çš„segmentï¼ˆå¦‚æœæœ‰ï¼‰
										if (storedSegment) {
											allStoredSegments.push(storedSegment);
										}
									} else if (data.type === 'error') {
										throw new Error(`è½¬å½•æœåŠ¡é”™è¯¯: ${data.error}`);
									}
								} catch (parseError) {
									// å¿½ç•¥è§£æé”™è¯¯çš„è¡Œ
								}
							}
						}
					}
				} finally {
					reader.releaseLock();
				}

				// 6. å¤„ç†æœ€åä¸€ä¸ªå¾…åˆå¹¶çš„ç»„
				if (mergeState.currentGroup) {
					const isFirst = !mergeState.isFirstSegmentStored;
					await storeSegmentToD1(env, mergeState.transcriptionId, mergeState.currentGroup, ++mergeState.lastStoredSequence, isFirst);
					console.log(`ğŸ’¾ å­˜å‚¨æœ€åä¸€ä¸ªåˆå¹¶ç»„: sequence=${mergeState.lastStoredSequence}, is_first=${isFirst}`);
					
					// ğŸ”¥ æ”¶é›†æœ€åä¸€ä¸ªå­˜å‚¨çš„segment
					allStoredSegments.push({
						...mergeState.currentGroup,
						sequence: mergeState.lastStoredSequence,
						is_first: isFirst,
						is_last: false
					});
				}

				// 7. æ ‡è®°æœ€åä¸€ä¸ªç‰‡æ®µä¸º is_last=true
				if (mergeState.lastStoredSequence > 0) {
					await markLastTranscriptionSegment(env, transcriptionId);
					console.log(`ğŸ æ ‡è®°æœ€åç‰‡æ®µå®Œæˆ: transcription_id=${transcriptionId}`);
					
					// ğŸ”¥ æ›´æ–°æœ€åä¸€ä¸ªsegmentçš„is_lastæ ‡è®°
					if (allStoredSegments.length > 0) {
						allStoredSegments[allStoredSegments.length - 1].is_last = true;
					}
				}

				// 8. æ›´æ–°è½¬å½•è®°å½•çš„æ€»ç‰‡æ®µæ•°
				await updateTranscriptionTotalSegments(env, transcriptionId, mergeState.lastStoredSequence);
				
				// 9. æ›´æ–°ä»»åŠ¡çŠ¶æ€
				await updateMediaTaskStatus(env, taskId, 'completed', 90);
				
				console.log(`âœ… å®æ—¶è½¬å½•å®Œæˆ: ID=${transcriptionId}, æœ€ç»ˆç‰‡æ®µæ•°=${mergeState.lastStoredSequence}`);
				console.log(`ğŸ“Š æ”¶é›†åˆ° ${allStoredSegments.length} ä¸ªå·²å­˜å‚¨çš„segments`);
				
				return {
					transcriptionId,
					totalSegments: mergeState.lastStoredSequence,
					metadata,
					segments: allStoredSegments  // ğŸ”¥ è¿”å›æ‰€æœ‰å·²å­˜å‚¨çš„segments
				};
			});
			
			// æ­¥éª¤3: éŸ³é¢‘åˆ‡åˆ† (æ–°å¢)
			const audioSegmentResult = await step.do("audio-segment", async () => {
				console.log(`æ­¥éª¤3: å¼€å§‹éŸ³é¢‘åˆ‡åˆ† ${taskId}`);
				
				// ğŸ”¥ ä½¿ç”¨ä¸Šä¸€æ­¥æ”¶é›†çš„æ•°æ®ï¼Œé¿å…æŸ¥è¯¢D1
				if (!transcriptionResult.segments || transcriptionResult.segments.length === 0) {
					console.log(`è·³è¿‡éŸ³é¢‘åˆ‡åˆ†: æ²¡æœ‰è½¬å½•æ•°æ®`);
					return { success: false, message: 'æ²¡æœ‰è½¬å½•æ•°æ®' };
				}
				
				// ğŸ”¥ ç›´æ¥ä½¿ç”¨æ¯«ç§’æ ¼å¼ï¼Œæ¶ˆé™¤å†—ä½™è½¬æ¢
				const transcripts = transcriptionResult.segments.map((segment: TranscriptionSegment) => ({
					sequence: segment.sequence,
					startMs: segment.start_ms,
					endMs: segment.end_ms,
					speaker: segment.speaker,
					original: segment.original_text,
					translation: segment.translated_text,
					content_type: segment.content_type
				}));
				
				console.log(`ğŸ¯ è½¬å½•æ•°æ®æ ·æœ¬ (å‰3æ¡):`, transcripts.slice(0, 3).map(t => ({
					sequence: t.sequence,
					timeRange: `${t.startMs}ms - ${t.endMs}ms`,
					speaker: t.speaker,
					text: t.original.substring(0, 30) + '...'
				})));
				
				console.log(`å‡†å¤‡åˆ‡åˆ†éŸ³é¢‘: å…± ${transcripts.length} ä¸ªè½¬å½•ç‰‡æ®µ`);
				
				// 3. è°ƒç”¨éŸ³é¢‘åˆ‡åˆ†æœåŠ¡
				const pathParts = originalFile.split('/');
				const userId = pathParts[1];
				const outputPrefix = `users/${userId}/${taskId}/audio-segments`;
				
				const result = await env.AUDIO_SEGMENT_SERVICE.segment({
					audioKey: audioKey,
					transcripts,
					outputPrefix
					// æ³¨æ„ï¼šåˆ‡åˆ†å‚æ•°ç°åœ¨é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼šGAP_DURATION_MS, MAX_DURATION_MS, MIN_DURATION_MS
				});
				
				if (!result.success) {
					console.error(`éŸ³é¢‘åˆ‡åˆ†å¤±è´¥: ${result.error}`);
					return { success: false, error: result.error };
				}
				
				console.log(`âœ… éŸ³é¢‘åˆ‡åˆ†å®Œæˆ: ç”Ÿæˆ ${result.segments?.length || 0} ä¸ªéŸ³é¢‘ç‰‡æ®µ`);
				
				// 4. å°†åˆ‡åˆ†ä¿¡æ¯å­˜å‚¨åˆ°æ•°æ®åº“(å¯é€‰)
				if (result.segments && result.segments.length > 0) {
					// å¯ä»¥åœ¨è¿™é‡Œå­˜å‚¨éŸ³é¢‘ç‰‡æ®µä¿¡æ¯åˆ°æ•°æ®åº“
					console.log(`ğŸµ éŸ³é¢‘åˆ‡ç‰‡è¯¦æƒ…:`, result.segments.map(s => ({
						id: s.segmentId,
						speaker: s.speaker,
						duration: `${s.durationMs}ms`,
						sentences: s.sentences.length
					})));
				}
				
				return {
					success: true,
					segmentCount: result.segments?.length || 0,
					sentenceToSegmentMap: result.sentenceToSegmentMap
				};
			});
			
			// æ­¥éª¤4: æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼ˆåŸå§‹æ–‡ä»¶ä¿ç•™åœ¨videosæ¡¶ï¼‰
			await step.do("cleanup", async () => {
				console.log(`æ­¥éª¤4: æ¸…ç†å®Œæˆï¼Œä¿ç•™åŸå§‹æ–‡ä»¶: ${originalFile}`);
				// ä¸åˆ é™¤åŸå§‹æ–‡ä»¶ï¼Œä¿ç•™åœ¨videosæ¡¶ä¸­ä¾›ç”¨æˆ·ä¸‹è½½
			});
			
			// æ­¥éª¤5: æ›´æ–°æœ€ç»ˆçŠ¶æ€
			await step.do("finalize", async () => {
				console.log(`æ­¥éª¤5: ä»»åŠ¡å®Œæˆ ${taskId}`);
				
				await completeMediaTask(env, taskId, true);
				
				console.log(`SepTransWorkflow æˆåŠŸå®Œæˆ: ${taskId}`);
			});
			
			// æ­¥éª¤6: å®Œæˆæ—¥å¿—
			await step.do("complete-logging", async () => {
				console.log(`æ­¥éª¤6: å·¥ä½œæµå®Œæˆ ${taskId}`);
				console.log(`ğŸ“Š ç»“æœç»Ÿè®¡: è§†é¢‘=${videoUrl}, éŸ³é¢‘=${audioUrl}, è½¬å½•ç‰‡æ®µ=${transcriptionResult.totalSegments}, éŸ³é¢‘åˆ‡ç‰‡=${audioSegmentResult.segmentCount}`);
			});
			
		} catch (error: any) {
			console.error(`SepTransWorkflow å¤±è´¥: ${taskId}`, error);
			
			// æ›´æ–°ä»»åŠ¡çŠ¶æ€ä¸ºå¤±è´¥
			await step.do("mark-failed", async () => {
				await setMediaTaskError(env, taskId, error.message, error.stack);
			});
			
			// è®°å½•é”™è¯¯ä¿¡æ¯
			await step.do("log-error", async () => {
				console.error(`âŒ å·¥ä½œæµå¤±è´¥è¯¦æƒ… ${taskId}:`, {
					message: error.message,
					stack: error.stack?.substring(0, 500)
				});
			});
			
			throw error;
		}
	}
}